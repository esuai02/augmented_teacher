#!/usr/bin/env python3
"""
ğŸ”¥ Holarchy ë¬¸ì„œ ìë™ ë°°ì¹˜ ì‹œìŠ¤í…œ v2.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ê¸°ëŠ¥:
- ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ HTE ëª¨ë“ˆ(M00~M21) ê²°ì •
- ë¬¸ì„œ íƒ€ì…ë³„ ìë™ ë¶„ë¥˜: Project(P), Task(T), Drilling(D), App(A)
- ë‹¤ì¤‘ í™€ë¡  ë™ì‹œ ìƒì„± ì§€ì›
- íŒŒì¼ëª…: HTE_MXX_PYY_TZZ_VWW_AAA.md

í´ë” êµ¬ì¡°:
  2 Company/4 HTE/
  â”œâ”€â”€ M00_Astral/
  â”œâ”€â”€ M01_TimeCrystal/
  â”œâ”€â”€ ...
  â””â”€â”€ M21_SoftwareBackbone/
"""

import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict


@dataclass
class HolonSpec:
    """ìƒì„±í•  í™€ë¡  ëª…ì„¸"""
    content: str
    holon_type: str  # project, task, drilling, app
    module_hint: str = None  # M00~M21 ì§ì ‘ ì§€ì • ì‹œ
    parent_id: str = None
    title: str = None
    priority: str = "medium"


class DocumentPlacer:
    """ë¬¸ì„œ ìë™ ë°°ì¹˜ ë° ìƒì„± (v2.0 - ë‹¤ì¤‘ í™€ë¡  ì§€ì›)"""
    
    # í™€ë¡  íƒ€ì… ì •ì˜ (P=Project, T=Task/Topic, D=Drilling, A=App/Agent)
    HOLON_TYPES = {
        "project": {"code": "P", "desc": "í”„ë¡œì íŠ¸ - ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ê³„íš", 
                   "keywords": ["í”„ë¡œì íŠ¸", "ê³„íš", "ê¸°íš", "ë¡œë“œë§µ", "ì „ëµ", "ë°©ì•ˆ"]},
        "task": {"code": "T", "desc": "íƒœìŠ¤í¬ - êµ¬ì²´ì  ì‹¤í–‰ ë‹¨ìœ„",
                "keywords": ["í• ì¼", "ì‘ì—…", "ì‹¤í–‰", "êµ¬í˜„", "ê°œë°œ", "í…ŒìŠ¤íŠ¸"]},
        "drilling": {"code": "D", "desc": "ë“œë¦´ë§ - ê¹Šì´ ìˆëŠ” íƒêµ¬/ì—°êµ¬",
                    "keywords": ["ì—°êµ¬", "ë¶„ì„", "íƒêµ¬", "ì‹¬ì¸µ", "ì¡°ì‚¬", "ë¦¬ì„œì¹˜"]},
        "app": {"code": "A", "desc": "ì•±/ì—ì´ì „íŠ¸ - ìë™í™”ëœ ê¸°ëŠ¥ ë‹¨ìœ„",
               "keywords": ["ì•±", "ì—ì´ì „íŠ¸", "ë´‡", "ìë™í™”", "ë„êµ¬", "ì‹œìŠ¤í…œ"]}
    }
    
    # ëª¨ë“ˆ ì •ì˜
    MODULES = {
        "M00": {"name": "Astral", "full": "M00_Astral", 
                "keywords": ["ì „ëµ", "ì„¸ê³„ê´€", "ë¹„ì „", "ë¯¸ì…˜", "ì² í•™", "ëª©í‘œ", "ë°©í–¥", "í•µì‹¬"],
                "desc": "ì‹¬ì—°ì˜ ë¿Œë¦¬, ì¡´ì¬ì˜ ì›ì²œ"},
        "M01": {"name": "TimeCrystal", "full": "M01_TimeCrystal",
                "keywords": ["ì‹œê°„", "ê²½ì˜", "ì˜ì‚¬ê²°ì •", "ë¦¬ë”", "ì¼ì •", "ê³„íš", "ìŠ¤ì¼€ì¤„"],
                "desc": "ë¯¸ë˜ì—ì„œ ì˜¨ ê¸°ì–µ, ì² í•™ì˜ ì”¨ì•—"},
        "M02": {"name": "TimelineGenesis", "full": "M02_TimelineGenesis",
                "keywords": ["ìš´ì˜", "í”„ë¡œì„¸ìŠ¤", "ë¦¬ë“¬", "íšŒì˜", "ë¯¸íŒ…", "ì ˆì°¨", "ì›Œí¬í”Œë¡œìš°"],
                "desc": "ì² í•™ì„ í˜„ì‹¤ì— ì‹¬ëŠ” ì¥ì¹˜"},
        "M03": {"name": "BusinessModel", "full": "M03_BusinessModel",
                "keywords": ["ë¹„ì¦ˆë‹ˆìŠ¤", "ëª¨ë¸", "ìˆ˜ìµ", "ë§¤ì¶œ", "ê°€ê²©", "ê³ ê°", "ì‹œì¥"],
                "desc": "ì˜ë¯¸ë¥¼ ê±°ë˜ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” ë³€í™˜"},
        "M04": {"name": "KPI_OKR", "full": "M04_KPI_OKR",
                "keywords": ["kpi", "okr", "ëª©í‘œ", "ì„±ê³¼", "ì§€í‘œ", "ì¸¡ì •", "ë‹¬ì„±"],
                "desc": "ìˆ«ìê°€ ê¸°ë„ë¬¸ì´ ë˜ëŠ” ê³³"},
        "M05": {"name": "FinancialGrowth", "full": "M05_FinancialGrowth",
                "keywords": ["ì¬ë¬´", "íˆ¬ì", "ì˜ˆì‚°", "ë¹„ìš©", "ìê¸ˆ", "ê¸ˆìœµ", "ì„±ì¥"],
                "desc": "ìˆœí™˜ì˜ ì†ë„, ì—ë„ˆì§€ì˜ íë¦„"},
        "M06": {"name": "SWOT", "full": "M06_SWOT",
                "keywords": ["swot", "ê°•ì ", "ì•½ì ", "ê¸°íšŒ", "ìœ„í˜‘", "ë¶„ì„", "ê²½ìŸ"],
                "desc": "ì˜ì‹ì˜ ë°©í–¥ì„±, íŒ¨í„´ì˜ ë¶„ë¥˜"},
        "M07": {"name": "BizWeighing", "full": "M07_BizWeighing",
                "keywords": ["ì „ëµ", "ë¹„ì¤‘", "ìš°ì„ ìˆœìœ„", "ë¦¬ì†ŒìŠ¤", "ë°°ë¶„", "ì§‘ì¤‘"],
                "desc": "ë©ˆì¶”ì§€ ì•ŠëŠ” ì „ìŸ, ë¦¬ë“¬ì˜ ìŠ¹ë¦¬"},
        "M08": {"name": "InternalBranding", "full": "M08_InternalBranding",
                "keywords": ["ë‚´ë¶€", "ë¸Œëœë”©", "ë¬¸í™”", "ê°€ì¹˜", "ì§ì›", "íŒ€"],
                "desc": "ìê¸°ë„ ëª¨ë¥´ê²Œ í˜ë¦¬ëŠ” íŒ¨í„´"},
        "M09": {"name": "VerticalDrilling", "full": "M09_VerticalDrilling",
                "keywords": ["í•µì‹¬", "ê¸°ìˆ ", "ê°œë°œ", "ì—°êµ¬", "ê¹Šì´", "ì „ë¬¸"],
                "desc": "í•µì‹¬ ì „ëµ/ëª¨ë¸/ê¸°ìˆ ê°œë°œ ê¸°íšì˜ ìˆ˜ì§ êµ´ì°©"},
        "M10": {"name": "AgentGarden", "full": "M10_AgentGarden",
                "keywords": ["agent", "ì—ì´ì „íŠ¸", "holon", "í™€ë¡ ", "ìë™í™”", "ë´‡"],
                "desc": "ë¶„ì‚°ëœ ë¬´ì§€ì„± ì‹¤í–‰ì˜ ì¶•ì œ"},
        "M11": {"name": "ServicePipeline", "full": "M11_ServicePipeline",
                "keywords": ["ì„œë¹„ìŠ¤", "íŒŒì´í”„ë¼ì¸", "ë°°í¬", "ì „ë‹¬", "ìš´ì˜"],
                "desc": "ì „ë‹¬ì˜ ë§ˆë²•, ê´€í†µì˜ ê¸°ìˆ "},
        "M12": {"name": "ExternalBranding", "full": "M12_ExternalBranding",
                "keywords": ["ì™¸ë¶€", "ë§ˆì¼€íŒ…", "í™ë³´", "ê´‘ê³ ", "ë¸Œëœë“œ", "ì¸ì§€ë„"],
                "desc": "ì¡´ì¬ì˜ ì”í–¥ì„ í¼ëœ¨ë¦¬ëŠ” êµ¬ì¡°"},
        "M13": {"name": "TrackGrowthEngine", "full": "M13_TrackGrowthEngine",
                "keywords": ["ì„±ì¥", "ì—”ì§„", "í™•ì¥", "ìŠ¤ì¼€ì¼", "ê·¸ë¡œìŠ¤"],
                "desc": "ë¶€ë¥´ëŠ” í˜, íë¥´ê²Œ í•˜ëŠ” ë£¨í”„"},
        "M14": {"name": "CompanyOnboarding", "full": "M14_CompanyOnboarding",
                "keywords": ["ì˜¨ë³´ë”©", "êµìœ¡", "ì‹ ì…", "ì…ì‚¬", "íŠ¸ë ˆì´ë‹"],
                "desc": "ë¦¬ë“¬ì´ ë¹ ë¥´ë©´ ì´ë¯¸ ì´ê¸´ ìƒíƒœ"},
        "M15": {"name": "TimeCrystalCEO", "full": "M15_TimeCrystalCEO",
                "keywords": ["ceo", "ë¦¬ë”ì‹­", "ê²½ì˜ì§„", "ëŒ€í‘œ", "ì´ê´„"],
                "desc": "íë¦„ì´ ë˜ëŠ” ë¦¬ë”ì‹­"},
        "M16": {"name": "AIMindArchitecture", "full": "M16_AIMindArchitecture",
                "keywords": ["ai", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "llm", "gpt", "íŠœí„°", "í•™ìŠµ"],
                "desc": "ë„êµ¬ê°€ ìë„ ê³µê°„ì„ ì—¬ëŠ” ê²ƒ"},
        "M17": {"name": "NervousSystem", "full": "M17_NervousSystem",
                "keywords": ["ì‹ ê²½", "ë°ì´í„°", "íŒŒì´í”„ë¼ì¸", "ì—°ê²°", "í†µí•©", "api"],
                "desc": "ì—°ê²°ì˜ ì‹ ì „, íŒ¨í„´ì˜ ë„¤íŠ¸ì›Œí¬"},
        "M18": {"name": "InformationBlocks", "full": "M18_InformationBlocks",
                "keywords": ["ì •ë³´", "ë¸”ë¡", "ì§€ëŠ¥", "êµ¬ì¡°", "í”„ë ˆì„ì›Œí¬"],
                "desc": "ë¬´ì˜ì‹ ì •ë³´ ì¶•ì ì˜ ì‹¬ì—°"},
        "M19": {"name": "CompanyCulture", "full": "M19_CompanyCulture",
                "keywords": ["ë¬¸í™”", "ê°€ì¹˜ê´€", "ì² í•™", "ì¡°ì§ë¬¸í™”", "ë¬´ì§€ì„±"],
                "desc": "ë¬´ì˜ì‹ì  ì§€ì‹ì¶•ì  ì‹œìŠ¤í…œ"},
        "M20": {"name": "KnowledgeCrystal", "full": "M20_KnowledgeCrystal",
                "keywords": ["ì§€ì‹", "ì¶•ì ", "ê²°ì •ì²´", "í•™ìŠµ", "ì²´ê³„"],
                "desc": "ë£¨í”„ì˜ ì§„ë™ìœ¼ë¡œ ì‘ê²°ëœ ê²°ì •"},
        "M21": {"name": "SoftwareBackbone", "full": "M21_SoftwareBackbone",
                "keywords": ["ì†Œí”„íŠ¸ì›¨ì–´", "ë°±ë³¸", "ì¸í”„ë¼", "ì‹œìŠ¤í…œ", "ì„œë²„", "í´ë¼ìš°ë“œ"],
                "desc": "ëª¨ë‘ê°€ ì¤‘ì‹¬ì¸ ë¬´í˜•ì˜ ë¼ˆëŒ€"},
    }
    
    def __init__(self, base_path: str = None):
        if base_path:
            self.base_path = Path(base_path)
        else:
            self.base_path = Path(__file__).parent.parent.parent  # Holarchy ë£¨íŠ¸
        
        self.hte_path = self.base_path / "2 Company" / "4 HTE"
    
    def detect_holon_type(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ í™€ë¡  íƒ€ì… ìë™ ê°ì§€"""
        text_lower = text.lower()
        scores = {}
        
        for type_name, type_info in self.HOLON_TYPES.items():
            score = sum(1 for kw in type_info["keywords"] if kw.lower() in text_lower)
            scores[type_name] = score
        
        if max(scores.values()) == 0:
            return "task"  # ê¸°ë³¸ê°’
        
        return max(scores, key=scores.get)
    
    def parse_multi_holon_input(self, text: str) -> List[HolonSpec]:
        """
        ë‹¤ì¤‘ í™€ë¡  ì…ë ¥ íŒŒì‹±
        
        ì§€ì› í¬ë§·:
        1. ë²ˆí˜¸ ëª©ë¡: "1. ì²«ë²ˆì§¸\n2. ë‘ë²ˆì§¸"
        2. êµ¬ë¶„ì: "---" ë˜ëŠ” "==="
        3. í—¤ë” ê¸°ë°˜: "## í•­ëª©1\në‚´ìš©\n## í•­ëª©2"
        """
        specs = []
        
        # --- êµ¬ë¶„ìë¡œ ë¶„ë¦¬
        if '\n---\n' in text or '\n===\n' in text:
            parts = re.split(r'\n[-=]{3,}\n', text)
            for part in parts:
                if part.strip():
                    specs.append(HolonSpec(
                        content=part.strip(),
                        holon_type=self.detect_holon_type(part),
                        title=self._extract_title(part)
                    ))
            return specs
        
        # ## í—¤ë”ë¡œ ë¶„ë¦¬
        header_splits = re.split(r'\n##\s+', text)
        if len(header_splits) > 1:
            for i, part in enumerate(header_splits):
                if i == 0 and not part.strip():
                    continue
                if part.strip():
                    # ì²« ì¤„ì„ ì œëª©ìœ¼ë¡œ
                    lines = part.strip().split('\n')
                    title = lines[0].strip()
                    content = '\n'.join(lines) if len(lines) > 1 else title
                    specs.append(HolonSpec(
                        content=content,
                        holon_type=self.detect_holon_type(content),
                        title=title
                    ))
            return specs
        
        # ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œ ë¶„ë¦¬
        numbered = re.findall(r'(?:^|\n)(\d+)[.)\s]+(.+?)(?=\n\d+[.)\s]|\n\n|\Z)', text, re.DOTALL)
        if numbered and len(numbered) > 1:
            for num, content in numbered:
                if content.strip():
                    specs.append(HolonSpec(
                        content=content.strip(),
                        holon_type=self.detect_holon_type(content),
                        title=self._extract_title(content)
                    ))
            return specs
        
        # ë‹¨ì¼ í™€ë¡ 
        specs.append(HolonSpec(
            content=text.strip(),
            holon_type=self.detect_holon_type(text),
            title=self._extract_title(text)
        ))
        
        return specs
    
    def _extract_title(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì œëª© ì¶”ì¶œ"""
        lines = text.strip().split('\n')
        for line in lines[:5]:
            line = line.strip()
            if line.startswith('#'):
                return line.lstrip('#').strip()
            if len(line) > 5 and len(line) < 100:
                return line
        return lines[0][:50] if lines else "ë¬¸ì„œ"
    
    def create_multi_holons(self, text: str, parent_id: str = None, 
                            module_hint: str = None) -> List[Dict]:
        """
        ë‹¤ì¤‘ í™€ë¡  ë™ì‹œ ìƒì„± (SSOT ì¤€ìˆ˜)
        
        Args:
            text: ë‹¤ì¤‘ í™€ë¡  ì…ë ¥ í…ìŠ¤íŠ¸
            parent_id: ê³µí†µ ë¶€ëª¨ ID (ì„ íƒ)
            module_hint: ëª¨ë“  í™€ë¡ ì— ì ìš©í•  ëª¨ë“ˆ (M00~M21)
        
        Returns:
            ìƒì„±ëœ í™€ë¡  ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        print("=" * 60)
        print("ğŸ”¥ Holarchy ë‹¤ì¤‘ í™€ë¡  ìë™ ë°°ì¹˜ ì‹œìŠ¤í…œ")
        print("=" * 60)
        print()
        
        # 1. ì…ë ¥ íŒŒì‹±
        specs = self.parse_multi_holon_input(text)
        print(f"ğŸ“ ê°ì§€ëœ í™€ë¡  ìˆ˜: {len(specs)}")
        
        # ëª¨ë“ˆ íŒíŠ¸ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if module_hint:
            print(f"ğŸ“ ì§€ì •ëœ ë¯¸ì…˜ ì—ì´ì „íŠ¸: {module_hint}")
        print()
        
        results = []
        
        for i, spec in enumerate(specs, 1):
            print(f"â”€â”€â”€ [{i}/{len(specs)}] {spec.title or 'ë¬´ì œ'} â”€â”€â”€")
            
            # ëª¨ë“ˆ ê²°ì •: ì „ì—­ íŒíŠ¸ > ê°œë³„ íŒíŠ¸ > ìë™ ë¶„ì„
            effective_module = module_hint or spec.module_hint
            
            if effective_module and effective_module.upper() in self.MODULES:
                module_id = effective_module.upper()
                confidence = 1.0
            else:
                module_id, confidence, analysis = self.analyze_content(spec.content)
            
            print(f"   ëª¨ë“ˆ: {self.MODULES[module_id]['full']}")
            print(f"   íƒ€ì…: {spec.holon_type} ({self.HOLON_TYPES[spec.holon_type]['desc']})")
            print(f"   ì‹ ë¢°ë„: {confidence:.0%}")
            
            # 3. ë¬¸ì„œ ìƒì„± (module_hint ì „ë‹¬)
            result = self.create_document(
                spec.content, 
                doc_type=spec.holon_type,
                parent_id=parent_id or spec.parent_id,
                module_hint=effective_module
            )
            
            results.append({
                **result,
                "index": i,
                "detected_type": spec.holon_type
            })
            print()
        
        print("=" * 60)
        print(f"âœ… ì´ {len(results)}ê°œ í™€ë¡  ìƒì„± ì™„ë£Œ")
        print("=" * 60)
        
        return results
    
    def analyze_by_mission(self, text: str) -> Dict[str, List[Dict]]:
        """
        22ê°œ ë¯¸ì…˜ ì—ì´ì „íŠ¸ë³„ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
        
        Returns:
            {module_id: [{"score": float, "keywords": [...], "relevance": str}]}
        """
        text_lower = text.lower()
        analysis = {}
        
        for module_id, info in self.MODULES.items():
            matched = []
            for keyword in info["keywords"]:
                if keyword.lower() in text_lower:
                    matched.append(keyword)
            
            if matched:
                analysis[module_id] = {
                    "name": info["name"],
                    "full": info["full"],
                    "desc": info["desc"],
                    "score": len(matched),
                    "keywords": matched,
                    "confidence": min(len(matched) / 5, 1.0)
                }
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        return dict(sorted(analysis.items(), key=lambda x: x[1]["score"], reverse=True))
    
    def analyze_content(self, text: str) -> Tuple[str, float, Dict]:
        """í…ìŠ¤íŠ¸ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ëª¨ë“ˆ ê²°ì •"""
        text_lower = text.lower()
        scores = {}
        
        for module_id, info in self.MODULES.items():
            score = 0
            matched_keywords = []
            
            for keyword in info["keywords"]:
                if keyword.lower() in text_lower:
                    score += 1
                    matched_keywords.append(keyword)
            
            if score > 0:
                scores[module_id] = {
                    "score": score,
                    "keywords": matched_keywords,
                    "info": info
                }
        
        if not scores:
            # ê¸°ë³¸ê°’: M02 (íšŒì˜/í”„ë¡œì„¸ìŠ¤)
            return "M02", 0.3, {"matched": [], "reason": "ê¸°ë³¸ê°’ (í‚¤ì›Œë“œ ë§¤ì¹­ ì—†ìŒ)"}
        
        # ìµœê³  ì ìˆ˜ ëª¨ë“ˆ ì„ íƒ
        best_module = max(scores, key=lambda x: scores[x]["score"])
        best_info = scores[best_module]
        confidence = min(best_info["score"] / 5, 1.0)  # 5ê°œ í‚¤ì›Œë“œ ë§¤ì¹­ì‹œ 100%
        
        return best_module, confidence, {
            "matched": best_info["keywords"],
            "module_desc": best_info["info"]["desc"],
            "all_scores": {k: v["score"] for k, v in scores.items()}
        }
    
    def get_next_file_number(self, module_id: str) -> Tuple[int, int]:
        """í•´ë‹¹ ëª¨ë“ˆì˜ ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ (P, T) ê²°ì •"""
        module_info = self.MODULES.get(module_id)
        if not module_info:
            return 1, 1
        
        module_path = self.hte_path / module_info["full"]
        if not module_path.exists():
            module_path.mkdir(parents=True, exist_ok=True)
            return 1, 1
        
        # ê¸°ì¡´ íŒŒì¼ë“¤ì—ì„œ ìµœëŒ€ P ë²ˆí˜¸ ì°¾ê¸°
        pattern = f"HTE_{module_id}_P*_T*_V*_A*.md"
        existing = list(module_path.glob(pattern))
        
        if not existing:
            return 1, 1
        
        max_p = 0
        max_t_for_max_p = 0
        
        for f in existing:
            match = re.search(r'P(\d+)_T(\d+)', f.name)
            if match:
                p = int(match.group(1))
                t = int(match.group(2))
                if p > max_p:
                    max_p = p
                    max_t_for_max_p = t
                elif p == max_p and t > max_t_for_max_p:
                    max_t_for_max_p = t
        
        # ê°™ì€ Pì—ì„œ T ì¦ê°€, ë˜ëŠ” ìƒˆ P
        return max_p, max_t_for_max_p + 1
    
    def generate_filename(self, module_id: str, p_num: int = None, t_num: int = None, 
                          parent_id: str = None) -> str:
        """
        íŒŒì¼ëª… ìƒì„±: HTE_MXX_PYY_TZZ_V00_A00_[PARENT].md
        
        í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹:
        - íŒŒì¼ëª…ì— ë¶€ëª¨ ID í¬í•¨ â†’ í´ë” ì—†ì´ë„ ìƒí•˜ê´€ê³„ íŒŒì•… ê°€ëŠ¥
        - parent_id ì—†ìœ¼ë©´ [ROOT] ì‚¬ìš©
        """
        if p_num is None or t_num is None:
            p_num, t_num = self.get_next_file_number(module_id)
        
        # ë¶€ëª¨ ID í¬ë§·íŒ…
        if parent_id:
            # ê¸´ IDë¥¼ ì§§ê²Œ ë³€í™˜: hte-m16-p01t01 â†’ M16-P01T01
            parent_short = self._shorten_parent_id(parent_id)
        else:
            parent_short = "ROOT"
        
        return f"HTE_{module_id}_P{p_num:02d}_T{t_num:02d}_V00_A00_[{parent_short}].md"
    
    def _shorten_parent_id(self, parent_id: str) -> str:
        """
        ë¶€ëª¨ IDë¥¼ ì§§ì€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        ì˜ˆì‹œ:
        - hte-m16-p01t01 â†’ M16-P01T01
        - hte-doc-000 â†’ DOC-000
        - M16_P01_T01 â†’ M16-P01T01
        """
        if not parent_id:
            return "ROOT"
        
        # hte- ì ‘ë‘ì–´ ì œê±°
        short = parent_id.upper().replace("HTE-", "").replace("HTE_", "")
        
        # ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ í•˜ì´í”ˆìœ¼ë¡œ í†µì¼
        short = short.replace("_", "-")
        
        # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
        if len(short) > 15:
            short = short[:15]
        
        return short
    
    def extract_info(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ì œëª©, ë‚ ì§œ ë“± ì¶”ì¶œ"""
        lines = text.strip().split("\n")
        
        # ì œëª© ì¶”ì¶œ
        title = ""
        for line in lines[:5]:
            line = line.strip()
            if line.startswith("#"):
                title = line.lstrip("#").strip()
                break
            elif "ì œëª©" in line or "íšŒì˜ëª…" in line:
                title = re.sub(r"^(ì œëª©|íšŒì˜ëª…)[:\s]*", "", line).strip()
                break
        
        if not title:
            title = lines[0][:50] if lines else "ë¬¸ì„œ"
        
        # ë‚ ì§œ ì¶”ì¶œ
        date = datetime.now().strftime("%Y-%m-%d")
        date_match = re.search(r"(\d{4}[-./]\d{2}[-./]\d{2})", text)
        if date_match:
            date = date_match.group(1).replace(".", "-").replace("/", "-")
        
        # ì°¸ì„ì ì¶”ì¶œ
        participants = []
        part_match = re.search(r"ì°¸ì„ì?[:\s]*(.+?)(?:\n|$)", text)
        if part_match:
            participants = [p.strip() for p in re.split(r"[,ï¼Œã€\s]+", part_match.group(1)) if p.strip()]
        
        # ê²°ì •/í• ì¼ ì¶”ì¶œ
        decisions = re.findall(r"ê²°ì •[:\s]*(.+?)(?:\n|$)", text, re.IGNORECASE)
        tasks = re.findall(r"(?:TODO|í• ì¼)[:\s]*(.+?)(?:\n|$)", text, re.IGNORECASE)
        
        return {
            "title": title,
            "date": date,
            "participants": participants or ["ë¯¸ì§€ì •"],
            "decisions": [d.strip() for d in decisions],
            "tasks": [t.strip() for t in tasks]
        }
    
    def create_document(self, text: str, doc_type: str = "auto", parent_id: str = None, 
                        module_hint: str = None) -> Dict:
        """
        ë¬¸ì„œ ìƒì„±
        
        Args:
            text: ë¬¸ì„œ ë‚´ìš©
            doc_type: ë¬¸ì„œ íƒ€ì… (auto/project/task/drilling/app)
            parent_id: ë¶€ëª¨ ë¬¸ì„œ ID
            module_hint: ì§ì ‘ ì§€ì •í•œ ëª¨ë“ˆ (M00~M21)
        """
        print("=" * 60)
        print("ğŸ”¥ Holarchy ë¬¸ì„œ ìë™ ë°°ì¹˜ ì‹œìŠ¤í…œ")
        print("=" * 60)
        print()
        
        # 1. ë‚´ìš© ë¶„ì„
        print("ğŸ“ ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        # ëª¨ë“ˆ íŒíŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if module_hint and module_hint.upper() in self.MODULES:
            module_id = module_hint.upper()
            confidence = 1.0
            analysis = {"matched": ["ì§ì ‘ ì§€ì •"], "module_desc": self.MODULES[module_id]["desc"]}
        else:
            module_id, confidence, analysis = self.analyze_content(text)
        
        info = self.extract_info(text)
        
        module_info = self.MODULES[module_id]
        print(f"   ëª¨ë“ˆ: {module_info['full']}")
        print(f"   ì‹ ë¢°ë„: {confidence:.0%}")
        print(f"   ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(analysis['matched'])}")
        print(f"   ëª¨ë“ˆ ì„¤ëª…: {module_info['desc']}")
        print()
        
        # 2. íŒŒì¼ëª… ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ - ë¶€ëª¨ ID í¬í•¨)
        p_num, t_num = self.get_next_file_number(module_id)
        filename = self.generate_filename(module_id, p_num, t_num, parent_id)
        
        print(f"ğŸ“ íŒŒì¼ ìƒì„±:")
        print(f"   ìœ„ì¹˜: 2 Company/4 HTE/{module_info['full']}/")
        print(f"   íŒŒì¼ëª…: {filename}")
        print()
        
        # 3. Holon ë¬¸ì„œ ìƒì„±
        holon_id = f"hte-{module_id.lower()}-p{p_num:02d}t{t_num:02d}"
        
        holon = {
            "holon_id": holon_id,
            "slug": info["title"].replace(" ", "-").lower()[:30],
            "type": doc_type if doc_type != "auto" else "meeting",
            "module": module_info["full"],
            "meta": {
                "title": info["title"],
                "owner": info["participants"][0],
                "created_at": info["date"],
                "updated_at": info["date"],
                "priority": "high",
                "status": "active",
                "file_code": f"{module_id}_P{p_num:02d}_T{t_num:02d}"
            },
            "W": {
                "worldview": {
                    "identity": f"{module_info['desc']}ì˜ ì¼ë¶€",
                    "belief": "ë¬´ì§€ì„±ì˜ ê´€ì°°ì´ ì˜¤ë˜ë˜ì—ˆì„ ë•Œ ì§€ì‹ì´ ìŠ¤ë©°ë“ ë‹¤",
                    "value_system": "ë°˜ë³µ, íë¦„, ì—°ê²°"
                },
                "will": {
                    "drive": f"{info['title']}ì„ í†µí•´ {module_info['desc']}ë¥¼ ì‹¤í˜„í•œë‹¤",
                    "commitment": "ì™„ë²½í•˜ê²Œ í•˜ê¸° ì „ì— ë°˜ë³µë¶€í„° í•œë‹¤",
                    "non_negotiables": ["íë¦„ ìœ ì§€", "ì—°ê²° ìƒì„±", "ë°˜ë³µ"]
                },
                "intention": {
                    "primary": info["title"],
                    "secondary": info["decisions"][:3] if info["decisions"] else [],
                    "constraints": []
                },
                "goal": {
                    "ultimate": f"{info['title']} ì™„ë£Œ",
                    "milestones": info["tasks"][:3] if info["tasks"] else [],
                    "kpi": [],
                    "okr": {"objective": info["title"], "key_results": info["decisions"][:3]}
                },
                "activation": {
                    "triggers": ["ë¬¸ì„œ ìƒì„±"],
                    "resonance_check": f"ëª¨ë“ˆ {module_id}ì™€ {confidence:.0%} ì •ë ¬",
                    "drift_detection": "í‚¤ì›Œë“œ ë§¤ì¹­ ëª¨ë‹ˆí„°ë§"
                }
            },
            "X": {
                "context": text[:500] + "..." if len(text) > 500 else text,
                "current_state": "ìƒì„±ë¨",
                "heartbeat": "once",
                "signals": ["ë¬¸ì„œ ì‘ì„±ë¨"],
                "constraints": [],
                "will": "ë§¥ë½ì„ ì •í™•íˆ ê¸°ë¡í•œë‹¤"
            },
            "S": {
                "resources": [{"type": "human", "id": p, "role": "ì°¸ì—¬ì"} for p in info["participants"]],
                "dependencies": [],
                "access_points": ["ì´ ë¬¸ì„œ"],
                "structure_model": f"{module_info['full']} êµ¬ì¡°",
                "ontology_ref": [module_info["full"]],
                "readiness_score": 1.0,
                "will": "í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ë³´í•œë‹¤"
            },
            "P": {
                "procedure_steps": [
                    {"step_id": "p001", "description": "ë¬¸ì„œ ìƒì„±", "status": "done"},
                    {"step_id": "p002", "description": "ë‚´ìš© ì‘ì„±", "status": "done"},
                    {"step_id": "p003", "description": "ê²€í† ", "status": "pending"}
                ],
                "optimization_logic": "ë¬´ì§€ì„±ì˜ ë°˜ë³µ",
                "will": "ì ˆì°¨ë¥¼ íë¥´ê²Œ í•œë‹¤"
            },
            "E": {
                "execution_plan": [{"action_id": "e001", "description": "ì‹¤í–‰", "role": info["participants"][0], "eta": "TBD"}],
                "tooling": ["Holarchy System"],
                "edge_case_handling": [],
                "will": "ì‹¤í–‰ì— ì˜®ê¸´ë‹¤"
            },
            "R": {
                "reflection_notes": [],
                "lessons_learned": [],
                "success_path_inference": "ë°˜ë³µ â†’ íë¦„ â†’ ê²°ì •í™”",
                "future_prediction": "",
                "will": "ë˜ëŒì•„ë³´ê³  ê°œì„ í•œë‹¤"
            },
            "T": {
                "impact_channels": ["ê´€ë ¨ì"],
                "traffic_model": "ë¬¸ì„œ ê³µìœ ",
                "viral_mechanics": "",
                "bottleneck_points": [],
                "will": "ì „íŒŒí•œë‹¤"
            },
            "A": {
                "abstraction": "ë°˜ë³µ ê°€ëŠ¥í•œ í…œí”Œë¦¿í™”",
                "modularization": [],
                "automation_opportunities": [],
                "integration_targets": [],
                "resonance_logic": f"ëª¨ë“ˆ {module_id}ì™€ ê³µëª…",
                "will": "ê³ ë„í™”í•œë‹¤"
            },
            "links": {
                "parent": parent_id,  # í•˜ì´ë¸Œë¦¬ë“œ: íŒŒì¼ëª…ê³¼ ë™ì¼í•œ ë¶€ëª¨ ì •ë³´
                "children": [],
                "related": [],
                "supersedes": None
            }
        }
        
        # 4. íŒŒì¼ ì €ì¥
        module_path = self.hte_path / module_info["full"]
        module_path.mkdir(parents=True, exist_ok=True)
        
        filepath = module_path / filename
        
        content = f"""```json
{json.dumps(holon, ensure_ascii=False, indent=2)}
```

---

# ğŸ“„ {info['title']}

## ì›ë³¸ ë‚´ìš©

{text}

---

## ìë™ ë¶„ì„ ê²°ê³¼

- **ëª¨ë“ˆ**: {module_info['full']} - {module_info['desc']}
- **ì‹ ë¢°ë„**: {confidence:.0%}
- **ë§¤ì¹­ í‚¤ì›Œë“œ**: {', '.join(analysis['matched']) or 'ì—†ìŒ'}

### ì¶”ì¶œëœ ê²°ì • ì‚¬í•­
{chr(10).join(f"- {d}" for d in info['decisions']) if info['decisions'] else "- (ì—†ìŒ)"}

### ì¶”ì¶œëœ í• ì¼
{chr(10).join(f"- [ ] {t}" for t in info['tasks']) if info['tasks'] else "- (ì—†ìŒ)"}

---

*ğŸ”¥ Holarchy ìë™ ë°°ì¹˜ ì‹œìŠ¤í…œìœ¼ë¡œ ìƒì„±ë¨ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)*
*íŒŒì¼ ì½”ë“œ: {module_id}_P{p_num:02d}_T{t_num:02d}*
*ë¶€ëª¨: [{self._shorten_parent_id(parent_id) if parent_id else "ROOT"}]*
"""
        
        filepath.write_text(content, encoding="utf-8")
        
        # ìë™ íƒœê¹… ì ìš©
        tags_applied = {}
        try:
            from _auto_tagger import AutoTagger
            tagger = AutoTagger(str(self.base_path / "0 Docs" / "holons"))
            tags = tagger.tag_document(filepath)
            if tags:
                tags_applied = tags.to_dict()
                print(f"ğŸ·ï¸ íƒœê·¸ ì ìš©: {list(tags_applied.get('module', []))[:2]} + {list(tags_applied.get('topic', []))[:2]}...")
        except Exception as e:
            print(f"âš ï¸ ìë™ íƒœê¹… ì‹¤íŒ¨: {e}")
        
        print(f"âœ… íŒŒì¼ ìƒì„± ì™„ë£Œ!")
        print(f"   ê²½ë¡œ: {filepath}")
        print()
        
        return {
            "success": True,
            "holon_id": holon_id,
            "module": module_info["full"],
            "filename": filename,
            "filepath": str(filepath),
            "confidence": confidence,
            "matched_keywords": analysis["matched"],
            "title": info["title"],
            "decisions": info["decisions"],
            "tags": tags_applied,
            "tasks": info["tasks"],
            "parent_id": parent_id,  # í•˜ì´ë¸Œë¦¬ë“œ: ë¶€ëª¨ ì •ë³´ ë°˜í™˜
            "parent_short": self._shorten_parent_id(parent_id) if parent_id else "ROOT"
        }


def main():
    """í…ŒìŠ¤íŠ¸"""
    sample = """# AI íŠœí„° ê°ì • ì—”ì§„ ì„¤ê³„ íšŒì˜

ì¼ì‹œ: 2025-11-30
ì°¸ì„ì: ê¹€ì² ìˆ˜, ì´ì˜í¬

## ì•ˆê±´
1. AI íŠœí„°ì˜ ê°ì • ì¸ì‹ ê¸°ëŠ¥
2. í•™ìƒ ë°˜ì‘ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜

## ë…¼ì˜ ë‚´ìš©
ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸ì„ ì ìš©í•˜ê¸°ë¡œ í•¨.
LLMì„ í™œìš©í•œ ëŒ€í™” ë¶„ì„ë„ ë³‘í–‰.

## ê²°ì • ì‚¬í•­
- ê²°ì •: TensorFlow ê¸°ë°˜ ê°ì • ëª¨ë¸ ê°œë°œ
- ê²°ì •: í•™ìƒ í‘œì • ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€

## í• ì¼
- TODO: ê¹€ì² ìˆ˜ - ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ê³„
- TODO: ì´ì˜í¬ - í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
"""
    
    placer = DocumentPlacer()
    result = placer.create_document(sample)
    print()
    print("ê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

