#!/usr/bin/env python3
"""
ğŸ”¬ Meta-Research Engine - ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì—°êµ¬í•˜ëŠ” ë©”íƒ€ ì—°êµ¬ ì‹œìŠ¤í…œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í•µì‹¬ ì›ë¦¬:
- Layer 1: Research Engine (í”„ë¡œì íŠ¸ ìƒì„±/ìˆ˜ì •/ê°€ì„¤/ë¶„ì„)
- Layer 2: Meta-Research Engine (í”„ë¡œì íŠ¸ ê°„ ê´€ê³„ ë¶„ì„, í’ˆì§ˆ í‰ê°€, ì •ì œ)

5ë‹¨ê³„ íŒŒì´í”„ë¼ì¸:
1. ì‹ í˜¸ ê°ì§€ (Signal Detection)
2. ì˜ë¯¸ ë¶„ì„ & ë¶„ë¥˜ (Semantic Analysis)
3. í”„ë¡œì íŠ¸ ìƒì„±/ì§„í™” (Project Evolution)
4. ë©”íƒ€ ì—°êµ¬ ê²€ì¦Â·ì •ì œ (Meta Validation)
5. ì‚¬ëŒ ìŠ¹ì¸ (Human Approval)

ì¶œë ¥:
- similarity_matrix.json
- meta_research_report_YYYY-MM-DD.md
"""

import json
import re
import os
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict
import math

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("holarchy.meta_research_engine")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì„¤ì •
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SIMILARITY_THRESHOLD = 0.6  # ì¤‘ë³µ ì˜ì‹¬ ì„ê³„ê°’
CONFLICT_THRESHOLD = 0.4   # ì¶©ëŒ ê°€ëŠ¥ì„± ì„ê³„ê°’
DRIFT_THRESHOLD = 0.5      # drift ê°ì§€ ì„ê³„ê°’ (30% â†’ 50% ì¡°ì •)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°ì´í„° êµ¬ì¡°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class Signal:
    """í•˜ìœ„ ì •ë³´ ì‹ í˜¸"""
    type: str  # pattern, exception, drift, risk, insight, opportunity
    source_holon: str
    description: str
    severity: float  # 0.0 ~ 1.0
    detected_at: str
    related_holons: List[str] = field(default_factory=list)


@dataclass
class SimilarityPair:
    """ìœ ì‚¬ë„ ìŒ"""
    holon_a: str
    holon_b: str
    
    # ìœ ì‚¬ë„ ì ìˆ˜ë“¤
    will_similarity: float
    intention_similarity: float
    goal_similarity: float
    link_similarity: float
    overall_similarity: float
    
    # ë¶„ì„ ê²°ê³¼
    is_duplicate: bool
    is_conflicting: bool
    conflict_points: List[str] = field(default_factory=list)


@dataclass
class RefinementSuggestion:
    """ì •ì œ ì œì•ˆ"""
    action: str  # merge, derive_new, archive, split, redirect
    targets: List[str]
    reason: str
    impact: str
    priority: int  # 1=highest, 5=lowest
    
    def to_dict(self) -> dict:
        return {
            "action": self.action,
            "targets": self.targets,
            "reason": self.reason,
            "impact": self.impact,
            "priority": self.priority
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ìœ ì‚¬ë„ ë¶„ì„ ì—”ì§„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class SimilarityAnalyzer:
    """í”„ë¡œì íŠ¸ ê°„ ìœ ì‚¬ë„ ë¶„ì„"""
    
    def __init__(self, holons: Dict[str, dict]):
        self.holons = holons
        self.matrix: Dict[str, Dict[str, float]] = {}
        self.pairs: List[SimilarityPair] = []
    
    def _tokenize(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ í† í°í™”"""
        if not text:
            return set()
        tokens = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\d+', text.lower())
        return {t for t in tokens if len(t) >= 2}
    
    def _jaccard_similarity(self, set_a: Set[str], set_b: Set[str]) -> float:
        """Jaccard ìœ ì‚¬ë„"""
        if not set_a or not set_b:
            return 0.0
        intersection = len(set_a & set_b)
        union = len(set_a | set_b)
        return intersection / union if union > 0 else 0.0
    
    def _extract_will_tokens(self, holon: dict) -> Set[str]:
        """W.willì—ì„œ í† í° ì¶”ì¶œ"""
        tokens = set()
        w = holon.get("W", {})
        will = w.get("will", {})
        
        if isinstance(will, dict):
            for key in ["drive", "commitment"]:
                tokens.update(self._tokenize(will.get(key, "")))
            for item in will.get("non_negotiables", []):
                tokens.update(self._tokenize(item))
        elif isinstance(will, str):
            tokens.update(self._tokenize(will))
        
        return tokens
    
    def _extract_intention_tokens(self, holon: dict) -> Set[str]:
        """W.intentionì—ì„œ í† í° ì¶”ì¶œ"""
        tokens = set()
        w = holon.get("W", {})
        intention = w.get("intention", {})
        
        if isinstance(intention, dict):
            tokens.update(self._tokenize(intention.get("primary", "")))
            for item in intention.get("secondary", []):
                tokens.update(self._tokenize(item))
        
        return tokens
    
    def _extract_goal_tokens(self, holon: dict) -> Set[str]:
        """W.goalì—ì„œ í† í° ì¶”ì¶œ"""
        tokens = set()
        w = holon.get("W", {})
        goal = w.get("goal", {})
        
        if isinstance(goal, dict):
            tokens.update(self._tokenize(goal.get("ultimate", "")))
            for item in goal.get("milestones", []):
                tokens.update(self._tokenize(item))
            for item in goal.get("kpi", []):
                tokens.update(self._tokenize(item))
        
        return tokens
    
    def _get_links(self, holon: dict) -> Set[str]:
        """ë§í¬ ì¶”ì¶œ"""
        links = set()
        link_section = holon.get("links", {})
        
        for key in ["parent", "children", "related", "spawned_from"]:
            value = link_section.get(key)
            if isinstance(value, str) and value:
                links.add(value)
            elif isinstance(value, list):
                links.update([v for v in value if v])
        
        return links
    
    def calculate_similarity(self, holon_a_id: str, holon_b_id: str) -> SimilarityPair:
        """ë‘ Holon ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
        holon_a = self.holons[holon_a_id]
        holon_b = self.holons[holon_b_id]
        
        # ê° ì˜ì—­ë³„ ìœ ì‚¬ë„
        will_sim = self._jaccard_similarity(
            self._extract_will_tokens(holon_a),
            self._extract_will_tokens(holon_b)
        )
        
        intention_sim = self._jaccard_similarity(
            self._extract_intention_tokens(holon_a),
            self._extract_intention_tokens(holon_b)
        )
        
        goal_sim = self._jaccard_similarity(
            self._extract_goal_tokens(holon_a),
            self._extract_goal_tokens(holon_b)
        )
        
        link_sim = self._jaccard_similarity(
            self._get_links(holon_a),
            self._get_links(holon_b)
        )
        
        # ì¢…í•© ìœ ì‚¬ë„ (ê°€ì¤‘ í‰ê· )
        overall = (
            will_sim * 0.35 +
            intention_sim * 0.25 +
            goal_sim * 0.25 +
            link_sim * 0.15
        )
        
        # ì¤‘ë³µ/ì¶©ëŒ íŒë‹¨
        is_duplicate = overall >= SIMILARITY_THRESHOLD
        
        # ì¶©ëŒ ê°ì§€ (ìœ ì‚¬í•˜ì§€ë§Œ ëª©í‘œê°€ ë‹¤ë¥¸ ê²½ìš°)
        is_conflicting = (will_sim > 0.5 and goal_sim < 0.3) or \
                        (intention_sim > 0.5 and goal_sim < 0.3)
        
        conflict_points = []
        if is_conflicting:
            if will_sim > 0.5 and goal_sim < 0.3:
                conflict_points.append("Willì€ ìœ ì‚¬í•˜ë‚˜ Goalì´ ë‹¤ë¦„")
            if intention_sim > 0.5 and goal_sim < 0.3:
                conflict_points.append("Intentionì€ ìœ ì‚¬í•˜ë‚˜ Goalì´ ë‹¤ë¦„")
        
        return SimilarityPair(
            holon_a=holon_a_id,
            holon_b=holon_b_id,
            will_similarity=will_sim,
            intention_similarity=intention_sim,
            goal_similarity=goal_sim,
            link_similarity=link_sim,
            overall_similarity=overall,
            is_duplicate=is_duplicate,
            is_conflicting=is_conflicting,
            conflict_points=conflict_points
        )
    
    def build_matrix(self) -> Dict[str, Dict[str, float]]:
        """ì „ì²´ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì¶•"""
        holon_ids = list(self.holons.keys())
        self.matrix = {h: {} for h in holon_ids}
        self.pairs = []
        
        for i, id_a in enumerate(holon_ids):
            for id_b in holon_ids[i+1:]:
                pair = self.calculate_similarity(id_a, id_b)
                self.pairs.append(pair)
                self.matrix[id_a][id_b] = pair.overall_similarity
                self.matrix[id_b][id_a] = pair.overall_similarity
        
        return self.matrix
    
    def get_duplicates(self) -> List[SimilarityPair]:
        """ì¤‘ë³µ ì˜ì‹¬ ìŒ ë°˜í™˜"""
        return [p for p in self.pairs if p.is_duplicate]
    
    def get_conflicts(self) -> List[SimilarityPair]:
        """ì¶©ëŒ ìŒ ë°˜í™˜"""
        return [p for p in self.pairs if p.is_conflicting]


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Drift ë¶„ì„ ì—”ì§„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class DriftAnalyzer:
    """ìƒìœ„ í—Œë²•ê³¼ì˜ alignment ë¶„ì„ ë° drift ê°ì§€"""
    
    def __init__(self, holons: Dict[str, dict], root_w: dict):
        self.holons = holons
        self.root_w = root_w
        self.root_keywords = self._extract_root_keywords()
    
    def _tokenize(self, text: str) -> Set[str]:
        if not text:
            return set()
        tokens = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\d+', text.lower())
        return {t for t in tokens if len(t) >= 2}
    
    def _extract_root_keywords(self) -> Set[str]:
        """Root Wì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = set()
        
        will = self.root_w.get("will", {})
        if isinstance(will, dict):
            keywords.update(self._tokenize(will.get("drive", "")))
            keywords.update(self._tokenize(will.get("commitment", "")))
        
        goal = self.root_w.get("goal", {})
        if isinstance(goal, dict):
            keywords.update(self._tokenize(goal.get("ultimate", "")))
        
        return keywords
    
    def calculate_drift(self, holon: dict) -> Tuple[float, List[str]]:
        """
        Holonì˜ drift ì ìˆ˜ ê³„ì‚°
        
        Returns:
            (drift_score, missing_keywords)
            drift_scoreê°€ ë†’ì„ìˆ˜ë¡ ìƒìœ„ í—Œë²•ì—ì„œ ë²—ì–´ë‚¨
        """
        w = holon.get("W", {})
        will = w.get("will", {})
        
        holon_keywords = set()
        if isinstance(will, dict):
            holon_keywords.update(self._tokenize(will.get("drive", "")))
        
        if not self.root_keywords:
            return 0.0, []
        
        # ê³µí†µ í‚¤ì›Œë“œ
        common = holon_keywords & self.root_keywords
        coverage = len(common) / len(self.root_keywords)
        
        # drift = 1 - coverage (coverageê°€ ë‚®ì„ìˆ˜ë¡ driftê°€ ë†’ìŒ)
        drift_score = 1 - coverage
        
        # ëˆ„ë½ëœ í•µì‹¬ í‚¤ì›Œë“œ
        missing = list(self.root_keywords - holon_keywords)[:5]
        
        return drift_score, missing
    
    def analyze_all(self) -> Dict[str, Tuple[float, List[str]]]:
        """ëª¨ë“  Holonì˜ drift ë¶„ì„"""
        results = {}
        for holon_id, holon in self.holons.items():
            results[holon_id] = self.calculate_drift(holon)
        return results


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í’ˆì§ˆ ê²€ì‚¬ ì—”ì§„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class QualityInspector:
    """ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ í’ˆì§ˆ ê²€ì‚¬"""
    
    def __init__(self, holons: Dict[str, dict]):
        self.holons = holons
    
    def check_problem_definition(self, holon: dict) -> Tuple[bool, str]:
        """ë¬¸ì œ ì •ì˜ ì ì ˆì„± ê²€ì‚¬"""
        x = holon.get("X", {})
        
        # X.problem ë˜ëŠ” X.context í™•ì¸
        problem = x.get("problem", "") or x.get("context", "")
        
        if not problem or problem.startswith("["):
            return False, "ë¬¸ì œ ì •ì˜ê°€ ë¹„ì–´ìˆê±°ë‚˜ í”Œë ˆì´ìŠ¤í™€ë”"
        
        if len(problem) < 20:
            return False, "ë¬¸ì œ ì •ì˜ê°€ ë„ˆë¬´ ì§§ìŒ"
        
        return True, "OK"
    
    def check_reasoning_structure(self, holon: dict) -> Tuple[bool, str]:
        """ê·¼ê±° êµ¬ì¡° ì¶©ì¡±ì„± ê²€ì‚¬"""
        s = holon.get("S", {})
        
        # S ì„¹ì…˜ì— í•µì‹¬ ìš”ì†Œê°€ ìˆëŠ”ì§€
        has_structure = any([
            s.get("core_components"),
            s.get("key_variables"),
            s.get("constraints")
        ])
        
        if not has_structure:
            return False, "S ì„¹ì…˜ì— ê·¼ê±° êµ¬ì¡° ì—†ìŒ"
        
        return True, "OK"
    
    def check_hypothesis_flow(self, holon: dict) -> Tuple[bool, str]:
        """ê°€ì„¤ ìƒì„± íë¦„ ê²€ì‚¬"""
        # W â†’ X â†’ P íë¦„ì´ ë…¼ë¦¬ì ì¸ì§€
        w = holon.get("W", {})
        x = holon.get("X", {})
        p = holon.get("P", {})
        
        has_will = bool(w.get("will"))
        has_context = bool(x.get("context") or x.get("problem"))
        has_process = bool(p.get("procedure_steps") or p.get("workflow"))
        
        if not all([has_will, has_context, has_process]):
            return False, "Wâ†’Xâ†’P íë¦„ì´ ë¶ˆì™„ì „"
        
        return True, "OK"
    
    def check_causality(self, holon: dict) -> Tuple[bool, str]:
        """ì¸ê³¼ê´€ê³„ ì™œê³¡ ê²€ì‚¬ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)"""
        # Eì˜ ì‹¤í–‰ ê³„íšì´ Pì˜ ì ˆì°¨ì™€ ì—°ê²°ë˜ëŠ”ì§€
        p = holon.get("P", {})
        e = holon.get("E", {})
        
        procedure = p.get("procedure_steps", [])
        execution = e.get("execution_plan", [])
        
        if procedure and not execution:
            return False, "ì ˆì°¨(P)ëŠ” ìˆìœ¼ë‚˜ ì‹¤í–‰(E)ì´ ë¹„ì–´ìˆìŒ"
        
        return True, "OK"
    
    def inspect(self, holon_id: str) -> Dict[str, Tuple[bool, str]]:
        """Holon í’ˆì§ˆ ê²€ì‚¬"""
        holon = self.holons.get(holon_id, {})
        
        return {
            "problem_definition": self.check_problem_definition(holon),
            "reasoning_structure": self.check_reasoning_structure(holon),
            "hypothesis_flow": self.check_hypothesis_flow(holon),
            "causality": self.check_causality(holon)
        }
    
    def inspect_all(self) -> Dict[str, Dict[str, Tuple[bool, str]]]:
        """ëª¨ë“  Holon í’ˆì§ˆ ê²€ì‚¬"""
        return {hid: self.inspect(hid) for hid in self.holons}


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì •ì œ ì œì•ˆ ì—”ì§„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class RefinementEngine:
    """ì •ì œ/í†µí•© ì œì•ˆ ìƒì„±"""
    
    def __init__(self, similarity_analyzer: SimilarityAnalyzer, 
                 drift_analyzer: DriftAnalyzer,
                 quality_inspector: QualityInspector):
        self.similarity = similarity_analyzer
        self.drift = drift_analyzer
        self.quality = quality_inspector
        self.suggestions: List[RefinementSuggestion] = []
    
    def generate_suggestions(self) -> List[RefinementSuggestion]:
        """ì •ì œ ì œì•ˆ ìƒì„±"""
        self.suggestions = []
        
        # 1. ì¤‘ë³µ ë¬¸ì„œ ë³‘í•© ì œì•ˆ
        for pair in self.similarity.get_duplicates():
            self.suggestions.append(RefinementSuggestion(
                action="merge",
                targets=[pair.holon_a, pair.holon_b],
                reason=f"ìœ ì‚¬ë„ {pair.overall_similarity:.0%} - ì¤‘ë³µ ì˜ì‹¬",
                impact="ë¬¸ì„œ ìˆ˜ ê°ì†Œ, ìœ ì§€ë³´ìˆ˜ ë¹„ìš© ì ˆê°",
                priority=2
            ))
        
        # 2. ì¶©ëŒ ë¬¸ì„œ ì¬ì •ì˜ ì œì•ˆ
        for pair in self.similarity.get_conflicts():
            self.suggestions.append(RefinementSuggestion(
                action="redirect",
                targets=[pair.holon_a, pair.holon_b],
                reason=f"ì¶©ëŒ: {', '.join(pair.conflict_points)}",
                impact="ëª©í‘œ ëª…í™•í™”, í˜¼ì„  ë°©ì§€",
                priority=1
            ))
        
        # 3. Driftê°€ ë†’ì€ ë¬¸ì„œ ì¬ì •ë ¬ ì œì•ˆ
        drift_results = self.drift.analyze_all()
        for holon_id, (drift_score, missing) in drift_results.items():
            if drift_score > DRIFT_THRESHOLD:
                self.suggestions.append(RefinementSuggestion(
                    action="redirect",
                    targets=[holon_id],
                    reason=f"Drift {drift_score:.0%} - ìƒìœ„ í—Œë²•ê³¼ ë¶ˆì¼ì¹˜",
                    impact=f"ëˆ„ë½ í‚¤ì›Œë“œ: {', '.join(missing[:3])}",
                    priority=3
                ))
        
        # 4. í’ˆì§ˆ ë¯¸ë‹¬ ë¬¸ì„œ ê°œì„  ì œì•ˆ
        quality_results = self.quality.inspect_all()
        for holon_id, checks in quality_results.items():
            failed_checks = [k for k, (passed, _) in checks.items() if not passed]
            if failed_checks:
                self.suggestions.append(RefinementSuggestion(
                    action="derive_new",
                    targets=[holon_id],
                    reason=f"í’ˆì§ˆ ë¯¸ë‹¬: {', '.join(failed_checks)}",
                    impact="ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ í’ˆì§ˆ í–¥ìƒ",
                    priority=4
                ))
        
        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        self.suggestions.sort(key=lambda x: x.priority)
        
        return self.suggestions


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë©”íƒ€ ì—°êµ¬ ì—”ì§„ (í†µí•©)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class MetaResearchEngine:
    """ë©”íƒ€ ì—°êµ¬ ì—”ì§„ - ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì—°êµ¬"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.holons_path = self.base_path / "holons"
        self.reports_path = self.base_path / "reports"
        
        self.holons: Dict[str, dict] = {}
        self.root_w: dict = {}
        
        # ì„œë¸Œ ì—”ì§„ë“¤
        self.similarity_analyzer: Optional[SimilarityAnalyzer] = None
        self.drift_analyzer: Optional[DriftAnalyzer] = None
        self.quality_inspector: Optional[QualityInspector] = None
        self.refinement_engine: Optional[RefinementEngine] = None
    
    def load_holons(self) -> None:
        """ëª¨ë“  Holon ë¡œë“œ"""
        for md_file in self.holons_path.glob("*.md"):
            if md_file.name.startswith("_"):
                continue
            
            content = md_file.read_text(encoding="utf-8")
            json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
            
            if json_match:
                try:
                    holon = json.loads(json_match.group(1))
                    holon_id = holon.get("holon_id", md_file.stem)
                    self.holons[holon_id] = holon
                except json.JSONDecodeError as e:
                    logger.debug(f"Holon JSON íŒŒì‹± ì‹¤íŒ¨ [{md_file.name}]: {e}")
    
    def find_root_w(self) -> dict:
        """ë£¨íŠ¸ W ì°¾ê¸°"""
        for holon_id, holon in self.holons.items():
            if holon.get("type") == "strategy":
                return holon.get("W", {})
        
        if "hte-doc-000" in self.holons:
            return self.holons["hte-doc-000"].get("W", {})
        
        for holon in self.holons.values():
            return holon.get("W", {})
        
        return {}
    
    def run_analysis(self) -> dict:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("=" * 70)
        print("ğŸ”¬ Meta-Research Engine v1.0")
        print("   ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì—°êµ¬í•˜ëŠ” ë©”íƒ€ ì—°êµ¬ ì‹œìŠ¤í…œ")
        print("=" * 70)
        print()
        
        # Step 1: ë°ì´í„° ë¡œë“œ
        print("ğŸ“‚ Step 1: í”„ë¡œì íŠ¸ ìŠ¤ìº”...")
        self.load_holons()
        self.root_w = self.find_root_w()
        print(f"   ë¡œë“œëœ ë¬¸ì„œ: {len(self.holons)}ê°œ")
        print()
        
        # Step 2: ìœ ì‚¬ë„ ë¶„ì„
        print("ğŸ”— Step 2: ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì¶•...")
        self.similarity_analyzer = SimilarityAnalyzer(self.holons)
        matrix = self.similarity_analyzer.build_matrix()
        duplicates = self.similarity_analyzer.get_duplicates()
        conflicts = self.similarity_analyzer.get_conflicts()
        print(f"   ì¤‘ë³µ ì˜ì‹¬: {len(duplicates)}ìŒ")
        print(f"   ì¶©ëŒ ê°ì§€: {len(conflicts)}ìŒ")
        print()
        
        # Step 3: Drift ë¶„ì„
        print("ğŸ“ Step 3: Drift ë¶„ì„...")
        self.drift_analyzer = DriftAnalyzer(self.holons, self.root_w)
        drift_results = self.drift_analyzer.analyze_all()
        high_drift = [h for h, (d, _) in drift_results.items() if d > DRIFT_THRESHOLD]
        print(f"   ê³ drift ë¬¸ì„œ: {len(high_drift)}ê°œ")
        print()
        
        # Step 4: í’ˆì§ˆ ê²€ì‚¬
        print("ğŸ” Step 4: í’ˆì§ˆ ê²€ì‚¬...")
        self.quality_inspector = QualityInspector(self.holons)
        quality_results = self.quality_inspector.inspect_all()
        quality_issues = sum(1 for checks in quality_results.values() 
                           if any(not passed for passed, _ in checks.values()))
        print(f"   í’ˆì§ˆ ì´ìŠˆ: {quality_issues}ê°œ")
        print()
        
        # Step 5: ì •ì œ ì œì•ˆ ìƒì„±
        print("ğŸ’¡ Step 5: ì •ì œ ì œì•ˆ ìƒì„±...")
        self.refinement_engine = RefinementEngine(
            self.similarity_analyzer,
            self.drift_analyzer,
            self.quality_inspector
        )
        suggestions = self.refinement_engine.generate_suggestions()
        print(f"   ìƒì„±ëœ ì œì•ˆ: {len(suggestions)}ê°œ")
        print()
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            "total_holons": len(self.holons),
            "duplicates": len(duplicates),
            "conflicts": len(conflicts),
            "high_drift": len(high_drift),
            "quality_issues": quality_issues,
            "suggestions": len(suggestions),
            "similarity_matrix": matrix,
            "drift_results": {h: d for h, (d, _) in drift_results.items()},
            "quality_results": quality_results,
            "refinement_suggestions": [s.to_dict() for s in suggestions]
        }
    
    def generate_report(self, analysis_result: dict) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        today = datetime.now().strftime("%Y-%m-%d")
        
        report = f"""# ğŸ”¬ Meta-Research Report

**ìƒì„±ì¼**: {today}  
**ë¶„ì„ ëŒ€ìƒ**: {analysis_result['total_holons']}ê°œ Holon

---

## ğŸ“Š ë¶„ì„ ìš”ì•½

| í•­ëª© | ìˆ˜ëŸ‰ |
|------|------|
| ì¤‘ë³µ ì˜ì‹¬ ìŒ | {analysis_result['duplicates']} |
| ì¶©ëŒ ê°ì§€ ìŒ | {analysis_result['conflicts']} |
| ê³ Drift ë¬¸ì„œ | {analysis_result['high_drift']} |
| í’ˆì§ˆ ì´ìŠˆ ë¬¸ì„œ | {analysis_result['quality_issues']} |
| ì •ì œ ì œì•ˆ | {analysis_result['suggestions']} |

---

## ğŸ”— ì¤‘ë³µ/ì¶©ëŒ ë¶„ì„

"""
        
        # ì¤‘ë³µ/ì¶©ëŒ ìƒì„¸
        for pair in self.similarity_analyzer.pairs:
            if pair.is_duplicate or pair.is_conflicting:
                status = "ğŸ”´ ì¤‘ë³µ" if pair.is_duplicate else "âš ï¸ ì¶©ëŒ"
                report += f"""### {status}: `{pair.holon_a}` â†” `{pair.holon_b}`

- **ì „ì²´ ìœ ì‚¬ë„**: {pair.overall_similarity:.0%}
- **Will ìœ ì‚¬ë„**: {pair.will_similarity:.0%}
- **Goal ìœ ì‚¬ë„**: {pair.goal_similarity:.0%}
"""
                if pair.conflict_points:
                    report += f"- **ì¶©ëŒ í¬ì¸íŠ¸**: {', '.join(pair.conflict_points)}\n"
                report += "\n"
        
        # Drift ë¶„ì„
        report += """---

## ğŸ“ Drift ë¶„ì„ (ìƒìœ„ í—Œë²•ê³¼ì˜ alignment)

| ë¬¸ì„œ | Drift ì ìˆ˜ | ìƒíƒœ |
|------|-----------|------|
"""
        drift_results = self.drift_analyzer.analyze_all()
        for holon_id, (drift, missing) in sorted(drift_results.items(), key=lambda x: -x[1][0]):
            status = "ğŸ”´ ë†’ìŒ" if drift > DRIFT_THRESHOLD else "âœ… ì •ìƒ"
            report += f"| {holon_id} | {drift:.0%} | {status} |\n"
        
        # í’ˆì§ˆ ê²€ì‚¬
        report += """
---

## ğŸ” í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼

"""
        for holon_id, checks in self.quality_inspector.inspect_all().items():
            failed = [(k, msg) for k, (passed, msg) in checks.items() if not passed]
            if failed:
                report += f"### âš ï¸ `{holon_id}`\n\n"
                for check_name, msg in failed:
                    report += f"- **{check_name}**: {msg}\n"
                report += "\n"
        
        # ì •ì œ ì œì•ˆ
        report += """---

## ğŸ’¡ ì •ì œ ì œì•ˆ (ìš°ì„ ìˆœìœ„ìˆœ)

"""
        for i, s in enumerate(self.refinement_engine.suggestions, 1):
            action_emoji = {
                "merge": "ğŸ”€",
                "redirect": "â†ªï¸",
                "derive_new": "ğŸ†•",
                "archive": "ğŸ“¦",
                "split": "âœ‚ï¸"
            }.get(s.action, "ğŸ“Œ")
            
            report += f"""### {i}. {action_emoji} {s.action.upper()}: `{', '.join(s.targets)}`

- **ì´ìœ **: {s.reason}
- **ì˜í–¥**: {s.impact}
- **ìš°ì„ ìˆœìœ„**: P{s.priority}

"""
        
        # ë‹¤ìŒ ì•¡ì…˜
        report += """---

## ğŸš€ ê¶Œì¥ ë‹¤ìŒ ì•¡ì…˜

1. ìœ„ ì œì•ˆ ê²€í†  í›„ ìŠ¹ì¸/ê±°ë¶€ ê²°ì •
2. ìŠ¹ì¸ëœ ì œì•ˆì— ëŒ€í•´ `python _cli.py meta apply` ì‹¤í–‰
3. ë³€ê²½ì‚¬í•­ ì»¤ë°‹ ë° ë¬¸ì„œ ì¬ê²€ì¦

---

> ğŸ“ ì´ ë¦¬í¬íŠ¸ëŠ” AIê°€ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ìµœì¢… íŒë‹¨ì€ ì‚¬ëŒì´ í•©ë‹ˆë‹¤.
"""
        
        return report
    
    def save_report(self, report: str) -> Path:
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        self.reports_path.mkdir(parents=True, exist_ok=True)
        
        today = datetime.now().strftime("%Y-%m-%d")
        report_file = self.reports_path / f"meta_research_report_{today}.md"
        
        report_file.write_text(report, encoding="utf-8")
        return report_file
    
    def save_matrix(self) -> Path:
        """ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì €ì¥"""
        matrix_file = self.holons_path / "_similarity_matrix.json"
        
        data = {
            "generated_at": datetime.now().isoformat(),
            "threshold": SIMILARITY_THRESHOLD,
            "matrix": self.similarity_analyzer.matrix
        }
        
        matrix_file.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        return matrix_file
    
    def print_summary(self, analysis_result: dict) -> None:
        """ì½˜ì†” ìš”ì•½ ì¶œë ¥"""
        print("=" * 70)
        print("ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 70)
        print()
        
        print(f"ğŸ“Š í†µê³„:")
        print(f"   â€¢ ì´ ë¬¸ì„œ: {analysis_result['total_holons']}ê°œ")
        print(f"   â€¢ ì¤‘ë³µ ì˜ì‹¬: {analysis_result['duplicates']}ìŒ")
        print(f"   â€¢ ì¶©ëŒ ê°ì§€: {analysis_result['conflicts']}ìŒ")
        print(f"   â€¢ ê³ Drift: {analysis_result['high_drift']}ê°œ")
        print(f"   â€¢ í’ˆì§ˆ ì´ìŠˆ: {analysis_result['quality_issues']}ê°œ")
        print()
        
        suggestions = self.refinement_engine.suggestions
        if suggestions:
            print("ğŸ’¡ ì •ì œ ì œì•ˆ (ìƒìœ„ 5ê°œ):")
            print("-" * 70)
            for i, s in enumerate(suggestions[:5], 1):
                print(f"   [{i}] {s.action.upper()}: {', '.join(s.targets)}")
                print(f"       â†’ {s.reason}")
            print()
        
        print("=" * 70)


def main():
    """CLI ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Meta-Research Engine")
    parser.add_argument("command", choices=["analyze", "report"],
                       help="ëª…ë ¹: analyze(ë¶„ì„), report(ë¦¬í¬íŠ¸ ìƒì„±)")
    
    args = parser.parse_args()
    
    script_dir = Path(__file__).parent
    engine = MetaResearchEngine(str(script_dir.parent))
    
    if args.command == "analyze":
        result = engine.run_analysis()
        engine.print_summary(result)
        
        # ë§¤íŠ¸ë¦­ìŠ¤ ì €ì¥
        matrix_file = engine.save_matrix()
        print(f"ğŸ“ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤: {matrix_file}")
        
    elif args.command == "report":
        result = engine.run_analysis()
        report = engine.generate_report(result)
        report_file = engine.save_report(report)
        
        engine.print_summary(result)
        print(f"ğŸ“„ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        print()
        print("ğŸ”” ë¦¬í¬íŠ¸ë¥¼ ê²€í† í•˜ê³  ì œì•ˆì„ ìŠ¹ì¸/ê±°ë¶€í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()

