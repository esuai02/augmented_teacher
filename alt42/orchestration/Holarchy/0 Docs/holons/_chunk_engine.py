#!/usr/bin/env python3
"""
ğŸ§  Chunk Engine - W ê¸°ë°˜ ì¤‘ìš”ë„ íŒë‹¨ ì‹œìŠ¤í…œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í•µì‹¬ ì›ë¦¬:
- W (Worldview/Will)ë¥¼ ì¤‘ìš”ë„ íŒë‹¨ì˜ ë¶ê·¹ì„±ìœ¼ë¡œ ì‚¬ìš©
- íšŒì‚¬ì˜ ì˜ì§€ì— ë¶€í•©í•˜ëŠ” ê²ƒë§Œ Chunkë¡œ ìŠ¹ê²©
- í•­ìƒ 5~7ê°œì˜ Active Chunkë§Œ ìœ ì§€ (ì¸ê°„ ì‘ì—…ê¸°ì–µ ëª¨ë°©)

ì•Œê³ ë¦¬ì¦˜:
1. ì „ì²´ Holon ëª©ë¡ ê²€ìƒ‰ (Raw Pool)
2. í›„ë³´êµ° ì¶”ì¶œ (Candidate Pool)  
3. W ê¸°ë°˜ salience score ê³„ì‚°
4. Top-K Chunk ì„ ì •
"""

import json
import re
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
import math

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("holarchy.chunk_engine")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì„¤ì •
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

MAX_ACTIVE_CHUNKS = 7  # ì¸ê°„ ì‘ì—…ê¸°ì–µ ìš©ëŸ‰
MIN_SALIENCE_THRESHOLD = 0.3  # ìµœì†Œ ì¤‘ìš”ë„ ì„ê³„ê°’

# ê°€ì¤‘ì¹˜ ì„¤ì •
WEIGHT_WILL_RESONANCE = 0.40  # W.will ê³µëª…ë„
WEIGHT_GOAL_RELEVANCE = 0.30  # W.goal ì—°ê´€ì„±
WEIGHT_INTENTION_ALIGN = 0.20  # W.intention ì •í•©ì„±
WEIGHT_RECENCY = 0.10  # ìµœê·¼ì„±


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë°ì´í„° êµ¬ì¡°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class Chunk:
    """ì‚¬ëŒì˜ 'ìƒê° í•œ ë©ì–´ë¦¬' í‘œí˜„"""
    id: str
    title: str
    why_important: str
    linked_holons: List[str]  # ê´€ë ¨ holon_id ëª©ë¡
    hypotheses: List[str]  # í˜„ì¬ ê°€ì„¤ë“¤
    next_actions: List[str]  # ë‹¤ìŒ í–‰ë™
    salience_score: float  # ì¤‘ìš”ë„ ì ìˆ˜ (0.0 ~ 1.0)
    
    # ìŠ¤ì½”ì–´ ìƒì„¸
    score_breakdown: Dict[str, float] = field(default_factory=dict)
    
    # ë©”íƒ€
    created_at: str = ""
    updated_at: str = ""
    status: str = "active"  # active, dormant, archived
    
    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "title": self.title,
            "why_important": self.why_important,
            "linked_holons": self.linked_holons,
            "hypotheses": self.hypotheses,
            "next_actions": self.next_actions,
            "salience_score": round(self.salience_score, 3),
            "score_breakdown": {k: round(v, 3) for k, v in self.score_breakdown.items()},
            "created_at": self.created_at,
            "updated_at": self.updated_at,
            "status": self.status
        }


@dataclass
class DailyEpisode:
    """í•˜ë£¨ ë‹¨ìœ„ ì—í”¼ì†Œë“œ ìš”ì•½"""
    date: str
    main_goals: List[str]
    active_chunks: List[str]  # chunk id ëª©ë¡
    key_events: List[str]
    decisions: List[str]
    lessons_learned: List[str]
    metrics_snapshot: Dict[str, any] = field(default_factory=dict)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# W ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚° ì—”ì§„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class SalienceEngine:
    """W ê¸°ë°˜ ì¤‘ìš”ë„ íŒë‹¨ ì—”ì§„"""
    
    def __init__(self, root_w: dict):
        """
        Args:
            root_w: ë£¨íŠ¸ Holonì˜ W ì„¹ì…˜ (íšŒì‚¬ì˜ í•µì‹¬ ì˜ì§€)
        """
        self.root_w = root_w
        self.will_keywords = self._extract_will_keywords()
        self.goal_kpis = self._extract_kpis()
        self.constraints = self._extract_constraints()
    
    def _extract_will_keywords(self) -> set:
        """W.willì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = set()
        
        will = self.root_w.get("will", {})
        
        # driveì—ì„œ ì¶”ì¶œ
        drive = will.get("drive", "")
        keywords.update(self._tokenize(drive))
        
        # commitmentì—ì„œ ì¶”ì¶œ
        commitment = will.get("commitment", "")
        keywords.update(self._tokenize(commitment))
        
        # non_negotiablesì—ì„œ ì¶”ì¶œ
        non_negs = will.get("non_negotiables", [])
        for item in non_negs:
            keywords.update(self._tokenize(item))
        
        # worldviewì—ì„œ ì¶”ì¶œ
        worldview = self.root_w.get("worldview", {})
        for key in ["identity", "belief", "value_system"]:
            keywords.update(self._tokenize(worldview.get(key, "")))
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {"ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë¥¼", "ì„", "ì˜", "ì—", "ë¡œ", "ìœ¼ë¡œ", "ì™€", "ê³¼", "í•˜ë‹¤", "ë˜ë‹¤", "ìˆë‹¤", "ì—†ë‹¤"}
        keywords -= stopwords
        
        return keywords
    
    def _extract_kpis(self) -> List[str]:
        """W.goalì—ì„œ KPI ì¶”ì¶œ"""
        goal = self.root_w.get("goal", {})
        kpis = goal.get("kpi", [])
        
        # OKRì˜ key_resultsë„ í¬í•¨
        okr = goal.get("okr", {})
        kpis.extend(okr.get("key_results", []))
        
        return kpis
    
    def _extract_constraints(self) -> List[str]:
        """W.intentionì—ì„œ ì œì•½ì‚¬í•­ ì¶”ì¶œ"""
        intention = self.root_w.get("intention", {})
        return intention.get("constraints", [])
    
    def _tokenize(self, text: str) -> set:
        """í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë¶„ë¦¬"""
        if not text:
            return set()
        
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
        tokens = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\d+', text.lower())
        
        # 2ê¸€ì ì´ìƒë§Œ
        return {t for t in tokens if len(t) >= 2}
    
    def calculate_salience(self, holon: dict) -> Tuple[float, Dict[str, float]]:
        """
        Holonì˜ ì¤‘ìš”ë„(salience) ì ìˆ˜ ê³„ì‚°
        
        Returns:
            (total_score, breakdown_dict)
        """
        breakdown = {}
        
        # 1. Will ê³µëª…ë„ (40%)
        will_score = self._calc_will_resonance(holon)
        breakdown["will_resonance"] = will_score
        
        # 2. Goal ì—°ê´€ì„± (30%)
        goal_score = self._calc_goal_relevance(holon)
        breakdown["goal_relevance"] = goal_score
        
        # 3. Intention ì •í•©ì„± (20%)
        intention_score = self._calc_intention_alignment(holon)
        breakdown["intention_alignment"] = intention_score
        
        # 4. ìµœê·¼ì„± (10%)
        recency_score = self._calc_recency(holon)
        breakdown["recency"] = recency_score
        
        # ê°€ì¤‘ í•©ì‚°
        total = (
            will_score * WEIGHT_WILL_RESONANCE +
            goal_score * WEIGHT_GOAL_RELEVANCE +
            intention_score * WEIGHT_INTENTION_ALIGN +
            recency_score * WEIGHT_RECENCY
        )
        
        return total, breakdown
    
    def _calc_will_resonance(self, holon: dict) -> float:
        """W.willê³¼ì˜ ê³µëª…ë„ ê³„ì‚°"""
        # Holonì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        holon_text = self._collect_holon_text(holon)
        holon_tokens = self._tokenize(holon_text)
        
        if not self.will_keywords or not holon_tokens:
            return 0.5  # ê¸°ë³¸ê°’
        
        # í‚¤ì›Œë“œ ê²¹ì¹¨ ë¹„ìœ¨
        overlap = holon_tokens & self.will_keywords
        
        # Jaccard ìœ ì‚¬ë„ ë³€í˜• (holonì´ will í‚¤ì›Œë“œë¥¼ ì–¼ë§ˆë‚˜ í¬í•¨í•˜ëŠ”ì§€)
        coverage = len(overlap) / len(self.will_keywords) if self.will_keywords else 0
        
        # ìµœì†Œ 1ê°œëŠ” ê²¹ì³ì•¼ ì˜ë¯¸ ìˆìŒ
        if len(overlap) == 0:
            return 0.1
        
        return min(1.0, coverage * 1.5)  # ì•½ê°„ ê´€ëŒ€í•˜ê²Œ
    
    def _calc_goal_relevance(self, holon: dict) -> float:
        """W.goalê³¼ì˜ ì—°ê´€ì„± ê³„ì‚°"""
        holon_text = self._collect_holon_text(holon)
        
        if not self.goal_kpis:
            return 0.5
        
        # KPI ì–¸ê¸‰ íšŸìˆ˜
        mentions = 0
        for kpi in self.goal_kpis:
            kpi_keywords = self._tokenize(kpi)
            holon_tokens = self._tokenize(holon_text)
            if kpi_keywords & holon_tokens:
                mentions += 1
        
        return min(1.0, mentions / len(self.goal_kpis) * 2)
    
    def _calc_intention_alignment(self, holon: dict) -> float:
        """W.intentionê³¼ì˜ ì •í•©ì„± (ì œì•½ ìœ„ë°˜ ì—¬ë¶€)"""
        holon_text = self._collect_holon_text(holon)
        
        if not self.constraints:
            return 1.0  # ì œì•½ ì—†ìœ¼ë©´ í†µê³¼
        
        # ì œì•½ ìœ„ë°˜ í‚¤ì›Œë“œ ì²´í¬ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì˜ë¯¸ë¡ ì  ë¶„ì„ í•„ìš”
        violations = 0
        for constraint in self.constraints:
            # "í•˜ì§€ ì•ŠëŠ”ë‹¤", "ê¸ˆì§€" ë“±ì˜ ë¶€ì • íŒ¨í„´ í™•ì¸
            if any(neg in constraint for neg in ["ì•Š", "ê¸ˆì§€", "ì œì™¸", "ë¶ˆê°€"]):
                # ì œì•½ì— ì–¸ê¸‰ëœ í‚¤ì›Œë“œê°€ holonì— ìˆìœ¼ë©´ ìœ„ë°˜ ê°€ëŠ¥ì„±
                constraint_keywords = self._tokenize(constraint)
                holon_tokens = self._tokenize(holon_text)
                if constraint_keywords & holon_tokens:
                    violations += 0.5
        
        return max(0.0, 1.0 - violations)
    
    def _calc_recency(self, holon: dict) -> float:
        """ìµœê·¼ì„± ì ìˆ˜ (ìµœê·¼ ìˆ˜ì •ì¼ ê¸°ì¤€)"""
        meta = holon.get("meta", {})
        updated_at = meta.get("updated_at", "")
        
        if not updated_at:
            return 0.5
        
        try:
            update_date = datetime.strptime(updated_at, "%Y-%m-%d")
            days_ago = (datetime.now() - update_date).days
            
            # 7ì¼ ì´ë‚´: 1.0, 30ì¼: 0.5, 90ì¼ ì´ìƒ: 0.1
            if days_ago <= 7:
                return 1.0
            elif days_ago <= 30:
                return 0.7
            elif days_ago <= 90:
                return 0.4
            else:
                return 0.1
        except ValueError as e:
            logger.debug(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ [recency_score]: {e}")
            return 0.5

    def _collect_holon_text(self, holon: dict) -> str:
        """Holonì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        texts = []
        
        # meta
        meta = holon.get("meta", {})
        texts.append(meta.get("title", ""))
        
        # W ì„¹ì…˜
        w = holon.get("W", {})
        for section in ["worldview", "will", "intention", "goal"]:
            section_data = w.get(section, {})
            if isinstance(section_data, dict):
                for v in section_data.values():
                    if isinstance(v, str):
                        texts.append(v)
                    elif isinstance(v, list):
                        texts.extend([str(x) for x in v])
        
        # XSPERTAì˜ will í•„ë“œë“¤
        for slot in ["X", "S", "P", "E", "R", "T", "A"]:
            slot_data = holon.get(slot, {})
            if isinstance(slot_data, dict):
                texts.append(slot_data.get("will", ""))
        
        return " ".join(texts)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Chunk ê´€ë¦¬ì
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class ChunkManager:
    """Active Chunk ê´€ë¦¬ (Top-K ìœ ì§€)"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.holons_path = self.base_path / "holons"
        self.chunks_file = self.holons_path / "_chunks.json"
        self.episodes_file = self.holons_path / "_episodes.json"
        
        self.holons: Dict[str, dict] = {}
        self.chunks: List[Chunk] = []
        self.root_w: dict = {}
        self.engine: Optional[SalienceEngine] = None
    
    def load_holons(self) -> None:
        """ëª¨ë“  Holon ë¡œë“œ"""
        for md_file in self.holons_path.glob("*.md"):
            if md_file.name.startswith("_"):
                continue
            
            content = md_file.read_text(encoding="utf-8")
            json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
            
            if json_match:
                try:
                    holon = json.loads(json_match.group(1))
                    holon_id = holon.get("holon_id", md_file.stem)
                    self.holons[holon_id] = holon
                except json.JSONDecodeError as e:
                    logger.debug(f"Holon JSON íŒŒì‹± ì‹¤íŒ¨ [{md_file.name}]: {e}")

    def find_root_w(self) -> dict:
        """ë£¨íŠ¸ Holonì˜ W ì°¾ê¸° (strategy ë˜ëŠ” hte-doc-000)"""
        # strategy íƒ€ì… ìš°ì„ 
        for holon_id, holon in self.holons.items():
            if holon.get("type") == "strategy":
                return holon.get("W", {})
        
        # hte-doc-000 fallback
        if "hte-doc-000" in self.holons:
            return self.holons["hte-doc-000"].get("W", {})
        
        # ì²« ë²ˆì§¸ holonì˜ W
        for holon in self.holons.values():
            return holon.get("W", {})
        
        return {}
    
    def calculate_all_salience(self) -> List[Tuple[str, float, Dict]]:
        """ëª¨ë“  Holonì˜ salience ê³„ì‚°"""
        self.root_w = self.find_root_w()
        self.engine = SalienceEngine(self.root_w)
        
        results = []
        for holon_id, holon in self.holons.items():
            score, breakdown = self.engine.calculate_salience(holon)
            results.append((holon_id, score, breakdown))
        
        # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results.sort(key=lambda x: x[1], reverse=True)
        return results
    
    def generate_chunks(self) -> List[Chunk]:
        """Top-K Chunk ìƒì„±"""
        salience_results = self.calculate_all_salience()
        
        chunks = []
        today = datetime.now().strftime("%Y-%m-%d")
        
        for i, (holon_id, score, breakdown) in enumerate(salience_results[:MAX_ACTIVE_CHUNKS]):
            if score < MIN_SALIENCE_THRESHOLD:
                continue
            
            holon = self.holons[holon_id]
            meta = holon.get("meta", {})
            w = holon.get("W", {})
            
            chunk = Chunk(
                id=f"chunk-{i+1:03d}",
                title=meta.get("title", holon_id),
                why_important=w.get("will", {}).get("drive", ""),
                linked_holons=[holon_id],
                hypotheses=[],
                next_actions=self._extract_next_actions(holon),
                salience_score=score,
                score_breakdown=breakdown,
                created_at=today,
                updated_at=today,
                status="active"
            )
            chunks.append(chunk)
        
        self.chunks = chunks
        return chunks
    
    def _extract_next_actions(self, holon: dict) -> List[str]:
        """Holonì—ì„œ ë‹¤ìŒ í–‰ë™ ì¶”ì¶œ"""
        actions = []
        
        # E (Execution) ì„¹ì…˜ì—ì„œ ì¶”ì¶œ
        e = holon.get("E", {})
        for plan in e.get("execution_plan", []):
            if isinstance(plan, dict):
                action = plan.get("action", "")
                if action and not action.startswith("["):
                    actions.append(action)
        
        # P (Process) ì„¹ì…˜ì—ì„œ ì¶”ì¶œ
        p = holon.get("P", {})
        for step in p.get("procedure_steps", []):
            if isinstance(step, dict):
                desc = step.get("description", "")
                if desc and not desc.startswith("["):
                    actions.append(desc)
        
        return actions[:3]  # ìµœëŒ€ 3ê°œ
    
    def save_chunks(self) -> None:
        """Chunk ì €ì¥"""
        data = {
            "generated_at": datetime.now().isoformat(),
            "root_w_keywords": list(self.engine.will_keywords) if self.engine else [],
            "max_chunks": MAX_ACTIVE_CHUNKS,
            "chunks": [c.to_dict() for c in self.chunks]
        }
        
        self.chunks_file.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
    
    def load_chunks(self) -> List[Chunk]:
        """ì €ì¥ëœ Chunk ë¡œë“œ"""
        if not self.chunks_file.exists():
            return []
        
        try:
            data = json.loads(self.chunks_file.read_text(encoding="utf-8"))
            chunks = []
            for c in data.get("chunks", []):
                chunk = Chunk(
                    id=c["id"],
                    title=c["title"],
                    why_important=c["why_important"],
                    linked_holons=c["linked_holons"],
                    hypotheses=c.get("hypotheses", []),
                    next_actions=c.get("next_actions", []),
                    salience_score=c["salience_score"],
                    score_breakdown=c.get("score_breakdown", {}),
                    created_at=c.get("created_at", ""),
                    updated_at=c.get("updated_at", ""),
                    status=c.get("status", "active")
                )
                chunks.append(chunk)
            return chunks
        except (json.JSONDecodeError, FileNotFoundError, UnicodeDecodeError) as e:
            logger.debug(f"Chunks íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def print_report(self) -> None:
        """ì˜¤ëŠ˜ì˜ ë¨¸ë¦¿ì† ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("=" * 70)
        print("ğŸ§  ì˜¤ëŠ˜ íšŒì‚¬ ë¨¸ë¦¿ì† (Active Chunks)")
        print("=" * 70)
        print()
        
        if not self.chunks:
            print("âŒ Active Chunk ì—†ìŒ")
            return
        
        # Root W ìš”ì•½
        if self.root_w:
            will = self.root_w.get("will", {})
            drive = will.get("drive", "")
            if drive:
                print(f"ğŸ¯ í•µì‹¬ ì˜ì§€: {drive[:60]}...")
                print()
        
        # Chunk ì¹´ë“œë“¤
        print(f"ğŸ“‹ Active Chunks ({len(self.chunks)}/{MAX_ACTIVE_CHUNKS}):")
        print("-" * 70)
        
        for i, chunk in enumerate(self.chunks, 1):
            status_icon = "ğŸ”¥" if chunk.salience_score >= 0.7 else "ğŸ“Œ" if chunk.salience_score >= 0.5 else "ğŸ“"
            
            print(f"\n{status_icon} [{i}] {chunk.title}")
            print(f"    ì¤‘ìš”ë„: {chunk.salience_score:.0%}")
            print(f"    ì´ìœ : {chunk.why_important[:50]}..." if len(chunk.why_important) > 50 else f"    ì´ìœ : {chunk.why_important}")
            
            # ìŠ¤ì½”ì–´ ìƒì„¸
            bd = chunk.score_breakdown
            print(f"    ì ìˆ˜: Will {bd.get('will_resonance', 0):.0%} | Goal {bd.get('goal_relevance', 0):.0%} | Intent {bd.get('intention_alignment', 0):.0%}")
            
            # ë‹¤ìŒ í–‰ë™
            if chunk.next_actions:
                print(f"    ë‹¤ìŒ: {chunk.next_actions[0]}" if chunk.next_actions else "")
        
        print()
        print("-" * 70)
        print(f"â„¹ï¸  W ê¸°ë°˜ ì¤‘ìš”ë„ íŒë‹¨ (Top-{MAX_ACTIVE_CHUNKS} ìœ ì§€)")
        print("=" * 70)


def main():
    """CLI ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Chunk Engine - W ê¸°ë°˜ ì¤‘ìš”ë„ íŒë‹¨")
    parser.add_argument("command", choices=["generate", "show", "export"],
                       help="ëª…ë ¹: generate(ìƒì„±), show(í‘œì‹œ), export(JSON ë‚´ë³´ë‚´ê¸°)")
    
    args = parser.parse_args()
    
    script_dir = Path(__file__).parent
    manager = ChunkManager(str(script_dir.parent))
    
    if args.command == "generate":
        print("ğŸ“‚ Holon ë¡œë“œ ì¤‘...")
        manager.load_holons()
        print(f"   ë¡œë“œëœ ë¬¸ì„œ: {len(manager.holons)}ê°œ")
        print()
        
        print("ğŸ§® Salience ê³„ì‚° ì¤‘...")
        manager.generate_chunks()
        manager.save_chunks()
        print(f"   ìƒì„±ëœ Chunk: {len(manager.chunks)}ê°œ")
        print()
        
        manager.print_report()
        
    elif args.command == "show":
        manager.load_holons()
        chunks = manager.load_chunks()
        if chunks:
            manager.chunks = chunks
            manager.root_w = manager.find_root_w()
            manager.print_report()
        else:
            print("âŒ ì €ì¥ëœ Chunk ì—†ìŒ. 'generate' ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    
    elif args.command == "export":
        chunks = manager.load_chunks()
        if chunks:
            print(json.dumps([c.to_dict() for c in chunks], ensure_ascii=False, indent=2))
        else:
            print("[]")


if __name__ == "__main__":
    main()

