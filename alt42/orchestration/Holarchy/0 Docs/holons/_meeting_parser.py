#!/usr/bin/env python3
"""
ğŸ”¥ íšŒì˜ë¡ ìë™ íŒŒì‹± & Holon ìƒì„±ê¸°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ê¸°ëŠ¥:
- íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ Holon ë¬¸ì„œ ìƒì„±
- ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ parent ìë™ ì„ íƒ
- Decision, Task í•­ëª© ìë™ ì¶”ì¶œ
"""

import json
import re
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("holarchy.meeting_parser")


class MeetingParser:
    """íšŒì˜ë¡ íŒŒì‹± ë° Holon ìë™ ìƒì„±"""
    
    # í‚¤ì›Œë“œ â†’ parent ë§¤í•‘ (ê¸°ë³¸)
    KEYWORD_PARENT_MAP = {
        # ì œí’ˆ/ê¸°ìˆ  ê´€ë ¨
        "api": "hte-doc-005",
        "ì‹œìŠ¤í…œ": "hte-doc-002",
        "ì•„í‚¤í…ì²˜": "hte-doc-002",
        "ì œí’ˆ": "hte-doc-002",
        "ê¸°ëŠ¥": "hte-doc-002",
        "ê°œë°œ": "hte-doc-002",
        
        # ì¡°ì§ ê´€ë ¨
        "ì¡°ì§": "hte-doc-001",
        "íŒ€": "hte-doc-001",
        "ì¸ì‚¬": "hte-doc-001",
        "ì±„ìš©": "hte-doc-001",
        
        # ì „ëµ ê´€ë ¨
        "ì „ëµ": "hte-doc-003",
        "ìš´ì˜": "hte-doc-003",
        "í”„ë¡œì„¸ìŠ¤": "hte-doc-003",
        
        # íˆ¬ì/ì¬ë¬´
        "íˆ¬ì": "hte-doc-004",
        "ì¬ë¬´": "hte-doc-004",
        "ë¹„ìš©": "hte-doc-004",
        "ì˜ˆì‚°": "hte-doc-004",
        
        # AI/PM
        "ai": "strategy-2025-001",
        "pm": "strategy-2025-001",
        "ìë™í™”": "strategy-2025-001",
        "í•™ìƒ": "strategy-2025-001",
        "ì§„ë‹¨": "feature-2025-001",
        "ì‹œì„ ": "feature-2025-002",
        "ì§‘ì¤‘ë„": "feature-2025-002",
    }
    
    # HTE ë¯¸ì…˜ ì—ì´ì „íŠ¸ í‚¤ì›Œë“œ â†’ ëª¨ë“ˆ ë§¤í•‘
    HTE_MODULE_MAP = {
        "M00": {"name": "Astral", "keywords": ["ì „ëµ", "ì„¸ê³„ê´€", "ë¹„ì „", "ë¯¸ì…˜", "ì² í•™", "ëª©í‘œ", "ë°©í–¥"]},
        "M01": {"name": "TimeCrystal", "keywords": ["ì‹œê°„", "ê²½ì˜", "ì˜ì‚¬ê²°ì •", "ë¦¬ë”", "ì¼ì •", "ê³„íš"]},
        "M02": {"name": "TimelineGenesis", "keywords": ["ìš´ì˜", "í”„ë¡œì„¸ìŠ¤", "ë¦¬ë“¬", "íšŒì˜", "ë¯¸íŒ…", "ì ˆì°¨"]},
        "M03": {"name": "BusinessModel", "keywords": ["ë¹„ì¦ˆë‹ˆìŠ¤", "ëª¨ë¸", "ìˆ˜ìµ", "ë§¤ì¶œ", "ê°€ê²©", "ê³ ê°"]},
        "M04": {"name": "KPI_OKR", "keywords": ["kpi", "okr", "ëª©í‘œ", "ì„±ê³¼", "ì§€í‘œ", "ì¸¡ì •"]},
        "M05": {"name": "FinancialGrowth", "keywords": ["ì¬ë¬´", "íˆ¬ì", "ì˜ˆì‚°", "ë¹„ìš©", "ìê¸ˆ", "ê¸ˆìœµ"]},
        "M06": {"name": "SWOT", "keywords": ["swot", "ê°•ì ", "ì•½ì ", "ê¸°íšŒ", "ìœ„í˜‘", "ë¶„ì„"]},
        "M07": {"name": "BizWeighing", "keywords": ["ìš°ì„ ìˆœìœ„", "ë¦¬ì†ŒìŠ¤", "ë°°ë¶„", "ì§‘ì¤‘", "ì„ íƒ"]},
        "M08": {"name": "InternalBranding", "keywords": ["ë‚´ë¶€", "ë¸Œëœë”©", "ë¬¸í™”", "ê°€ì¹˜", "ì§ì›"]},
        "M09": {"name": "VerticalDrilling", "keywords": ["í•µì‹¬", "ê¸°ìˆ ", "ê°œë°œ", "ì—°êµ¬", "ê¹Šì´", "ì „ë¬¸"]},
        "M10": {"name": "AgentGarden", "keywords": ["agent", "ì—ì´ì „íŠ¸", "holon", "í™€ë¡ ", "ìë™í™”", "ë´‡"]},
        "M11": {"name": "ServicePipeline", "keywords": ["ì„œë¹„ìŠ¤", "íŒŒì´í”„ë¼ì¸", "ë°°í¬", "ì „ë‹¬"]},
        "M12": {"name": "ExternalBranding", "keywords": ["ì™¸ë¶€", "ë§ˆì¼€íŒ…", "í™ë³´", "ê´‘ê³ ", "ë¸Œëœë“œ"]},
        "M13": {"name": "TrackGrowthEngine", "keywords": ["ì„±ì¥", "ì—”ì§„", "í™•ì¥", "ìŠ¤ì¼€ì¼", "ê·¸ë¡œìŠ¤"]},
        "M14": {"name": "CompanyOnboarding", "keywords": ["ì˜¨ë³´ë”©", "êµìœ¡", "ì‹ ì…", "ì…ì‚¬", "íŠ¸ë ˆì´ë‹"]},
        "M15": {"name": "TimeCrystalCEO", "keywords": ["ceo", "ë¦¬ë”ì‹­", "ê²½ì˜ì§„", "ëŒ€í‘œ", "ì´ê´„"]},
        "M16": {"name": "AIMindArchitecture", "keywords": ["ai", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "llm", "gpt", "íŠœí„°"]},
        "M17": {"name": "NervousSystem", "keywords": ["ì‹ ê²½", "ë°ì´í„°", "íŒŒì´í”„ë¼ì¸", "ì—°ê²°", "í†µí•©", "api"]},
        "M18": {"name": "InformationBlocks", "keywords": ["ì •ë³´", "ë¸”ë¡", "ì§€ëŠ¥", "êµ¬ì¡°", "í”„ë ˆì„ì›Œí¬"]},
        "M19": {"name": "CompanyCulture", "keywords": ["ë¬¸í™”", "ê°€ì¹˜ê´€", "ì¡°ì§ë¬¸í™”", "ë¬´ì§€ì„±"]},
        "M20": {"name": "KnowledgeCrystal", "keywords": ["ì§€ì‹", "ì¶•ì ", "ê²°ì •ì²´", "í•™ìŠµ", "ì²´ê³„"]},
        "M21": {"name": "SoftwareBackbone", "keywords": ["ì†Œí”„íŠ¸ì›¨ì–´", "ë°±ë³¸", "ì¸í”„ë¼", "ì‹œìŠ¤í…œ", "ì„œë²„"]},
    }
    
    # Decision/Task ì¶”ì¶œ íŒ¨í„´ (í™•ì¥)
    DECISION_PATTERNS = [
        r"ê²°ì •[:\s]*(.+?)(?:\n|$)",
        r"í•©ì˜[:\s]*(.+?)(?:\n|$)",
        r"í™•ì •[:\s]*(.+?)(?:\n|$)",
        r"â†’\s*ê²°ì •[:\s]*(.+?)(?:\n|$)",
        r"ê²°ë¡ [:\s]*(.+?)(?:\n|$)",
        r"(.+?)(?:ë¡œ|ìœ¼ë¡œ)\s*(?:ê²°ì •|í™•ì •|í•©ì˜)",  # "Aë¡œ ê²°ì •"
        r"(.+?)(?:í•˜ê¸°ë¡œ|í•˜ë„ë¡)\s*(?:í–ˆ|í•¨|í•˜ì˜€)",  # "Aí•˜ê¸°ë¡œ í•¨"
    ]
    
    TASK_PATTERNS = [
        r"í• ì¼[:\s]*(.+?)(?:\n|$)",
        r"TODO[:\s]*(.+?)(?:\n|$)",
        r"ì•¡ì…˜[:\s]*(.+?)(?:\n|$)",
        r"ë‹´ë‹¹[:\s]*(.+?)(?:\n|$)",
        r"â†’\s*(.+?)\s*ë‹´ë‹¹",
        r"\[\s*\]\s*(.+?)(?:\n|$)",  # [ ] ì²´í¬ë°•ìŠ¤
        r"(.+?)\s*(?:ë‹´ë‹¹|ì±…ì„)[:\s]*(\w+)",  # "A ë‹´ë‹¹: í™ê¸¸ë™"
    ]
    
    # Action íŒ¨í„´ (ê²°ì •/í• ì¼ ìë™ ê°ì§€) - í™•ì¥
    ACTION_PATTERNS = [
        r"(.+?)(?:í•´ì•¼\s*(?:í•œë‹¤|í•¨|í•©ë‹ˆë‹¤|í•´ìš”))",  # "~í•´ì•¼ í•œë‹¤"
        r"(.+?)(?:í•˜ì|í•©ì‹œë‹¤|í•´ë´ìš”)",  # "~í•˜ì"
        r"(.+?)(?:í•„ìš”(?:í•˜ë‹¤|í•¨|í•©ë‹ˆë‹¤|í•´ìš”)?)",  # "~í•„ìš”"
        r"(.+?)(?:ê°œì„ |ìˆ˜ì •|ë³´ì™„|ì¶”ê°€|ì‚­ì œ|ë³€ê²½)(?:\s*(?:í•„ìš”|ìš”ë§|ìš”ì²­|í•´ì•¼))",  # "~ê°œì„  í•„ìš”"
        r"(.+?)\s*ë²„íŠ¼\s*(?:í•„ìš”|ì¶”ê°€|ìƒì„±)",  # "ë²„íŠ¼ í•„ìš”"
        r"(.+?)(?:ì•ˆ\s*ë¨|ì•ˆë¨|ì˜¤ë¥˜|ì—ëŸ¬|ë²„ê·¸)",  # "~ì•ˆë¨", "ì˜¤ë¥˜"
        r"(?:ë¬¸ì œ|ì´ìŠˆ)[:\s]*(.+?)(?:\n|$)",  # "ë¬¸ì œ: ~"
    ]
    
    # ë²ˆí˜¸ ëª©ë¡ íŒ¨í„´
    NUMBERED_ITEM_PATTERN = r"(?:^|\n)\s*(\d+)[\.)\s]+(.+?)(?=\n\s*\d+[\.)\s]|\n\n|\Z)"
    
    def __init__(self, holons_path: str):
        self.holons_path = Path(holons_path)
        self.meetings_path = self.holons_path.parent / "meetings"
        self.decisions_path = self.holons_path.parent / "decisions"
        self.tasks_path = self.holons_path.parent / "tasks"
        
        # HTE ë¯¸ì…˜ ì—ì´ì „íŠ¸ ê²½ë¡œ
        self.hte_path = self.holons_path.parent.parent / "2 Company" / "4 HTE"
        
        # í´ë” ìƒì„±
        self.meetings_path.mkdir(exist_ok=True)
        self.decisions_path.mkdir(exist_ok=True)
        self.tasks_path.mkdir(exist_ok=True)
        
        # ê¸°ì¡´ Holon ë¡œë“œ (holons + HTE)
        self.holons = self._load_holons()
        self.hte_docs = self._load_hte_documents()
    
    def _load_holons(self) -> Dict[str, dict]:
        """ê¸°ì¡´ Holon ë¬¸ì„œ ë¡œë“œ"""
        holons = {}
        for md_file in self.holons_path.glob("*.md"):
            if md_file.name.startswith("_"):
                continue
            content = md_file.read_text(encoding="utf-8")
            json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
            if json_match:
                try:
                    holon = json.loads(json_match.group(1))
                    holon_id = holon.get("holon_id")
                    if holon_id:
                        holons[holon_id] = holon
                except json.JSONDecodeError as e:
                    logger.debug(f"Holon JSON íŒŒì‹± ì‹¤íŒ¨ [{md_file.name}]: {e}")
        return holons
    
    def _load_hte_documents(self) -> Dict[str, dict]:
        """HTE ë¯¸ì…˜ ì—ì´ì „íŠ¸ ë¬¸ì„œ ë¡œë“œ"""
        hte_docs = {}
        
        if not self.hte_path.exists():
            return hte_docs
        
        # HTE í´ë”ì˜ ëª¨ë“  HTE_*.md íŒŒì¼ ë¡œë“œ
        for md_file in self.hte_path.rglob("HTE_*.md"):
            try:
                content = md_file.read_text(encoding="utf-8")
                json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
                if json_match:
                    holon = json.loads(json_match.group(1))
                    holon_id = holon.get("holon_id")
                    if holon_id:
                        # ëª¨ë“ˆ ì •ë³´ ì¶”ê°€
                        module = holon.get("module", "")
                        hte_docs[holon_id] = {
                            **holon,
                            "_filepath": str(md_file),
                            "_module": module
                        }
            except (json.JSONDecodeError, FileNotFoundError, UnicodeDecodeError) as e:
                logger.debug(f"HTE ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨ [{md_file.name}]: {e}")
        
        return hte_docs
    
    def _search_hte_by_keywords(self, text: str) -> List[Tuple[str, float, str]]:
        """
        í‚¤ì›Œë“œë¡œ HTE ë¬¸ì„œ ê²€ìƒ‰
        
        Returns:
            [(holon_id, score, module), ...]
        """
        text_lower = text.lower()
        results = []
        
        # 1. ëª¨ë“ˆ ë ˆë²¨ ë§¤ì¹­
        for module_id, info in self.HTE_MODULE_MAP.items():
            score = 0
            matched = []
            for keyword in info["keywords"]:
                if keyword.lower() in text_lower:
                    score += 1
                    matched.append(keyword)
            
            if score > 0:
                # í•´ë‹¹ ëª¨ë“ˆì˜ ë¬¸ì„œë“¤ ê²€ìƒ‰
                module_full = f"{module_id}_{info['name']}"
                for holon_id, doc in self.hte_docs.items():
                    if module_full in doc.get("_module", ""):
                        results.append((holon_id, score / 5, module_full))
        
        # 2. ë¬¸ì„œ ì œëª©/ë‚´ìš© ë§¤ì¹­
        for holon_id, doc in self.hte_docs.items():
            title = doc.get("meta", {}).get("title", "").lower()
            drive = doc.get("W", {}).get("will", {}).get("drive", "").lower()
            
            # ì œëª©ì´ë‚˜ driveì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì ìˆ˜
            for keyword in text_lower.split()[:20]:  # ì²˜ìŒ 20ë‹¨ì–´ë§Œ
                if len(keyword) > 2:
                    if keyword in title or keyword in drive:
                        # ì´ë¯¸ ìˆìœ¼ë©´ ì ìˆ˜ ì¦ê°€
                        found = False
                        for i, (hid, score, mod) in enumerate(results):
                            if hid == holon_id:
                                results[i] = (hid, score + 0.1, mod)
                                found = True
                                break
                        if not found:
                            results.append((holon_id, 0.3, doc.get("_module", "")))
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:10]  # ìƒìœ„ 10ê°œ
    
    def _extract_title(self, text: str) -> str:
        """íšŒì˜ë¡ì—ì„œ ì œëª© ì¶”ì¶œ"""
        lines = text.strip().split("\n")
        
        # ì²« ì¤„ì´ ì œëª©ì¼ ê°€ëŠ¥ì„±
        first_line = lines[0].strip()
        
        # # ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ë§ˆí¬ë‹¤ìš´ ì œëª©
        if first_line.startswith("#"):
            return first_line.lstrip("#").strip()
        
        # ì œëª©: íŒ¨í„´
        title_match = re.search(r"ì œëª©[:\s]*(.+?)(?:\n|$)", text)
        if title_match:
            return title_match.group(1).strip()
        
        # íšŒì˜ëª…: íŒ¨í„´
        meeting_match = re.search(r"íšŒì˜ëª…[:\s]*(.+?)(?:\n|$)", text)
        if meeting_match:
            return meeting_match.group(1).strip()
        
        # ì²« ì¤„ ì‚¬ìš© (30ì ì œí•œ)
        return first_line[:30] if first_line else "íšŒì˜ë¡"
    
    def _extract_date(self, text: str) -> str:
        """íšŒì˜ë¡ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
        # YYYY-MM-DD íŒ¨í„´
        date_match = re.search(r"(\d{4}-\d{2}-\d{2})", text)
        if date_match:
            return date_match.group(1)
        
        # YYYY.MM.DD íŒ¨í„´
        date_match = re.search(r"(\d{4})\.(\d{2})\.(\d{2})", text)
        if date_match:
            return f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
        
        # ì˜¤ëŠ˜ ë‚ ì§œ
        return datetime.now().strftime("%Y-%m-%d")
    
    def _extract_participants(self, text: str) -> List[str]:
        """ì°¸ì„ì ì¶”ì¶œ"""
        participants = []
        
        # ì°¸ì„ì: íŒ¨í„´
        match = re.search(r"ì°¸ì„ì?[:\s]*(.+?)(?:\n|$)", text)
        if match:
            names = re.split(r"[,ï¼Œã€\s]+", match.group(1))
            participants = [n.strip() for n in names if n.strip()]
        
        return participants if participants else ["ë¯¸ì§€ì •"]
    
    def _find_best_parent(self, text: str) -> Tuple[str, float, List[Dict]]:
        """
        ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ parent ì°¾ê¸° (HTE ë¬¸ì„œ í¬í•¨)
        
        Returns:
            (parent_id, confidence, referenced_docs)
        """
        text_lower = text.lower()
        
        # 1. ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­
        scores = {}
        for keyword, parent_id in self.KEYWORD_PARENT_MAP.items():
            if keyword in text_lower:
                scores[parent_id] = scores.get(parent_id, 0) + 1
        
        # 2. HTE ë¬¸ì„œ ê²€ìƒ‰
        hte_matches = self._search_hte_by_keywords(text)
        for holon_id, score, module in hte_matches:
            # HTE ë¬¸ì„œ ì ìˆ˜ ì¶”ê°€ (ê°€ì¤‘ì¹˜ 2ë°°)
            scores[holon_id] = scores.get(holon_id, 0) + (score * 2)
        
        # ì°¸ì¡° ë¬¸ì„œ ëª©ë¡ ìƒì„±
        referenced_docs = []
        for holon_id, score, module in hte_matches[:5]:
            doc = self.hte_docs.get(holon_id, {})
            referenced_docs.append({
                "holon_id": holon_id,
                "title": doc.get("meta", {}).get("title", holon_id),
                "module": module,
                "score": score
            })
        
        if scores:
            best_parent = max(scores, key=scores.get)
            max_score = scores[best_parent]
            confidence = min(max_score / 5, 1.0)  # ìµœëŒ€ 1.0
            return best_parent, confidence, referenced_docs
        
        # ê¸°ë³¸ê°’: strategy-2025-001 (AI PM)
        return "strategy-2025-001", 0.3, referenced_docs
    
    def _extract_decisions(self, text: str) -> List[str]:
        """ê²°ì • ì‚¬í•­ ì¶”ì¶œ"""
        decisions = []
        for pattern in self.DECISION_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE)
            decisions.extend([m.strip() for m in matches if m.strip()])
        return list(set(decisions))  # ì¤‘ë³µ ì œê±°
    
    def _extract_tasks(self, text: str) -> List[str]:
        """í• ì¼ ì¶”ì¶œ"""
        tasks = []
        for pattern in self.TASK_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for m in matches:
                if isinstance(m, tuple):
                    tasks.append(' - '.join(m).strip())
                else:
                    tasks.append(m.strip())
        return list(set(t for t in tasks if t and len(t) > 3))  # ì¤‘ë³µ ì œê±°, ìµœì†Œ ê¸¸ì´
    
    def _extract_actions_from_patterns(self, text: str) -> Tuple[List[str], List[str]]:
        """
        Action íŒ¨í„´ìœ¼ë¡œ ê²°ì •/í• ì¼ ìë™ ì¶”ì¶œ
        
        Returns:
            (inferred_decisions, inferred_tasks)
        """
        inferred_decisions = []
        inferred_tasks = []
        
        for pattern in self.ACTION_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            for m in matches:
                content = m.strip() if isinstance(m, str) else m[0].strip()
                if not content or len(content) < 5:
                    continue
                
                # ë¶„ë¥˜: "í•„ìš”", "í•´ì•¼" â†’ Task, "ë¡œ ê²°ì •", "í™•ì •" â†’ Decision
                content_lower = content.lower()
                if any(kw in content_lower for kw in ['í•„ìš”', 'í•´ì•¼', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ì•ˆë¨', 'ë¬¸ì œ']):
                    inferred_tasks.append(content[:100])
                else:
                    inferred_decisions.append(content[:100])
        
        return list(set(inferred_decisions))[:5], list(set(inferred_tasks))[:5]
    
    def _extract_numbered_items(self, text: str) -> List[Dict]:
        """
        ë²ˆí˜¸ ëª©ë¡ íŒŒì‹± (1. ì²«ë²ˆì§¸, 2. ë‘ë²ˆì§¸...)
        
        Returns:
            [{"num": 1, "content": "...", "type": "issue/task/decision"}]
        """
        items = []
        matches = re.findall(self.NUMBERED_ITEM_PATTERN, text, re.DOTALL)
        
        for num, content in matches:
            content = content.strip()
            if not content:
                continue
            
            # íƒ€ì… ì¶”ë¡ 
            content_lower = content.lower()
            if any(kw in content_lower for kw in ['ì˜¤ë¥˜', 'ì—ëŸ¬', 'ë²„ê·¸', 'ì•ˆë¨', 'ë¬¸ì œ']):
                item_type = 'issue'
            elif any(kw in content_lower for kw in ['í•„ìš”', 'í•´ì•¼', 'ì¶”ê°€', 'ìˆ˜ì •']):
                item_type = 'task'
            elif any(kw in content_lower for kw in ['ê²°ì •', 'í™•ì •', 'í•©ì˜', 'ì™„ë£Œ']):
                item_type = 'decision'
            else:
                item_type = 'info'
            
            items.append({
                "num": int(num),
                "content": content[:200],
                "type": item_type
            })
        
        return items
    
    def _determine_status(self, text: str, decisions: List[str], tasks: List[str]) -> str:
        """
        ì‹¤ì œ ìƒíƒœ íŒë‹¨ (í‘œë©´ì  ìƒíƒœê°€ ì•„ë‹Œ ì‹¤ì§ˆì  ì™„ë£Œ ì—¬ë¶€)
        """
        # ê²°ì •/í• ì¼ì´ ì—†ìœ¼ë©´ ë¯¸ì™„ë£Œ
        if not decisions and not tasks:
            return "incomplete"
        
        # ë¯¸ì™„ë£Œ í‚¤ì›Œë“œ ì²´í¬
        incomplete_keywords = ['ì¶”í›„', 'ë‚˜ì¤‘ì—', 'TBD', 'ë¯¸ì •', 'ê²€í†  í•„ìš”', 'ì¶”ê°€ ë…¼ì˜']
        text_lower = text.lower()
        for kw in incomplete_keywords:
            if kw.lower() in text_lower:
                return "pending"
        
        # ì§„í–‰ì¤‘ í‚¤ì›Œë“œ ì²´í¬
        progress_keywords = ['ì§„í–‰ì¤‘', 'ì§„í–‰ ì¤‘', 'ê°œë°œì¤‘', 'ì‘ì—…ì¤‘']
        for kw in progress_keywords:
            if kw.lower() in text_lower:
                return "in_progress"
        
        return "completed"
    
    def _extract_agenda(self, text: str) -> List[str]:
        """ì•ˆê±´ ì¶”ì¶œ"""
        agenda = []
        
        # ì•ˆê±´: íŒ¨í„´
        agenda_match = re.search(r"ì•ˆê±´[:\s]*\n?((?:.+\n?)+)", text)
        if agenda_match:
            items = agenda_match.group(1).split("\n")
            for item in items:
                item = item.strip()
                if item and not item.startswith(("ì°¸ì„", "ì¼ì‹œ", "ì¥ì†Œ")):
                    # ë²ˆí˜¸/ë¶ˆë¦¿ ì œê±°
                    item = re.sub(r"^[\d\.\-\*\â€¢]+\s*", "", item)
                    if item:
                        agenda.append(item)
        
        return agenda[:5]  # ìµœëŒ€ 5ê°œ
    
    def _generate_meeting_id(self) -> str:
        """íšŒì˜ ID ìƒì„±"""
        today = datetime.now()
        year = today.strftime("%Y")
        
        # ê¸°ì¡´ meeting ê°œìˆ˜ í™•ì¸
        existing = list(self.meetings_path.glob(f"meeting-{year}-*.md"))
        next_num = len(existing) + 1
        
        return f"meeting-{year}-{next_num:03d}"
    
    def _generate_execution_plan(self, decisions: List[str], tasks: List[str], 
                                  participants: List[str]) -> List[Dict]:
        """
        ê²°ì •/í• ì¼ì—ì„œ ìƒì„¸ ì‹¤í–‰ ê³„íš ìë™ ìƒì„±
        """
        plan = []
        action_id = 1
        
        # ê²°ì •ì‚¬í•­ â†’ ì‹¤í–‰ ê³„íš
        for i, decision in enumerate(decisions[:5]):
            plan.append({
                "action_id": f"e{action_id:03d}",
                "type": "decision",
                "description": decision[:100],
                "role": participants[i % len(participants)] if participants else "ë‹´ë‹¹ì ë¯¸ì •",
                "eta": "TBD",
                "status": "pending"
            })
            action_id += 1
        
        # í• ì¼ â†’ ì‹¤í–‰ ê³„íš
        for i, task in enumerate(tasks[:5]):
            # ë‹´ë‹¹ì ì¶”ì¶œ ì‹œë„
            assignee = "ë‹´ë‹¹ì ë¯¸ì •"
            assignee_match = re.search(r"(\w+)\s*(?:ë‹´ë‹¹|ì±…ì„)", task)
            if assignee_match:
                assignee = assignee_match.group(1)
            elif participants:
                assignee = participants[i % len(participants)]
            
            plan.append({
                "action_id": f"e{action_id:03d}",
                "type": "task",
                "description": task[:100],
                "role": assignee,
                "eta": "TBD",
                "status": "pending"
            })
            action_id += 1
        
        # ê³„íšì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ í•­ëª© ì¶”ê°€
        if not plan:
            plan.append({
                "action_id": "e001",
                "type": "review",
                "description": "íšŒì˜ ë‚´ìš© ê²€í†  ë° í›„ì† ì¡°ì¹˜ ê²°ì • í•„ìš”",
                "role": participants[0] if participants else "ë‹´ë‹¹ì ë¯¸ì •",
                "eta": "TBD",
                "status": "pending"
            })
        
        return plan
    
    def _generate_procedure_steps(self, status: str, decisions: List[str], 
                                   tasks: List[str]) -> List[Dict]:
        """
        ìƒíƒœì— ë”°ë¥¸ ì ˆì°¨ ë‹¨ê³„ ìƒì„±
        """
        steps = [
            {"step_id": "p001", "description": "ì•ˆê±´ ê²€í† ", "status": "done"},
            {"step_id": "p002", "description": "ë…¼ì˜ ì§„í–‰", "status": "done"},
        ]
        
        # ê²°ì • ë„ì¶œ ìƒíƒœ
        if decisions:
            steps.append({"step_id": "p003", "description": f"ê²°ì • ë„ì¶œ ({len(decisions)}ê±´)", "status": "done"})
        else:
            steps.append({"step_id": "p003", "description": "ê²°ì • ë„ì¶œ", "status": "pending"})
        
        # í• ì¼ ë„ì¶œ ìƒíƒœ
        if tasks:
            steps.append({"step_id": "p004", "description": f"í• ì¼ ë„ì¶œ ({len(tasks)}ê±´)", "status": "done"})
        else:
            steps.append({"step_id": "p004", "description": "í• ì¼ ë„ì¶œ", "status": "pending"})
        
        # í›„ì† ì¡°ì¹˜ ìƒíƒœ
        if status == "completed":
            steps.append({"step_id": "p005", "description": "í›„ì† ì¡°ì¹˜ í™•ì •", "status": "done"})
        elif status == "in_progress":
            steps.append({"step_id": "p005", "description": "í›„ì† ì¡°ì¹˜ ì§„í–‰ ì¤‘", "status": "in_progress"})
        else:
            steps.append({"step_id": "p005", "description": "í›„ì† ì¡°ì¹˜ í•„ìš”", "status": "pending"})
        
        return steps
    
    def _generate_kpi(self, decisions: List[str], tasks: List[str], 
                      numbered_items: List[Dict]) -> List[str]:
        """
        êµ¬ì²´ì ì¸ KPI ìƒì„±
        """
        kpis = []
        
        if decisions:
            kpis.append(f"ê²°ì • ì‚¬í•­: {len(decisions)}ê±´ í™•ì •")
        else:
            kpis.append("ê²°ì • ì‚¬í•­: 0ê±´ (ì¶”ê°€ ë…¼ì˜ í•„ìš”)")
        
        if tasks:
            kpis.append(f"ì‹¤í–‰ ê³¼ì œ: {len(tasks)}ê±´ ë„ì¶œ")
        else:
            kpis.append("ì‹¤í–‰ ê³¼ì œ: 0ê±´ (ì•¡ì…˜ ì•„ì´í…œ í•„ìš”)")
        
        # ì´ìŠˆ ì¹´ìš´íŠ¸
        issues = [i for i in numbered_items if i.get("type") == "issue"]
        if issues:
            kpis.append(f"ì´ìŠˆ/ë¬¸ì œ: {len(issues)}ê±´ ì‹ë³„")
        
        return kpis
    
    def _calculate_completion_rate(self, decisions: List[str], tasks: List[str], 
                                    status: str) -> Dict:
        """
        ì™„ë£Œìœ¨ ê³„ì‚°
        """
        # ê¸°ë³¸ ì ìˆ˜ ì²´ê³„
        score = 0
        max_score = 100
        breakdown = {}
        
        # ê²°ì • ì‚¬í•­ (30ì )
        if decisions:
            decision_score = min(len(decisions) * 10, 30)
            score += decision_score
            breakdown["decisions"] = {"score": decision_score, "max": 30, "count": len(decisions)}
        else:
            breakdown["decisions"] = {"score": 0, "max": 30, "count": 0}
        
        # í• ì¼ (30ì )
        if tasks:
            task_score = min(len(tasks) * 10, 30)
            score += task_score
            breakdown["tasks"] = {"score": task_score, "max": 30, "count": len(tasks)}
        else:
            breakdown["tasks"] = {"score": 0, "max": 30, "count": 0}
        
        # ìƒíƒœ (40ì )
        status_scores = {
            "completed": 40,
            "in_progress": 20,
            "pending": 10,
            "incomplete": 0
        }
        status_score = status_scores.get(status, 0)
        score += status_score
        breakdown["status"] = {"score": status_score, "max": 40, "value": status}
        
        return {
            "total": score,
            "max": max_score,
            "percentage": round(score / max_score * 100),
            "breakdown": breakdown,
            "is_complete": score >= 70
        }
    
    def _create_meeting_holon(self, text: str) -> dict:
        """íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¡œ Meeting Holon ìƒì„±"""
        title = self._extract_title(text)
        date = self._extract_date(text)
        participants = self._extract_participants(text)
        parent_id, confidence, referenced_docs = self._find_best_parent(text)
        
        # ê¸°ë³¸ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ
        decisions = self._extract_decisions(text)
        tasks = self._extract_tasks(text)
        
        # Action íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ ì¶”ì¶œ
        inferred_decisions, inferred_tasks = self._extract_actions_from_patterns(text)
        decisions = list(set(decisions + inferred_decisions))
        tasks = list(set(tasks + inferred_tasks))
        
        # ë²ˆí˜¸ ëª©ë¡ì—ì„œ ì¶”ê°€ ì¶”ì¶œ
        numbered_items = self._extract_numbered_items(text)
        for item in numbered_items:
            if item["type"] == "issue":
                tasks.append(f"[ì´ìŠˆ #{item['num']}] {item['content'][:80]}")
            elif item["type"] == "task":
                tasks.append(f"[í•­ëª© #{item['num']}] {item['content'][:80]}")
            elif item["type"] == "decision":
                decisions.append(f"[ê²°ì • #{item['num']}] {item['content'][:80]}")
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        decisions = list(set(decisions))[:10]
        tasks = list(set(tasks))[:10]
        
        agenda = self._extract_agenda(text)
        meeting_id = self._generate_meeting_id()
        
        # ì‹¤ì œ ìƒíƒœ íŒë‹¨
        actual_status = self._determine_status(text, decisions, tasks)
        
        # Root W ê°€ì ¸ì˜¤ê¸°
        root_w = self.holons.get("hte-doc-000", {}).get("W", {})
        root_drive = root_w.get("will", {}).get("drive", "")
        
        holon = {
            "holon_id": meeting_id,
            "slug": title.replace(" ", "-").lower()[:30],
            "type": "meeting",
            "module": "M02_TimelineGenesis",
            "meta": {
                "title": title,
                "owner": participants[0] if participants else "ë¯¸ì§€ì •",
                "created_at": date,
                "updated_at": date,
                "priority": "high",
                "status": "active"
            },
            "W": {
                "worldview": {
                    "identity": "íšŒì˜ë¥¼ í†µí•´ ì˜ì‚¬ê²°ì •ê³¼ ë°©í–¥ ì •ë ¬ì„ ìˆ˜í–‰í•˜ëŠ” í˜‘ì—… ì„¸ì…˜",
                    "belief": "íš¨ê³¼ì ì¸ íšŒì˜ëŠ” ëª…í™•í•œ ê²°ì •ê³¼ ì‹¤í–‰ ê°€ëŠ¥í•œ íƒœìŠ¤í¬ë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤",
                    "value_system": "ì‹œê°„ íš¨ìœ¨, ê²°ì • ëª…í™•ì„±, ì‹¤í–‰ ì—°ê²°"
                },
                "will": {
                    "drive": f"ì´ íšŒì˜ë¥¼ í†µí•´ {title} ê´€ë ¨ ëª…í™•í•œ ê²°ì •ì„ ë‚´ë¦¬ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•œë‹¤. {root_drive[:50]}...",
                    "commitment": "ëª¨ë“  ì•ˆê±´ì— ëŒ€í•´ ê²°ë¡ ì„ ë‚´ë¦¬ê³  ë‹´ë‹¹ìë¥¼ ì§€ì •í•œë‹¤",
                    "non_negotiables": ["ê²°ì • ì‚¬í•­ ë¬¸ì„œí™”", "ë‹´ë‹¹ì ì§€ì •", "ê¸°í•œ ì„¤ì •"]
                },
                "intention": {
                    "primary": title,
                    "secondary": agenda[:3] if agenda else ["ì•ˆê±´ ë…¼ì˜"],
                    "constraints": ["ì‹œê°„ ì œí•œ", "ì°¸ì„ì ì¼ì •"]
                },
                "goal": {
                    "ultimate": f"{title} ì™„ë£Œ ë° í›„ì† ì¡°ì¹˜ í™•ì •",
                    "milestones": ["ì•ˆê±´ ë…¼ì˜", "ê²°ì •", "ì•¡ì…˜ ì•„ì´í…œ ë„ì¶œ"],
                    "kpi": self._generate_kpi(decisions, tasks, numbered_items),
                    "okr": {
                        "objective": title,
                        "key_results": decisions[:3] if decisions else ["ê²°ì • ì‚¬í•­ ë„ì¶œ"]
                    },
                    "completion_rate": self._calculate_completion_rate(decisions, tasks, actual_status)
                },
                "activation": {
                    "triggers": ["íšŒì˜ ì‹œì‘"],
                    "resonance_check": f"ìƒìœ„ ëª©í‘œ({parent_id})ì™€ ì •ë ¬ í™•ì¸ë¨ (ì‹ ë¢°ë„: {confidence:.0%})",
                    "drift_detection": "íšŒì˜ ëª©ì ì—ì„œ ë²—ì–´ë‚˜ëŠ” ë…¼ì˜ ê°ì§€"
                }
            },
            "X": {
                "context": text[:500] + "..." if len(text) > 500 else text,
                "current_state": actual_status,  # ì‹¤ì§ˆì  ìƒíƒœ ë°˜ì˜
                "numbered_items": [f"#{i['num']}: {i['content'][:50]}..." for i in numbered_items[:5]],
                "heartbeat": "once",
                "signals": ["íšŒì˜ë¡ ì‘ì„±ë¨"] + ([f"ì´ìŠˆ {len([i for i in numbered_items if i['type']=='issue'])}ê±´ ê°ì§€"] if numbered_items else []),
                "constraints": ["ì°¸ì„ì ì¼ì •", "ì‹œê°„ ì œí•œ"],
                "will": "íšŒì˜ ë§¥ë½ì„ ì •í™•íˆ ê¸°ë¡í•˜ì—¬ í›„ì† ì¡°ì¹˜ì— í™œìš©í•œë‹¤"
            },
            "S": {
                "resources": [
                    {"type": "human", "id": p, "role": "ì°¸ì„ì"} for p in participants
                ],
                "dependencies": [parent_id],
                "access_points": ["ì´ ë¬¸ì„œ"],
                "structure_model": "íšŒì˜ â†’ ê²°ì • â†’ íƒœìŠ¤í¬",
                "ontology_ref": ["M02_TimelineGenesis"],
                "readiness_score": 1.0,
                "will": "í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ë³´í•˜ì—¬ íšŒì˜ ëª©ì ì„ ë‹¬ì„±í•œë‹¤"
            },
            "P": {
                "procedure_steps": self._generate_procedure_steps(actual_status, decisions, tasks),
                "optimization_logic": "íš¨ìœ¨ì ì¸ íšŒì˜ ì§„í–‰",
                "will": "ì²´ê³„ì ì¸ ì ˆì°¨ë¡œ ìƒì‚°ì ì¸ íšŒì˜ë¥¼ ìˆ˜í–‰í•œë‹¤"
            },
            "E": {
                "execution_plan": self._generate_execution_plan(decisions, tasks, participants),
                "tooling": ["íšŒì˜ì‹¤", "í™”ìƒíšŒì˜"],
                "edge_case_handling": ["ë¶ˆì°¸ ì‹œ íšŒì˜ë¡ ê³µìœ "],
                "will": "ê²°ì •ëœ ì‚¬í•­ì„ ì‹¤ì œë¡œ ì‹¤í–‰í•œë‹¤"
            },
            "R": {
                "reflection_notes": ["íšŒì˜ ì™„ë£Œ"],
                "lessons_learned": [],
                "success_path_inference": "ëª…í™•í•œ ê²°ì • â†’ ì‹¤í–‰ â†’ ì„±ê³¼",
                "future_prediction": "í›„ì† íšŒì˜ í•„ìš” ì—¬ë¶€ íŒë‹¨",
                "will": "íšŒì˜ ê²°ê³¼ë¥¼ ë˜ëŒì•„ë³´ê³  ê°œì„ ì ì„ ì°¾ëŠ”ë‹¤"
            },
            "T": {
                "impact_channels": ["ì°¸ì„ì", "ê´€ë ¨ íŒ€"],
                "traffic_model": "íšŒì˜ë¡ ê³µìœ  â†’ ì•¡ì…˜ ì‹¤í–‰",
                "viral_mechanics": "ê²°ì • ì‚¬í•­ì˜ íŒ€ ì „íŒŒ",
                "bottleneck_points": ["ì‹¤í–‰ ì§€ì—°"],
                "will": "íšŒì˜ ê²°ê³¼ë¥¼ ê´€ë ¨ìì—ê²Œ íš¨ê³¼ì ìœ¼ë¡œ ì „íŒŒí•œë‹¤"
            },
            "A": {
                "abstraction": "ë°˜ë³µ ê°€ëŠ¥í•œ íšŒì˜ í…œí”Œë¦¿í™”",
                "modularization": ["ì•ˆê±´ ëª¨ë“ˆ", "ê²°ì • ëª¨ë“ˆ", "íƒœìŠ¤í¬ ëª¨ë“ˆ"],
                "automation_opportunities": ["íšŒì˜ë¡ ìë™ ìƒì„±", "íƒœìŠ¤í¬ ìë™ ì¶”ì¶œ"],
                "integration_targets": [parent_id],
                "resonance_logic": f"ìƒìœ„ ëª©í‘œì™€ ì •ë ¬ (ì‹ ë¢°ë„: {confidence:.0%})",
                "will": "íšŒì˜ íŒ¨í„´ì„ ê³ ë„í™”í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì¸ë‹¤"
            },
            "links": {
                "parent": parent_id,
                "children": [],
                "related": [doc["holon_id"] for doc in referenced_docs],  # HTE ì°¸ì¡° ë¬¸ì„œ
                "supersedes": None
            },
            "_parsed": {
                "decisions": decisions,
                "tasks": tasks,
                "agenda": agenda,
                "participants": participants,
                "confidence": confidence,
                "numbered_items": numbered_items,
                "actual_status": actual_status,
                "completion_rate": holon["W"]["goal"]["completion_rate"]["percentage"],
                "referenced_docs": referenced_docs  # HTE ì°¸ì¡° ë¬¸ì„œ
            }
        }
        
        return holon
    
    def parse_and_create(self, text: str, auto_spawn: bool = True) -> dict:
        """íšŒì˜ë¡ íŒŒì‹± í›„ Holon íŒŒì¼ ìƒì„±"""
        print("=" * 60)
        print("ğŸ”¥ íšŒì˜ë¡ ìë™ íŒŒì‹± & Holon ìƒì„±")
        print("=" * 60)
        print()
        
        # Meeting Holon ìƒì„±
        print("ğŸ“ íšŒì˜ë¡ ë¶„ì„ ì¤‘...")
        holon = self._create_meeting_holon(text)
        
        meeting_id = holon["holon_id"]
        title = holon["meta"]["title"]
        parent_id = holon["links"]["parent"]
        confidence = holon["_parsed"]["confidence"]
        decisions = holon["_parsed"]["decisions"]
        tasks = holon["_parsed"]["tasks"]
        
        actual_status = holon["_parsed"]["actual_status"]
        completion = holon["_parsed"]["completion_rate"]
        numbered_items = holon["_parsed"]["numbered_items"]
        
        referenced_docs = holon["_parsed"]["referenced_docs"]
        
        print(f"   ì œëª©: {title}")
        print(f"   ID: {meeting_id}")
        print(f"   ìƒìœ„ ì—°ê²°: {parent_id} (ì‹ ë¢°ë„: {confidence:.0%})")
        print(f"   ê²°ì • ì‚¬í•­: {len(decisions)}ê±´")
        print(f"   í• ì¼: {len(tasks)}ê±´")
        print(f"   ë²ˆí˜¸ í•­ëª©: {len(numbered_items)}ê±´ (ì´ìŠˆ: {len([i for i in numbered_items if i['type']=='issue'])}ê±´)")
        print(f"   ì‹¤ì œ ìƒíƒœ: {actual_status} (ì™„ë£Œìœ¨: {completion}%)")
        
        # HTE ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
        if referenced_docs:
            print(f"   ğŸ“š ì°¸ì¡°ëœ HTE ë¬¸ì„œ: {len(referenced_docs)}ê±´")
            for doc in referenced_docs[:3]:
                print(f"      â””â”€ {doc['module']}: {doc['title'][:30]}... ({doc['score']:.0%})")
        print()
        
        # _parsed ì œê±° í›„ ì €ì¥
        parsed_info = holon.pop("_parsed")
        
        # Meeting íŒŒì¼ ì €ì¥
        filename = f"{meeting_id}-{holon['slug']}.md"
        filepath = self.meetings_path / filename
        
        # ì´ìŠˆ ëª©ë¡ ìƒì„±
        issues = [i for i in numbered_items if i["type"] == "issue"]
        
        content = f"""```json
{json.dumps(holon, ensure_ascii=False, indent=2)}
```

---

# ğŸ“‹ {title}

| í•­ëª© | ê°’ |
|------|-----|
| ìƒíƒœ | {actual_status} |
| ì™„ë£Œìœ¨ | {completion}% |
| ê²°ì • | {len(decisions)}ê±´ |
| í• ì¼ | {len(tasks)}ê±´ |
| ì´ìŠˆ | {len(issues)}ê±´ |

---

## ì›ë³¸ íšŒì˜ë¡

{text}

---

## ğŸ” ìë™ ì¶”ì¶œ ì •ë³´

### âœ… ê²°ì • ì‚¬í•­ ({len(decisions)}ê±´)
{chr(10).join(f"- {d}" for d in decisions) if decisions else "- (ì¶”ì¶œëœ ê²°ì • ì—†ìŒ)"}

### â¬œ í• ì¼ ({len(tasks)}ê±´)
{chr(10).join(f"- [ ] {t}" for t in tasks) if tasks else "- (ì¶”ì¶œëœ í• ì¼ ì—†ìŒ)"}

### ğŸ”´ ì´ìŠˆ/ë¬¸ì œ ({len(issues)}ê±´)
{chr(10).join(f"- #{i['num']}: {i['content'][:80]}" for i in issues) if issues else "- (ì‹ë³„ëœ ì´ìŠˆ ì—†ìŒ)"}

### ğŸ“š ì°¸ì¡°ëœ HTE ë¬¸ì„œ ({len(referenced_docs)}ê±´)
{chr(10).join(f"- **{doc['module']}**: {doc['title']} ({doc['score']:.0%})" for doc in referenced_docs) if referenced_docs else "- (ê´€ë ¨ HTE ë¬¸ì„œ ì—†ìŒ)"}

---

## ğŸ“Š ì™„ë£Œìœ¨ ë¶„ì„

- **ê²°ì •**: {holon['W']['goal']['completion_rate']['breakdown']['decisions']['count']}ê±´ â†’ {holon['W']['goal']['completion_rate']['breakdown']['decisions']['score']}/{holon['W']['goal']['completion_rate']['breakdown']['decisions']['max']}ì 
- **í• ì¼**: {holon['W']['goal']['completion_rate']['breakdown']['tasks']['count']}ê±´ â†’ {holon['W']['goal']['completion_rate']['breakdown']['tasks']['score']}/{holon['W']['goal']['completion_rate']['breakdown']['tasks']['max']}ì 
- **ìƒíƒœ**: {holon['W']['goal']['completion_rate']['breakdown']['status']['value']} â†’ {holon['W']['goal']['completion_rate']['breakdown']['status']['score']}/{holon['W']['goal']['completion_rate']['breakdown']['status']['max']}ì 
- **ì´ì **: **{completion}%** {'âœ… ì™„ë£Œ' if holon['W']['goal']['completion_rate']['is_complete'] else 'âš ï¸ ë¯¸ì™„ë£Œ'}

---

*ğŸ”¥ Self-Healing ëª¨ë“œë¡œ ìë™ ìƒì„±ë¨*
"""
        
        filepath.write_text(content, encoding="utf-8")
        print(f"âœ… Meeting ìƒì„±: {filepath}")
        
        result = {
            "meeting_id": meeting_id,
            "file": str(filepath),
            "parent": parent_id,
            "confidence": confidence,
            "decisions": decisions,
            "tasks": tasks,
            "spawned": [],
            "referenced_docs": referenced_docs,  # HTE ì°¸ì¡° ë¬¸ì„œ
            "completion_rate": completion,
            "actual_status": actual_status
        }
        
        # Decision/Task ìë™ ìƒì„±
        if auto_spawn and (decisions or tasks):
            print()
            print("ğŸš€ Decision/Task ìë™ ìƒì„± ì¤‘...")
            spawned = self._spawn_from_meeting(meeting_id, decisions, tasks)
            result["spawned"] = spawned
        
        print()
        print("=" * 60)
        print(f"ğŸ”¥ ì™„ë£Œ! Meeting + {len(result['spawned'])}ê°œ í•˜ìœ„ ë¬¸ì„œ ìƒì„±")
        print("=" * 60)
        
        return result
    
    def _spawn_from_meeting(self, meeting_id: str, decisions: List[str], tasks: List[str]) -> List[str]:
        """Meetingì—ì„œ Decision/Task ìƒì„±"""
        spawned = []
        today = datetime.now().strftime("%Y-%m-%d")
        year = datetime.now().strftime("%Y")
        
        # Decision ìƒì„±
        for i, decision in enumerate(decisions[:5], 1):  # ìµœëŒ€ 5ê°œ
            decision_id = f"decision-{year}-{len(list(self.decisions_path.glob('*.md'))) + i:03d}"
            
            decision_holon = {
                "holon_id": decision_id,
                "slug": decision[:20].replace(" ", "-").lower(),
                "type": "decision",
                "meta": {
                    "title": decision[:50],
                    "created_at": today,
                    "status": "active"
                },
                "W": {
                    "will": {
                        "drive": f"'{decision}'ì„ ì‹¤í–‰ì— ì˜®ê¸´ë‹¤"
                    }
                },
                "links": {
                    "parent": meeting_id,
                    "children": [],
                    "related": []
                }
            }
            
            filepath = self.decisions_path / f"{decision_id}.md"
            content = f"""```json
{json.dumps(decision_holon, ensure_ascii=False, indent=2)}
```

# âœ… {decision[:50]}

*{meeting_id}ì—ì„œ ìë™ ìƒì„±ë¨*
"""
            filepath.write_text(content, encoding="utf-8")
            spawned.append(decision_id)
            print(f"   âœ… Decision: {decision_id}")
        
        # Task ìƒì„±
        for i, task in enumerate(tasks[:5], 1):  # ìµœëŒ€ 5ê°œ
            task_id = f"task-{year}-{len(list(self.tasks_path.glob('*.md'))) + i:03d}"
            
            task_holon = {
                "holon_id": task_id,
                "slug": task[:20].replace(" ", "-").lower(),
                "type": "task",
                "meta": {
                    "title": task[:50],
                    "created_at": today,
                    "status": "pending"
                },
                "W": {
                    "will": {
                        "drive": f"'{task}'ë¥¼ ì™„ë£Œí•œë‹¤"
                    }
                },
                "links": {
                    "parent": meeting_id,
                    "children": [],
                    "related": []
                }
            }
            
            filepath = self.tasks_path / f"{task_id}.md"
            content = f"""```json
{json.dumps(task_holon, ensure_ascii=False, indent=2)}
```

# â¬œ {task[:50]}

- [ ] ì™„ë£Œ

*{meeting_id}ì—ì„œ ìë™ ìƒì„±ë¨*
"""
            filepath.write_text(content, encoding="utf-8")
            spawned.append(task_id)
            print(f"   â¬œ Task: {task_id}")
        
        return spawned


def main():
    """í…ŒìŠ¤íŠ¸ìš©"""
    sample = """
# 2025ë…„ AI íŠœí„° ê°œë°œ í‚¥ì˜¤í”„ íšŒì˜

ì¼ì‹œ: 2025-11-30
ì°¸ì„ì: ê¹€ì² ìˆ˜, ì´ì˜í¬, ë°•ë¯¼ìˆ˜

## ì•ˆê±´
1. AI íŠœí„° MVP ë²”ìœ„ í™•ì •
2. ê°œë°œ ì¼ì • ë…¼ì˜
3. ë‹´ë‹¹ì ë°°ì •

## ë…¼ì˜ ë‚´ìš©
í•™ìƒ ì§„ë‹¨ ê¸°ëŠ¥ì„ ë¨¼ì € ê°œë°œí•˜ê¸°ë¡œ í•¨.
ì‹œì„  ì¶”ì  ê¸°ëŠ¥ì€ 2ë‹¨ê³„ë¡œ ì§„í–‰.

## ê²°ì • ì‚¬í•­
- ê²°ì •: MVPëŠ” ì§„ë‹¨ ë¦¬í¬íŠ¸ ê¸°ëŠ¥ìœ¼ë¡œ í•œì •
- ê²°ì •: 2ì›” ë§ ë² íƒ€ ì¶œì‹œ ëª©í‘œ

## í• ì¼
- TODO: ê¹€ì² ìˆ˜ - UI ë””ìì¸ ì´ˆì•ˆ (12/15ê¹Œì§€)
- TODO: ì´ì˜í¬ - ë°±ì—”ë“œ API ì„¤ê³„
- ë°•ë¯¼ìˆ˜ ë‹´ë‹¹ - ë°ì´í„° ëª¨ë¸ ì„¤ê³„
"""
    
    parser = MeetingParser(str(Path(__file__).parent))
    result = parser.parse_and_create(sample)
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

