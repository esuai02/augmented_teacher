#!/usr/bin/env python3
"""
ğŸ§  Vector RAG Engine - W(Worldview) ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í•µì‹¬ ê¸°ëŠ¥:
1. W.will.drive í•„ë“œë¥¼ ë²¡í„° ì„ë² ë”©
2. ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
3. ë§í¬ ê·¸ë˜í”„ íƒìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ í™•ì¥
4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + ê·¸ë˜í”„ + íƒœê·¸)

ì˜ë„:
- ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
- Holonì˜ W(ì˜ì§€) í•„ë“œë¥¼ í•µì‹¬ ê²€ìƒ‰ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
- ë§í¬ êµ¬ì¡°ë¥¼ í™œìš©í•œ ì»¨í…ìŠ¤íŠ¸ í™•ì¥
"""

import json
import re
import os
import logging
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("holarchy.vector_rag")
import hashlib

# API ì„¤ì •
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMENSIONS = 1536

# ë¡œì»¬ ì„ë² ë”© ì„¤ì • (sentence-transformers)
LOCAL_EMBEDDING_MODEL = "paraphrase-multilingual-MiniLM-L12-v2"  # í•œêµ­ì–´ ì§€ì›
LOCAL_EMBEDDING_DIMENSIONS = 384
USE_LOCAL_EMBEDDING = True  # Trueë©´ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©


@dataclass
class VectorDocument:
    """ë²¡í„°í™”ëœ ë¬¸ì„œ"""
    holon_id: str
    filepath: str
    title: str
    
    # W í•„ë“œ ë‚´ìš©
    w_drive: str  # W.will.drive
    w_worldview: str  # W.worldview (ì „ì²´)
    
    # ì„ë² ë”© ë²¡í„°
    embedding: List[float] = field(default_factory=list)
    
    # ë§í¬ ì •ë³´
    parent: str = ""
    children: List[str] = field(default_factory=list)
    related: List[str] = field(default_factory=list)
    
    # íƒœê·¸
    tags: Dict = field(default_factory=dict)
    
    # ìœ ì‚¬ë„ ì ìˆ˜ (ê²€ìƒ‰ ì‹œ ê³„ì‚°)
    similarity_score: float = 0.0


class VectorRAGEngine:
    """W ê¸°ë°˜ ë²¡í„° RAG ì—”ì§„"""
    
    def __init__(self, base_path: str = None):
        if base_path:
            self.base_path = Path(base_path)
        else:
            self.base_path = Path(__file__).parent
        
        self.holons_path = self.base_path
        self.docs_root = self.base_path.parent
        self.hte_path = self.docs_root.parent / "2 Company" / "4 HTE"
        
        # ë²¡í„° ìºì‹œ ê²½ë¡œ
        self.cache_path = self.docs_root / "reports" / "vector_cache.json"
        self.cache_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ë¬¸ì„œ & ë²¡í„° ìºì‹œ
        self.documents: Dict[str, VectorDocument] = {}
        self.vector_cache: Dict[str, List[float]] = {}
        
        # ìºì‹œ ë¡œë“œ
        self._load_cache()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OpenAI ì„ë² ë”©
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _get_embedding(self, text: str, use_cache: bool = True) -> List[float]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            ë²¡í„° (ë¡œì»¬: 384ì°¨ì›, OpenAI: 1536ì°¨ì›)
        """
        if not text or not text.strip():
            dim = LOCAL_EMBEDDING_DIMENSIONS if USE_LOCAL_EMBEDDING else EMBEDDING_DIMENSIONS
            return [0.0] * dim
        
        # ìºì‹œ í‚¤ ìƒì„± (í…ìŠ¤íŠ¸ í•´ì‹œ)
        cache_key = hashlib.md5(text.encode()).hexdigest()
        
        if use_cache and cache_key in self.vector_cache:
            return self.vector_cache[cache_key]
        
        # ë¡œì»¬ ì„ë² ë”© (sentence-transformers)
        if USE_LOCAL_EMBEDDING:
            try:
                from sentence_transformers import SentenceTransformer
                
                if not hasattr(self, '_local_model'):
                    print("   ğŸ“¦ ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
                    self._local_model = SentenceTransformer(LOCAL_EMBEDDING_MODEL)
                
                embedding = self._local_model.encode(text[:2000]).tolist()
                
                # ìºì‹œ ì €ì¥
                self.vector_cache[cache_key] = embedding
                
                return embedding
                
            except ImportError:
                print("âš ï¸ sentence-transformers í•„ìš”: pip install sentence-transformers")
                return [0.0] * LOCAL_EMBEDDING_DIMENSIONS
            except Exception as e:
                print(f"âš ï¸ ë¡œì»¬ ì„ë² ë”© ì˜¤ë¥˜: {e}")
                return [0.0] * LOCAL_EMBEDDING_DIMENSIONS
        
        # OpenAI ì„ë² ë”©
        try:
            import openai
            
            if not OPENAI_API_KEY:
                print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”")
                return [0.0] * EMBEDDING_DIMENSIONS
            
            client = openai.OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.embeddings.create(
                input=text[:8000],  # í† í° ì œí•œ
                model=EMBEDDING_MODEL
            )
            
            embedding = response.data[0].embedding
            
            # ìºì‹œ ì €ì¥
            self.vector_cache[cache_key] = embedding
            
            return embedding
            
        except ImportError:
            print("âš ï¸ openai íŒ¨í‚¤ì§€ í•„ìš”: pip install openai")
            return [0.0] * EMBEDDING_DIMENSIONS
        except Exception as e:
            print(f"âš ï¸ OpenAI ì„ë² ë”© ì˜¤ë¥˜: {e}")
            return [0.0] * EMBEDDING_DIMENSIONS
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not vec1 or not vec2:
            return 0.0
        
        a = np.array(vec1)
        b = np.array(vec2)
        
        dot = np.dot(a, b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return float(dot / (norm_a * norm_b))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ë¬¸ì„œ ë¡œë“œ & ì¸ë±ì‹±
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _extract_w_content(self, holon: Dict) -> Tuple[str, str]:
        """
        W(Worldview) í•„ë“œì—ì„œ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
        
        Returns:
            (w_drive, w_worldview_full)
        """
        w = holon.get("W", {})
        
        # W.will.drive (í•µì‹¬ ì˜ì§€)
        w_drive = w.get("will", {}).get("drive", "")
        
        # W ì „ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ
        w_full_parts = []
        
        # worldview
        worldview = w.get("worldview", {})
        if isinstance(worldview, dict):
            w_full_parts.append(worldview.get("identity", ""))
            w_full_parts.append(worldview.get("belief", ""))
            w_full_parts.append(worldview.get("value_system", ""))
        
        # will
        will = w.get("will", {})
        if isinstance(will, dict):
            w_full_parts.append(will.get("drive", ""))
            w_full_parts.append(will.get("commitment", ""))
        
        # intention
        intention = w.get("intention", {})
        if isinstance(intention, dict):
            w_full_parts.append(intention.get("primary", ""))
        
        # goal
        goal = w.get("goal", {})
        if isinstance(goal, dict):
            w_full_parts.append(goal.get("ultimate", ""))
        
        w_worldview = " ".join(filter(None, w_full_parts))
        
        return w_drive, w_worldview
    
    def load_document(self, filepath: Path) -> Optional[VectorDocument]:
        """ë‹¨ì¼ ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„°í™”"""
        if not filepath.exists():
            return None
        
        content = filepath.read_text(encoding="utf-8")
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
        if not json_match:
            return None
        
        try:
            holon = json.loads(json_match.group(1))
        except json.JSONDecodeError as e:
            logger.debug(f"Holon JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        
        holon_id = holon.get("holon_id", "")
        if not holon_id:
            return None
        
        # W í•„ë“œ ì¶”ì¶œ
        w_drive, w_worldview = self._extract_w_content(holon)
        
        # ë§í¬ ì¶”ì¶œ
        links = holon.get("links", {})
        
        # íƒœê·¸ ì¶”ì¶œ
        tags = holon.get("meta", {}).get("tags", {})
        
        doc = VectorDocument(
            holon_id=holon_id,
            filepath=str(filepath),
            title=holon.get("meta", {}).get("title", filepath.stem),
            w_drive=w_drive,
            w_worldview=w_worldview,
            parent=links.get("parent", ""),
            children=links.get("children", []),
            related=links.get("related", []),
            tags=tags
        )
        
        return doc
    
    def index_all_documents(self, force_reindex: bool = False):
        """
        ëª¨ë“  ë¬¸ì„œ ì¸ë±ì‹± (W í•„ë“œ ë²¡í„°í™”)
        
        Args:
            force_reindex: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ì¸ë±ì‹±
        """
        print("=" * 60)
        print("ğŸ§  Vector RAG Engine - W ê¸°ë°˜ ì¸ë±ì‹±")
        print("=" * 60)
        print()
        
        all_files = []
        
        # holons í´ë”
        for md_file in self.holons_path.glob("*.md"):
            if not md_file.name.startswith("_"):
                all_files.append(md_file)
        
        # meetings/decisions/tasks
        for folder in ["meetings", "decisions", "tasks"]:
            folder_path = self.docs_root / folder
            if folder_path.exists():
                all_files.extend(folder_path.glob("*.md"))
        
        # HTE í´ë”
        if self.hte_path.exists():
            all_files.extend(self.hte_path.rglob("HTE_*.md"))
        
        print(f"ğŸ“ ì´ {len(all_files)}ê°œ ë¬¸ì„œ ë°œê²¬")
        print()
        
        indexed = 0
        for filepath in all_files:
            doc = self.load_document(filepath)
            if not doc:
                continue
            
            # ë²¡í„° ì„ë² ë”© (W.will.drive ê¸°ì¤€)
            if doc.w_drive:
                print(f"   ğŸ”„ {doc.holon_id}: W.will.drive ì„ë² ë”© ì¤‘...")
                doc.embedding = self._get_embedding(doc.w_drive)
            elif doc.w_worldview:
                print(f"   ğŸ”„ {doc.holon_id}: W ì „ì²´ ì„ë² ë”© ì¤‘...")
                doc.embedding = self._get_embedding(doc.w_worldview[:2000])
            else:
                print(f"   âš ï¸ {doc.holon_id}: W í•„ë“œ ì—†ìŒ")
                continue
            
            self.documents[doc.holon_id] = doc
            indexed += 1
        
        # ìºì‹œ ì €ì¥
        self._save_cache()
        
        print()
        print(f"âœ… {indexed}ê°œ ë¬¸ì„œ ë²¡í„° ì¸ë±ì‹± ì™„ë£Œ")
        print("=" * 60)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ê²€ìƒ‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def search_by_w(self, query: str, top_k: int = 10) -> List[VectorDocument]:
        """
        W(ì˜ì§€) ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
        
        Returns:
            ìœ ì‚¬ë„ ìˆœ ì •ë ¬ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.documents:
            print("âš ï¸ ì¸ë±ì‹±ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. index_all_documents() ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return []
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self._get_embedding(query)
        
        # ëª¨ë“  ë¬¸ì„œì™€ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        for holon_id, doc in self.documents.items():
            if doc.embedding:
                similarity = self._cosine_similarity(query_embedding, doc.embedding)
                doc.similarity_score = similarity
                results.append(doc)
        
        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        results.sort(key=lambda x: x.similarity_score, reverse=True)
        
        return results[:top_k]
    
    def search_with_graph_expansion(self, query: str, top_k: int = 10, 
                                    expand_depth: int = 1) -> List[VectorDocument]:
        """
        ê²€ìƒ‰ + ë§í¬ ê·¸ë˜í”„ í™•ì¥
        
        1. W ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰ìœ¼ë¡œ ì´ˆê¸° ê²°ê³¼
        2. ë§í¬(parent/children/related)ë¥¼ ë”°ë¼ í™•ì¥
        3. ì¤‘ë³µ ì œê±° í›„ ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            expand_depth: ê·¸ë˜í”„ í™•ì¥ ê¹Šì´
        """
        # 1. ì´ˆê¸° ê²€ìƒ‰
        initial_results = self.search_by_w(query, top_k=top_k)
        
        # 2. ê·¸ë˜í”„ í™•ì¥
        expanded_ids = set()
        expanded_docs = []
        
        for doc in initial_results:
            expanded_ids.add(doc.holon_id)
            expanded_docs.append(doc)
            
            # parent í™•ì¥
            if doc.parent and doc.parent in self.documents:
                parent_doc = self.documents[doc.parent]
                if parent_doc.holon_id not in expanded_ids:
                    parent_doc.similarity_score = doc.similarity_score * 0.8  # ê°ì‡ 
                    expanded_docs.append(parent_doc)
                    expanded_ids.add(parent_doc.holon_id)
            
            # children í™•ì¥
            for child_id in doc.children[:3]:  # ìµœëŒ€ 3ê°œ
                if child_id in self.documents and child_id not in expanded_ids:
                    child_doc = self.documents[child_id]
                    child_doc.similarity_score = doc.similarity_score * 0.7
                    expanded_docs.append(child_doc)
                    expanded_ids.add(child_id)
            
            # related í™•ì¥
            for related_id in doc.related[:2]:  # ìµœëŒ€ 2ê°œ
                if related_id in self.documents and related_id not in expanded_ids:
                    related_doc = self.documents[related_id]
                    related_doc.similarity_score = doc.similarity_score * 0.6
                    expanded_docs.append(related_doc)
                    expanded_ids.add(related_id)
        
        # 3. ìœ ì‚¬ë„ ìˆœ ì¬ì •ë ¬
        expanded_docs.sort(key=lambda x: x.similarity_score, reverse=True)
        
        return expanded_docs
    
    def hybrid_search(self, query: str, top_k: int = 10,
                     tag_filter: Dict = None) -> List[VectorDocument]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + ê·¸ë˜í”„ + íƒœê·¸ í•„í„°
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            tag_filter: íƒœê·¸ í•„í„° (ì˜ˆ: {"module": ["M16"], "topic": ["AIíŠœí„°"]})
        """
        # 1. ê·¸ë˜í”„ í™•ì¥ ê²€ìƒ‰
        results = self.search_with_graph_expansion(query, top_k=top_k * 2)
        
        # 2. íƒœê·¸ í•„í„°ë§
        if tag_filter:
            filtered = []
            for doc in results:
                match = True
                for tag_key, tag_values in tag_filter.items():
                    doc_tags = doc.tags.get(tag_key, [])
                    if isinstance(doc_tags, str):
                        doc_tags = [doc_tags]
                    if not any(v in doc_tags for v in tag_values):
                        match = False
                        break
                if match:
                    filtered.append(doc)
            results = filtered
        
        return results[:top_k]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ìºì‹œ ê´€ë¦¬
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _save_cache(self):
        """ë²¡í„° ìºì‹œ ì €ì¥"""
        cache_data = {
            "updated_at": datetime.now().isoformat(),
            "model": EMBEDDING_MODEL,
            "vectors": self.vector_cache
        }
        with open(self.cache_path, "w", encoding="utf-8") as f:
            json.dump(cache_data, f, ensure_ascii=False)
        print(f"ğŸ’¾ ë²¡í„° ìºì‹œ ì €ì¥: {self.cache_path}")
    
    def _load_cache(self):
        """ë²¡í„° ìºì‹œ ë¡œë“œ"""
        if self.cache_path.exists():
            try:
                with open(self.cache_path, "r", encoding="utf-8") as f:
                    cache_data = json.load(f)
                self.vector_cache = cache_data.get("vectors", {})
                print(f"ğŸ“‚ ë²¡í„° ìºì‹œ ë¡œë“œ: {len(self.vector_cache)}ê°œ")
            except (json.JSONDecodeError, FileNotFoundError, UnicodeDecodeError) as e:
                logger.debug(f"ë²¡í„° ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.vector_cache = {}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì¶œë ¥
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def print_search_results(self, results: List[VectorDocument], query: str):
        """ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥"""
        print()
        print("=" * 70)
        print(f"ğŸ” ê²€ìƒ‰: \"{query}\"")
        print("=" * 70)
        print()
        print(f"{'#':3} {'ìœ ì‚¬ë„':8} {'ë¬¸ì„œ ID':25} {'ì œëª©':30}")
        print("-" * 70)
        
        for i, doc in enumerate(results, 1):
            similarity = f"{doc.similarity_score:.3f}"
            holon_id = doc.holon_id[:25]
            title = doc.title[:30]
            print(f"{i:3} {similarity:8} {holon_id:25} {title:30}")
        
        print()
        print(f"ğŸ“Š ì´ {len(results)}ê°œ ê²°ê³¼")
        print("=" * 70)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Vector RAG Engine")
    parser.add_argument("action", choices=["index", "search", "hybrid"], 
                       help="index: ì¸ë±ì‹±, search: ê²€ìƒ‰, hybrid: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰")
    parser.add_argument("-q", "--query", help="ê²€ìƒ‰ ì¿¼ë¦¬")
    parser.add_argument("-k", "--top-k", type=int, default=10, help="ê²°ê³¼ ìˆ˜")
    parser.add_argument("--force", action="store_true", help="ê°•ì œ ì¬ì¸ë±ì‹±")
    
    args = parser.parse_args()
    
    engine = VectorRAGEngine()
    
    if args.action == "index":
        engine.index_all_documents(force_reindex=args.force)
        
    elif args.action == "search":
        if not args.query:
            print("âŒ --query í•„ìš”")
            return
        
        # ì¸ë±ì‹± ì•ˆë˜ì–´ ìˆìœ¼ë©´ ë¡œë“œ
        if not engine.documents:
            engine.index_all_documents()
        
        results = engine.search_by_w(args.query, top_k=args.top_k)
        engine.print_search_results(results, args.query)
        
    elif args.action == "hybrid":
        if not args.query:
            print("âŒ --query í•„ìš”")
            return
        
        if not engine.documents:
            engine.index_all_documents()
        
        results = engine.hybrid_search(args.query, top_k=args.top_k)
        engine.print_search_results(results, args.query)


if __name__ == "__main__":
    main()

