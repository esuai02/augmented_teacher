#!/usr/bin/env python3
"""
ğŸ·ï¸ Auto-Tagger v3 - ë©€í‹°ë ˆì´ì–´ ìë™ íƒœê¹… ì—”ì§„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ê¸°ëŠ¥:
- ë¬¸ì„œ ë‚´ìš© ë¶„ì„í•˜ì—¬ ë©€í‹°ë ˆì´ì–´ íƒœê·¸ ìë™ ë¶€ì—¬
- ì£¼ì œ(semantic_topic) / ì—­í• (role) / í˜ë¥´ì†Œë‚˜(persona) / ê¸´ê¸‰ë„(urgency) / ì‹¤í–‰ê°€ëŠ¥ì„±(actionability)
- ê¸°ì¡´ Holon JSONì˜ meta.tags í•„ë“œì— ì €ì¥

íƒœê·¸ ë ˆì´ì–´:
1. module: M00~M21 ëª¨ë“ˆ ë§¤í•‘
2. topic: ì˜ë¯¸ ê¸°ë°˜ ì£¼ì œ íƒœê·¸
3. role: spec, meeting, decision ë“±
4. persona: í•™ìƒ, ì„ ìƒë‹˜, ë¶€ëª¨ ë“±
5. urgency: ê¸´ê¸‰, ìµœì‹ , ì¦‰ì‹œìˆ˜ì •
6. actionability: action-required, done, issue-list
"""

import json
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("holarchy.auto_tagger")
import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Tuple
from dataclasses import dataclass, field, asdict


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í‚¤ì›Œë“œ ì‚¬ì „ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ëª¨ë“ˆ ë§¤í•‘ (ê¸°ì¡´ _document_placer.pyì—ì„œ í†µí•©)
MODULE_KEYWORDS = {
    "M00": ["ì „ëµ", "ì„¸ê³„ê´€", "ë¹„ì „", "ë¯¸ì…˜", "ì² í•™", "ëª©í‘œ", "ë°©í–¥", "í•µì‹¬"],
    "M01": ["ì‹œê°„", "ê²½ì˜", "ì˜ì‚¬ê²°ì •", "ë¦¬ë”", "ì¼ì •", "ê³„íš", "ìŠ¤ì¼€ì¤„"],
    "M02": ["ìš´ì˜", "í”„ë¡œì„¸ìŠ¤", "ë¦¬ë“¬", "íšŒì˜", "ë¯¸íŒ…", "ì ˆì°¨", "ì›Œí¬í”Œë¡œìš°"],
    "M03": ["ë¹„ì¦ˆë‹ˆìŠ¤", "ëª¨ë¸", "ìˆ˜ìµ", "ë§¤ì¶œ", "ê°€ê²©", "ê³ ê°", "ì‹œì¥"],
    "M04": ["kpi", "okr", "ëª©í‘œ", "ì„±ê³¼", "ì§€í‘œ", "ì¸¡ì •", "ë‹¬ì„±"],
    "M05": ["ì¬ë¬´", "íˆ¬ì", "ì˜ˆì‚°", "ë¹„ìš©", "ìê¸ˆ", "ê¸ˆìœµ", "ì„±ì¥"],
    "M06": ["swot", "ê°•ì ", "ì•½ì ", "ê¸°íšŒ", "ìœ„í˜‘", "ë¶„ì„", "ê²½ìŸ"],
    "M07": ["ìš°ì„ ìˆœìœ„", "ë¦¬ì†ŒìŠ¤", "ë°°ë¶„", "ì§‘ì¤‘", "ì„ íƒ", "ë¹„ì¤‘"],
    "M08": ["ë‚´ë¶€", "ë¸Œëœë”©", "ë¬¸í™”", "ê°€ì¹˜", "ì§ì›", "íŒ€"],
    "M09": ["í•µì‹¬", "ê¸°ìˆ ", "ê°œë°œ", "ì—°êµ¬", "ê¹Šì´", "ì „ë¬¸", "ë“œë¦´ë§"],
    "M10": ["agent", "ì—ì´ì „íŠ¸", "holon", "í™€ë¡ ", "ìë™í™”", "ë´‡"],
    "M11": ["ì„œë¹„ìŠ¤", "íŒŒì´í”„ë¼ì¸", "ë°°í¬", "ì „ë‹¬", "ìš´ì˜"],
    "M12": ["ì™¸ë¶€", "ë§ˆì¼€íŒ…", "í™ë³´", "ê´‘ê³ ", "ë¸Œëœë“œ", "ì¸ì§€ë„"],
    "M13": ["ì„±ì¥", "ì—”ì§„", "í™•ì¥", "ìŠ¤ì¼€ì¼", "ê·¸ë¡œìŠ¤"],
    "M14": ["ì˜¨ë³´ë”©", "êµìœ¡", "ì‹ ì…", "ì…ì‚¬", "íŠ¸ë ˆì´ë‹"],
    "M15": ["ceo", "ë¦¬ë”ì‹­", "ê²½ì˜ì§„", "ëŒ€í‘œ", "ì´ê´„"],
    "M16": ["ai", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "llm", "gpt", "íŠœí„°", "í•™ìŠµ"],
    "M17": ["ì‹ ê²½", "ë°ì´í„°", "íŒŒì´í”„ë¼ì¸", "ì—°ê²°", "í†µí•©", "api"],
    "M18": ["ì •ë³´", "ë¸”ë¡", "ì§€ëŠ¥", "êµ¬ì¡°", "í”„ë ˆì„ì›Œí¬"],
    "M19": ["ë¬¸í™”", "ê°€ì¹˜ê´€", "ì¡°ì§ë¬¸í™”", "ë¬´ì§€ì„±"],
    "M20": ["ì§€ì‹", "ì¶•ì ", "ê²°ì •ì²´", "í•™ìŠµ", "ì²´ê³„"],
    "M21": ["ì†Œí”„íŠ¸ì›¨ì–´", "ë°±ë³¸", "ì¸í”„ë¼", "ì‹œìŠ¤í…œ", "ì„œë²„", "í´ë¼ìš°ë“œ"],
}

# ì£¼ì œ íƒœê·¸ (semantic_topic)
SEMANTIC_TOPICS = {
    # ê¸°ëŠ¥ ê´€ë ¨
    "TTS": ["tts", "ìŒì„±", "ì½ê¸°", "ë°œí™”", "speech", "voice"],
    "ì§ˆë¬¸í•˜ê¸°": ["ì§ˆë¬¸", "qna", "query", "ë¬¼ì–´", "ë‹µë³€"],
    "í™”ì´íŠ¸ë³´ë“œ": ["í™”ì´íŠ¸ë³´ë“œ", "whiteboard", "ê·¸ë¦¬ê¸°", "ìº”ë²„ìŠ¤"],
    "íƒ€ì´ë¨¸": ["íƒ€ì´ë¨¸", "timer", "ì‹œê°„ì¸¡ì •", "ì¹´ìš´íŠ¸"],
    "ë…¹í™”": ["ë…¹í™”", "recording", "ì˜ìƒ", "ë¹„ë””ì˜¤"],
    
    # ê²½í—˜ ê´€ë ¨
    "í•™ìƒê²½í—˜": ["í•™ìƒ í™”ë©´", "student", "í•™ìŠµì", "ìˆ˜ê°•ìƒ"],
    "êµì‚¬ë„êµ¬": ["ì„ ìƒë‹˜", "teacher", "êµì‚¬", "ê°•ì‚¬", "íŠœí„°"],
    "í•™ë¶€ëª¨": ["í•™ë¶€ëª¨", "parent", "ë³´í˜¸ì", "ê°€ì •í†µì‹ "],
    
    # ê¸°ìˆ  ê´€ë ¨
    "ì‹œì„ ì¶”ì ": ["ì‹œì„ ", "eye tracking", "attention", "ì§‘ì¤‘ë„", "gaze"],
    "ê°ì •ë¶„ì„": ["ê°ì •", "emotion", "sentiment", "í‘œì •"],
    "AIíŠœí„°": ["ai íŠœí„°", "ì¸ê³µì§€ëŠ¥ íŠœí„°", "ìë™ íŠœí„°ë§"],
    
    # ì‹œìŠ¤í…œ ê´€ë ¨
    "ì˜¤ë¥˜ê´€ë¦¬": ["ì˜¤ë¥˜", "error", "bug", "ë²„ê·¸", "ì—ëŸ¬", "ë¬¸ì œ"],
    "UXë¬¸ì œ": ["ux", "ì‚¬ìš©ì„±", "ë¶ˆí¸", "ê°œì„ "],
    "ì‹œìŠ¤í…œì•ˆì •ì„±": ["ì•ˆì •ì„±", "stability", "crash", "ë‹¤ìš´", "ë©ˆì¶¤"],
    "ìë™í™”": ["ìë™í™”", "automation", "ìë™", "ë°°ì¹˜"],
    "ëª¨ë“ˆì„¤ê³„": ["ëª¨ë“ˆ", "ì„¤ê³„", "ì•„í‚¤í…ì²˜", "êµ¬ì¡°"],
}

# ì—­í•  íƒœê·¸ (functional_role)
ROLE_KEYWORDS = {
    "spec": ["ëª…ì„¸", "ìŠ¤í™", "ì •ì˜", "specification", "ì„¤ê³„ì„œ"],
    "meeting": ["íšŒì˜", "ë¯¸íŒ…", "meeting", "ë…¼ì˜", "ì•ˆê±´"],
    "decision": ["ê²°ì •", "decision", "í™•ì •", "í•©ì˜"],
    "task-set": ["í• ì¼", "task", "todo", "ì‘ì—…"],
    "error-report": ["ì˜¤ë¥˜ ë³´ê³ ", "ë²„ê·¸ ë¦¬í¬íŠ¸", "ì—ëŸ¬ ë³´ê³ "],
    "planning": ["ê³„íš", "ê¸°íš", "planning", "ë¡œë“œë§µ"],
    "roadmap": ["ë¡œë“œë§µ", "roadmap", "ë§ˆì¼ìŠ¤í†¤", "ì¼ì •"],
    "analysis": ["ë¶„ì„", "analysis", "ë¦¬ì„œì¹˜", "ì¡°ì‚¬"],
    "feature": ["ê¸°ëŠ¥", "feature", "ì‹ ê·œ ê¸°ëŠ¥"],
}

# í˜ë¥´ì†Œë‚˜ íƒœê·¸ (persona_context)
PERSONA_KEYWORDS = {
    "í•™ìƒ": ["í•™ìƒ", "ìˆ˜ê°•ìƒ", "í•™ìŠµì", "student", "learner"],
    "ì„ ìƒë‹˜": ["ì„ ìƒë‹˜", "êµì‚¬", "ê°•ì‚¬", "teacher", "tutor", "instructor"],
    "ë¶€ëª¨": ["í•™ë¶€ëª¨", "ë¶€ëª¨", "ë³´í˜¸ì", "parent", "guardian"],
    "ìš´ì˜ì§„": ["ìš´ì˜", "ê´€ë¦¬ì", "admin", "operator", "ë§¤ë‹ˆì €"],
    "AIì‹œìŠ¤í…œ": ["ai", "ì‹œìŠ¤í…œ", "ë´‡", "ìë™í™”", "agent"],
}

# ê¸´ê¸‰ë„ í‚¤ì›Œë“œ (urgency)
URGENCY_KEYWORDS = {
    "ê¸´ê¸‰": ["ê¸´ê¸‰", "urgent", "asap", "ì¦‰ì‹œ", "ë‹¹ì¥"],
    "ì¦‰ì‹œìˆ˜ì •": ["ì˜¤ë¥˜", "error", "bug", "ë²„ê·¸", "crash", "ë‹¤ìš´"],
    "ë†’ìŒ": ["high", "ì¤‘ìš”", "critical", "í•„ìˆ˜"],
}

# ì‹¤í–‰ê°€ëŠ¥ì„± í‚¤ì›Œë“œ (actionability)
ACTIONABILITY_PATTERNS = {
    "action-required": [
        r"í•´ì•¼\s*(?:í•œë‹¤|í•¨|í•©ë‹ˆë‹¤)",
        r"í•„ìš”(?:í•˜ë‹¤|í•¨|í•©ë‹ˆë‹¤)?",
        r"ë²„íŠ¼\s*(?:í•„ìš”|ì¶”ê°€|ìƒì„±)",
        r"(?:ê°œì„ |ìˆ˜ì •|ë³´ì™„|ì¶”ê°€|ì‚­ì œ|ë³€ê²½)\s*(?:í•„ìš”|ìš”ë§|ìš”ì²­)",
    ],
    "done": [
        r"ì™„ë£Œ",
        r"ì¢…ë£Œ",
        r"í•´ê²°ë¨",
        r"done",
        r"finished",
    ],
    "issue-list": [
        r"(?:^|\n)\s*\d+[\.)\s]",  # ë²ˆí˜¸ ëª©ë¡
    ],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# íƒœê·¸ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class TagResult:
    """íƒœê·¸ ê²°ê³¼"""
    module: List[str] = field(default_factory=list)
    topic: List[str] = field(default_factory=list)
    role: str = ""
    persona: List[str] = field(default_factory=list)
    urgency: str = ""
    actionability: str = ""
    
    # ë©”íƒ€ ì •ë³´
    confidence: float = 0.0
    generated_at: str = ""
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = {}
        if self.module:
            result["module"] = self.module
        if self.topic:
            result["topic"] = self.topic
        if self.role:
            result["role"] = self.role
        if self.persona:
            result["persona"] = self.persona
        if self.urgency:
            result["urgency"] = self.urgency
        if self.actionability:
            result["actionability"] = self.actionability
        return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Auto-Tagger í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoTagger:
    """ë©€í‹°ë ˆì´ì–´ ìë™ íƒœê¹… ì—”ì§„"""
    
    def __init__(self, base_path: str = None):
        if base_path:
            self.base_path = Path(base_path)
        else:
            self.base_path = Path(__file__).parent
        
        self.holons_path = self.base_path
        self.docs_root = self.base_path.parent
        self.hte_path = self.docs_root.parent / "2 Company" / "4 HTE"
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê°œë³„ íƒœê·¸ ë ˆì´ì–´ ë¶„ì„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def detect_modules(self, text: str) -> List[Tuple[str, float]]:
        """ëª¨ë“ˆ íƒœê·¸ ê°ì§€ (M00~M21)"""
        text_lower = text.lower()
        scores = {}
        
        for module_id, keywords in MODULE_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw.lower() in text_lower)
            if score > 0:
                scores[module_id] = score / len(keywords)
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        sorted_modules = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_modules[:3]  # ìƒìœ„ 3ê°œ
    
    def detect_semantic_topics(self, text: str) -> List[Tuple[str, float]]:
        """ì£¼ì œ íƒœê·¸ ê°ì§€"""
        text_lower = text.lower()
        scores = {}
        
        for topic, keywords in SEMANTIC_TOPICS.items():
            score = sum(1 for kw in keywords if kw.lower() in text_lower)
            if score > 0:
                scores[topic] = score / len(keywords)
        
        # 0.3 ì´ìƒë§Œ ìœ ì§€
        filtered = [(t, s) for t, s in scores.items() if s >= 0.2]
        return sorted(filtered, key=lambda x: x[1], reverse=True)[:5]
    
    def detect_role(self, text: str, doc_type: str = "") -> str:
        """ì—­í•  íƒœê·¸ ê°ì§€"""
        # ê¸°ì¡´ type í•„ë“œ ìš°ì„ 
        if doc_type in ROLE_KEYWORDS:
            return doc_type
        
        text_lower = text.lower()
        best_role = ""
        best_score = 0
        
        for role, keywords in ROLE_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw.lower() in text_lower)
            if score > best_score:
                best_score = score
                best_role = role
        
        return best_role
    
    def detect_personas(self, text: str) -> List[str]:
        """í˜ë¥´ì†Œë‚˜ íƒœê·¸ ê°ì§€"""
        text_lower = text.lower()
        detected = []
        
        for persona, keywords in PERSONA_KEYWORDS.items():
            if any(kw.lower() in text_lower for kw in keywords):
                detected.append(persona)
        
        return detected
    
    def detect_urgency(self, text: str, priority: str = "", updated_at: str = "") -> str:
        """ê¸´ê¸‰ë„ íƒœê·¸ ê°ì§€"""
        text_lower = text.lower()
        
        # priority í•„ë“œ ìš°ì„ 
        if priority == "high":
            return "ê¸´ê¸‰"
        
        # í‚¤ì›Œë“œ ê¸°ë°˜
        for urgency, keywords in URGENCY_KEYWORDS.items():
            if any(kw.lower() in text_lower for kw in keywords):
                return urgency
        
        # ìµœê·¼ ì—…ë°ì´íŠ¸ í™•ì¸
        if updated_at:
            try:
                updated = datetime.fromisoformat(updated_at.replace("Z", "+00:00"))
                if datetime.now(updated.tzinfo) - updated < timedelta(days=3):
                    return "ìµœì‹ "
            except ValueError as e:
                logger.debug(f"ì—…ë°ì´íŠ¸ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨ [{updated_at}]: {e}")
        
        return ""
    
    def detect_actionability(self, text: str) -> str:
        """ì‹¤í–‰ê°€ëŠ¥ì„± íƒœê·¸ ê°ì§€"""
        for action_type, patterns in ACTIONABILITY_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE | re.MULTILINE):
                    return action_type
        return ""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í†µí•© íƒœê·¸ ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def generate_tags(self, text: str, holon: Dict = None) -> TagResult:
        """
        ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë©€í‹°ë ˆì´ì–´ íƒœê·¸ ìƒì„±
        
        Args:
            text: ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸
            holon: ê¸°ì¡´ Holon JSON (ìˆìœ¼ë©´ meta ì •ë³´ í™œìš©)
        
        Returns:
            TagResult ê°ì²´
        """
        # ê¸°ì¡´ ë©”íƒ€ ì •ë³´ ì¶”ì¶œ
        meta = holon.get("meta", {}) if holon else {}
        doc_type = holon.get("type", "") if holon else ""
        priority = meta.get("priority", "")
        updated_at = meta.get("updated_at", "")
        
        # ê° ë ˆì´ì–´ë³„ ë¶„ì„
        modules = self.detect_modules(text)
        topics = self.detect_semantic_topics(text)
        role = self.detect_role(text, doc_type)
        personas = self.detect_personas(text)
        urgency = self.detect_urgency(text, priority, updated_at)
        actionability = self.detect_actionability(text)
        
        # ì‹ ë¢°ë„ ê³„ì‚° (íƒœê·¸ ìˆ˜ ê¸°ë°˜)
        total_tags = len(modules) + len(topics) + (1 if role else 0) + len(personas)
        confidence = min(total_tags / 10, 1.0)
        
        return TagResult(
            module=[m[0] for m in modules],
            topic=[t[0] for t in topics],
            role=role,
            persona=personas,
            urgency=urgency,
            actionability=actionability,
            confidence=confidence,
            generated_at=datetime.now().isoformat()
        )
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë¬¸ì„œ íƒœê¹…
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def tag_document(self, filepath: Path, dry_run: bool = False) -> Optional[TagResult]:
        """
        ë‹¨ì¼ ë¬¸ì„œ íƒœê¹…
        
        Args:
            filepath: ë¬¸ì„œ ê²½ë¡œ
            dry_run: Trueë©´ íƒœê·¸ë§Œ ìƒì„±í•˜ê³  ì €ì¥ ì•ˆí•¨
        
        Returns:
            TagResult ë˜ëŠ” None
        """
        if not filepath.exists():
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {filepath}")
            return None
        
        content = filepath.read_text(encoding="utf-8")
        
        # JSON ë¸”ë¡ ì¶”ì¶œ
        json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
        if not json_match:
            print(f"âš ï¸ JSON ì—†ìŒ: {filepath.name}")
            return None
        
        try:
            holon = json.loads(json_match.group(1))
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {filepath.name} - {e}")
            return None
        
        # íƒœê·¸ ìƒì„±
        tags = self.generate_tags(content, holon)
        
        if dry_run:
            return tags
        
        # meta.tagsì— ì €ì¥
        if "meta" not in holon:
            holon["meta"] = {}
        
        holon["meta"]["tags"] = tags.to_dict()
        holon["meta"]["tags_generated_at"] = tags.generated_at
        
        # íŒŒì¼ ì—…ë°ì´íŠ¸
        new_json = json.dumps(holon, ensure_ascii=False, indent=2)
        new_content = re.sub(
            r'```json\s*\n.*?\n```',
            f'```json\n{new_json}\n```',
            content,
            flags=re.DOTALL
        )
        
        filepath.write_text(new_content, encoding="utf-8")
        return tags
    
    def tag_all_documents(self, dry_run: bool = False) -> Dict[str, TagResult]:
        """
        ì „ì²´ ë¬¸ì„œ íƒœê¹…
        
        Args:
            dry_run: Trueë©´ íƒœê·¸ë§Œ ìƒì„±í•˜ê³  ì €ì¥ ì•ˆí•¨
        
        Returns:
            {filepath: TagResult}
        """
        print("=" * 60)
        print("ğŸ·ï¸  Auto-Tagger v3 - ì „ì²´ ë¬¸ì„œ íƒœê¹…")
        print("=" * 60)
        print()
        
        results = {}
        
        # 1. holons í´ë”
        print("ğŸ“ 0 Docs/holons/")
        for md_file in self.holons_path.glob("*.md"):
            if md_file.name.startswith("_"):
                continue
            tags = self.tag_document(md_file, dry_run)
            if tags:
                results[str(md_file)] = tags
                print(f"   âœ… {md_file.name}: {tags.module} + {tags.topic[:2]}...")
        
        # 2. meetings/decisions/tasks í´ë”
        for folder in ["meetings", "decisions", "tasks"]:
            folder_path = self.docs_root / folder
            if folder_path.exists():
                print(f"\nğŸ“ 0 Docs/{folder}/")
                for md_file in folder_path.glob("*.md"):
                    tags = self.tag_document(md_file, dry_run)
                    if tags:
                        results[str(md_file)] = tags
                        print(f"   âœ… {md_file.name}: {tags.role or folder}")
        
        # 3. HTE í´ë”
        if self.hte_path.exists():
            print(f"\nğŸ“ 2 Company/4 HTE/")
            for md_file in self.hte_path.rglob("HTE_*.md"):
                tags = self.tag_document(md_file, dry_run)
                if tags:
                    results[str(md_file)] = tags
                    print(f"   âœ… {md_file.name}: {tags.module}")
        
        print()
        print("=" * 60)
        print(f"ğŸ·ï¸  ì™„ë£Œ! ì´ {len(results)}ê°œ ë¬¸ì„œ íƒœê¹…")
        if dry_run:
            print("   (dry-run ëª¨ë“œ - ì €ì¥ ì•ˆí•¨)")
        print("=" * 60)
        
        return results
    
    def print_tags(self, tags: TagResult):
        """íƒœê·¸ ê²°ê³¼ ì¶œë ¥"""
        print(f"   ëª¨ë“ˆ: {', '.join(tags.module) or '-'}")
        print(f"   ì£¼ì œ: {', '.join(tags.topic) or '-'}")
        print(f"   ì—­í• : {tags.role or '-'}")
        print(f"   í˜ë¥´ì†Œë‚˜: {', '.join(tags.persona) or '-'}")
        print(f"   ê¸´ê¸‰ë„: {tags.urgency or '-'}")
        print(f"   ì‹¤í–‰ê°€ëŠ¥ì„±: {tags.actionability or '-'}")
        print(f"   ì‹ ë¢°ë„: {tags.confidence:.0%}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI ì¸í„°í˜ì´ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """í…ŒìŠ¤íŠ¸/CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Auto-Tagger v3")
    parser.add_argument("--all", action="store_true", help="ì „ì²´ ë¬¸ì„œ íƒœê¹…")
    parser.add_argument("--file", type=str, help="ë‹¨ì¼ íŒŒì¼ íƒœê¹…")
    parser.add_argument("--dry-run", action="store_true", help="ì €ì¥ ì•ˆí•¨")
    
    args = parser.parse_args()
    
    tagger = AutoTagger()
    
    if args.all:
        tagger.tag_all_documents(dry_run=args.dry_run)
    elif args.file:
        filepath = Path(args.file)
        tags = tagger.tag_document(filepath, dry_run=args.dry_run)
        if tags:
            print(f"\nğŸ·ï¸ {filepath.name} íƒœê·¸:")
            tagger.print_tags(tags)
    else:
        # í…ŒìŠ¤íŠ¸
        sample = """# AI íŠœí„° ê°ì • ë¶„ì„ ê¸°ëŠ¥ ì„¤ê³„

ì´ ë¬¸ì„œëŠ” í•™ìƒì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ì„ ì •ì˜í•©ë‹ˆë‹¤.

## ë¬¸ì œ
1. í•™ìƒì´ TTS ìŒì„±ì„ ë“¤ì„ ë•Œ ì§‘ì¤‘ë„ê°€ ë–¨ì–´ì§
2. ì„ ìƒë‹˜ì´ í•™ìƒ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ê¸° ì–´ë ¤ì›€

## í•´ê²°
- ì‹œì„  ì¶”ì  ê¸°ëŠ¥ ì¶”ê°€ í•„ìš”
- ê°ì • ë¶„ì„ AI ì—°ë™ í•„ìš”

## TODO
- ê¹€ì² ìˆ˜ ë‹´ë‹¹: API ì„¤ê³„
"""
        tags = tagger.generate_tags(sample)
        print("ğŸ·ï¸ ìƒ˜í”Œ íƒœê·¸ ê²°ê³¼:")
        tagger.print_tags(tags)


if __name__ == "__main__":
    main()

