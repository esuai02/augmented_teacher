# Quantum Orchestration ì„¤ê³„ì„œ

> 22ê°œ êµìœ¡ AI ì—ì´ì „íŠ¸ë¥¼ ì–‘ìì—­í•™ ê°œë…ìœ¼ë¡œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ì‹œìŠ¤í…œ ì„¤ê³„

**ë²„ì „**: 1.4  
**ì‘ì„±ì¼**: 2025-12-07  
**ìµœì¢… ìˆ˜ì •**: 2025-12-09  
**ì ‘ê·¼ë°©ì‹**: ì§„í™”ì  í†µí•© (ê¸°ì¡´ _brain_engine.py, _memory_engine.py í™•ì¥)  
**ë™ê¸°í™” ìƒíƒœ**: âœ… engine_config.phpì™€ ë™ê¸°í™”ë¨

### ğŸ“š ê´€ë ¨ ë¬¸ì„œ

| ë¬¸ì„œ | ì—­í•  | ë°”ë¡œê°€ê¸° |
|------|------|---------|
| [00-INDEX.md](./00-INDEX.md) | ë¬¸ì„œ í—ˆë¸Œ | ì „ì²´ íƒìƒ‰ |
| [SYSTEM_STATUS.yaml](./SYSTEM_STATUS.yaml) | SSOT | ì‹œìŠ¤í…œ í˜„í™© |
| [quantum-learning-model.md](./quantum-learning-model.md) | ì´ë¡  ê¸°ë°˜ | 13ì¢… Ïˆ, Hamiltonian, í˜ë¥´ì†Œë‚˜ |
| [wavefunction-agent-mapping.md](./wavefunction-agent-mapping.md) | ë§¤í•‘ ê·œì¹™ | 13ì¢… Ïˆ â†” 22ê°œ Agent |
| [quantum-ide-critical-issues.md](./quantum-ide-critical-issues.md) | êµ¬í˜„ ë¬¸ì œì  | 17ê°œ Critical Issues |
| [PRD](../../../tasks/0005-prd-quantum-modeling-completion.md) | êµ¬í˜„ ë¡œë“œë§µ | Phase 0~4 |
| pocdashboard.php | POC êµ¬í˜„ | ì‹œë‚˜ë¦¬ì˜¤ 1~7 |

---

## 1. ê°œìš”

### 1.1 ëª©ì 

í•™ìƒì˜ í•™ìŠµ ìƒíƒœë¥¼ **í™•ë¥  ë²¡í„°**ë¡œ í‘œí˜„í•˜ê³ , 22ê°œ AI ì—ì´ì „íŠ¸ ê°„ì˜ **ìƒê´€ê´€ê³„**ì™€ **ê°„ì„­ íŒ¨í„´**ì„ ìˆ˜í•™ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ì—¬ **ìµœì ì˜ í•™ìŠµ ìƒíƒœ(Flow State)**ë¥¼ ë‹¬ì„±í•œë‹¤.

### 1.2 í•µì‹¬ ê°œë…

| ì–‘ìì—­í•™ ê°œë… | êµìœ¡ ì‹œìŠ¤í…œ ë§¤í•‘ |
|-------------|----------------|
| ìƒíƒœ ì¤‘ì²© (Superposition) | í•™ìƒì˜ ë‹¤ì°¨ì› í•™ìŠµ ìƒíƒœ |
| ì–½í˜ (Entanglement) | ì—ì´ì „íŠ¸ ê°„ ìƒê´€ê´€ê³„ |
| ê°„ì„­ (Interference) | ë‹¤ì¤‘ ì‹ í˜¸ì˜ ë³´ê°•/ìƒì‡„ |
| í•´ë°€í† ë‹ˆì•ˆ ì§„í™” | Flow State ìµœì í™” |
| íŒŒë™í•¨ìˆ˜ ë¶•ê´´ | ìµœì¢… ì˜ì‚¬ê²°ì • (Step 21) |

### 1.3 ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ì˜ ê´€ê³„

```
ê¸°ì¡´ êµ¬ì¡°                           í™•ì¥ êµ¬ì¡°
-----------                        -----------
MemoryWeights (4ê°€ì¤‘ì¹˜)      â†’      StudentStateVector (64ì°¨ì›)
MemoryScore (5ì»´í¬ë„ŒíŠ¸)      â†’      EntanglementMap (21x21 ìƒê´€)
calculate_composite_score() â†’      HamiltonianEvolution.evolve_to_flow_state()
```

---

## 2. ì•„í‚¤í…ì²˜

### 2.1 ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Quantum Orchestrator                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   í•™ìƒ ìƒíƒœ   â”‚  â”‚  ì—ì´ì „íŠ¸ ë§µ  â”‚  â”‚   ìµœì í™”ê¸°    â”‚      â”‚
â”‚  â”‚ StateVector  â”‚  â”‚ Entanglement â”‚  â”‚ Hamiltonian  â”‚      â”‚
â”‚  â”‚   (64dim)    â”‚  â”‚   (21x21)    â”‚  â”‚  Evolution   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚                  â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â”‚                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚   InterferenceCalc    â”‚                     â”‚
â”‚              â”‚    (ì‹ í˜¸ ê°„ì„­ ê³„ì‚°)     â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â”‚                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚    Decision Engine    â”‚                     â”‚
â”‚              â”‚  (Step 21 ìµœì¢… íŒë‹¨)   â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ë°ì´í„° íë¦„

```mermaid
graph LR
    A[í•™ìƒ ì…ë ¥] --> B[StateVector ìƒì„±]
    B --> C[21 ì—ì´ì „íŠ¸ ì‹ í˜¸]
    C --> D[Interference ê³„ì‚°]
    D --> E[Hamiltonian ì§„í™”]
    E --> F[Flow State ìˆ˜ë ´]
    F --> G[ìµœì¢… ê²°ì •]
```

---

## 3. í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 3.1 StudentStateVector (í•™ìƒ ìƒíƒœ ë²¡í„°)

**íŒŒì¼**: `holons/_quantum_state.py` (ì‹ ê·œ)

```python
from dataclasses import dataclass, field
from typing import List
import numpy as np

@dataclass
class StudentStateVector:
    """
    í•™ìƒì˜ í•™ìŠµ ìƒíƒœë¥¼ 64ì°¨ì› í™•ë¥  ë²¡í„°ë¡œ í‘œí˜„

    ê° ì°¨ì›ì€ [0.0, 1.0] ë²”ìœ„ì˜ í™•ë¥ ê°’
    0.5 = ì¤‘ë¦½ ìƒíƒœ (ì •ë³´ ë¶€ì¡±)
    """

    # === ì¸ì§€ ì°¨ì› (16) ===
    concept_mastery: float = 0.5      # ê°œë… ì´í•´ë„
    procedural_fluency: float = 0.5   # ì ˆì°¨ì  ìœ ì°½ì„±
    cognitive_load: float = 0.5       # ì¸ì§€ ë¶€í•˜
    attention_level: float = 0.5      # ì§‘ì¤‘ë„
    working_memory: float = 0.5       # ì‘ì—… ê¸°ì–µ ìš©ëŸ‰
    metacognition: float = 0.5        # ë©”íƒ€ì¸ì§€ ìˆ˜ì¤€
    transfer_ability: float = 0.5     # ì „ì´ ëŠ¥ë ¥
    problem_representation: float = 0.5  # ë¬¸ì œ í‘œìƒ ëŠ¥ë ¥
    schema_activation: float = 0.5    # ìŠ¤í‚¤ë§ˆ í™œì„±í™”
    retrieval_strength: float = 0.5   # ì¸ì¶œ ê°•ë„
    encoding_depth: float = 0.5       # ì¸ì½”ë”© ê¹Šì´
    elaboration: float = 0.5          # ì •êµí™” ìˆ˜ì¤€
    retention_strength: float = 0.5   # ê¸°ì–µ ìœ ì§€ ê°•ë„
    discrimination: float = 0.5       # ë³€ë³„ ëŠ¥ë ¥
    generalization: float = 0.5       # ì¼ë°˜í™” ëŠ¥ë ¥
    cognitive_flexibility: float = 0.5  # ì¸ì§€ì  ìœ ì—°ì„±

    # === ì •ì„œ ì°¨ì› (16) ===
    motivation: float = 0.5           # ë‚´ì¬ì  ë™ê¸°
    self_efficacy: float = 0.5        # ìê¸° íš¨ëŠ¥ê°
    confidence: float = 0.5           # ìì‹ ê°
    curiosity: float = 0.5            # í˜¸ê¸°ì‹¬
    interest: float = 0.5             # í¥ë¯¸
    anxiety: float = 0.5              # ë¶ˆì•ˆ (ì—­ë°©í–¥)
    frustration: float = 0.5          # ì¢Œì ˆê° (ì—­ë°©í–¥)
    boredom: float = 0.5              # ì§€ë£¨í•¨ (ì—­ë°©í–¥)
    confusion: float = 0.5            # í˜¼ë€ (ì¡°ê±´ë¶€)
    engagement_emotion: float = 0.5   # ì •ì„œì  ëª°ì…
    achievement_emotion: float = 0.5  # ì„±ì·¨ ê°ì •
    social_emotion: float = 0.5       # ì‚¬íšŒì  ê°ì •
    epistemic_emotion: float = 0.5    # ì¸ì‹ë¡ ì  ê°ì •
    growth_mindset: float = 0.5       # ì„±ì¥ ë§ˆì¸ë“œì…‹
    resilience: float = 0.5           # íšŒë³µíƒ„ë ¥ì„±
    emotional_regulation: float = 0.5  # ê°ì • ì¡°ì ˆ

    # === í–‰ë™ ì°¨ì› (16) ===
    engagement_behavior: float = 0.5  # í–‰ë™ì  ì°¸ì—¬
    persistence: float = 0.5          # ê³¼ì œ ì§€ì†ì„±
    help_seeking: float = 0.5         # ë„ì›€ ìš”ì²­ í–‰ë™
    self_regulation: float = 0.5      # ìê¸° ì¡°ì ˆ
    time_management: float = 0.5      # ì‹œê°„ ê´€ë¦¬
    effort_investment: float = 0.5    # ë…¸ë ¥ íˆ¬ì
    strategy_use: float = 0.5         # í•™ìŠµ ì „ëµ ì‚¬ìš©
    practice_frequency: float = 0.5   # ì—°ìŠµ ë¹ˆë„
    review_behavior: float = 0.5      # ë³µìŠµ í–‰ë™
    note_taking: float = 0.5          # ë…¸íŠ¸ ì •ë¦¬
    question_asking: float = 0.5      # ì§ˆë¬¸ í–‰ë™
    collaboration: float = 0.5        # í˜‘ë ¥ í•™ìŠµ
    resource_utilization: float = 0.5  # ìì› í™œìš©
    goal_setting: float = 0.5         # ëª©í‘œ ì„¤ì •
    self_monitoring: float = 0.5      # ìê¸° ëª¨ë‹ˆí„°ë§
    adaptive_behavior: float = 0.5    # ì ì‘ì  í–‰ë™

    # === ì»¨í…ìŠ¤íŠ¸ ì°¨ì› (16) ===
    time_pressure: float = 0.5        # ì‹œê°„ ì••ë°•
    time_of_day: float = 0.5          # í•™ìŠµ ì‹œê°„ëŒ€
    session_duration: float = 0.5     # í•™ìŠµ ì„¸ì…˜ ê¸¸ì´
    break_pattern: float = 0.5        # íœ´ì‹ íŒ¨í„´
    social_context: float = 0.5       # ì‚¬íšŒì  ë§¥ë½
    peer_influence: float = 0.5       # ë˜ë˜ ì˜í–¥
    teacher_support: float = 0.5      # êµì‚¬ ì§€ì›
    family_support: float = 0.5       # ê°€ì • ì§€ì›
    physical_fatigue: float = 0.5     # ì‹ ì²´ í”¼ë¡œ
    sleep_quality: float = 0.5        # ìˆ˜ë©´ í’ˆì§ˆ
    nutrition_state: float = 0.5      # ì˜ì–‘ ìƒíƒœ
    environment_fit: float = 0.5      # ë¬¼ë¦¬ì  í™˜ê²½
    distraction_level: float = 0.5    # ë°©í•´ ìš”ì†Œ
    technology_access: float = 0.5    # ê¸°ìˆ  ì ‘ê·¼ì„±
    content_difficulty: float = 0.5   # ì½˜í…ì¸  ë‚œì´ë„
    prior_knowledge: float = 0.5      # ì„ í–‰ ì§€ì‹

    def to_vector(self) -> np.ndarray:
        """64ì°¨ì› numpy ë²¡í„°ë¡œ ë³€í™˜"""
        return np.array([getattr(self, f.name) for f in fields(self)])

    @classmethod
    def from_vector(cls, vec: np.ndarray) -> 'StudentStateVector':
        """numpy ë²¡í„°ì—ì„œ StudentStateVector ìƒì„±"""
        field_names = [f.name for f in fields(cls)]
        return cls(**{name: float(vec[i]) for i, name in enumerate(field_names)})

    def normalize(self) -> 'StudentStateVector':
        """í™•ë¥  ë²¡í„° ì •ê·œí™” (í•© = 1)"""
        vec = self.to_vector()
        normalized = vec / vec.sum()
        return self.from_vector(normalized)

    def inner_product(self, other: 'StudentStateVector') -> float:
        """ë‘ ìƒíƒœ ë²¡í„°ì˜ ë‚´ì  (ìœ ì‚¬ë„)"""
        return float(np.dot(self.to_vector(), other.to_vector()))
```

### 3.2 EntanglementMap (ì—ì´ì „íŠ¸ ì–½í˜ ë§µ)

**íŒŒì¼**: `holons/_quantum_entanglement.py` (ì‹ ê·œ)

```python
from dataclasses import dataclass
from typing import Dict, List, Tuple
import numpy as np
from math import pi

@dataclass
class EntanglementEdge:
    """ë‘ ì—ì´ì „íŠ¸ ê°„ì˜ ì–½í˜ ê´€ê³„"""
    agent_a: int           # ì—ì´ì „íŠ¸ ë²ˆí˜¸ (1-21)
    agent_b: int           # ìƒëŒ€ ì—ì´ì „íŠ¸ ë²ˆí˜¸
    correlation: float     # ìƒê´€ ê°•ë„ (-1.0 ~ 1.0)
    phase: float           # ìœ„ìƒ (0 ~ 2Ï€)
    description: str = ""  # ê´€ê³„ ì„¤ëª…

    def __post_init__(self):
        if not -1.0 <= self.correlation <= 1.0:
            raise ValueError(f"correlation must be in [-1, 1], got {self.correlation}")
        if not 0 <= self.phase <= 2 * pi:
            self.phase = self.phase % (2 * pi)


class EntanglementMap:
    """
    22ê°œ ì—ì´ì „íŠ¸ì˜ ì–½í˜ ê´€ê³„ ê·¸ë˜í”„

    - ì–‘ì˜ ìƒê´€ (correlation > 0): ë™ì‹œ í™œì„±í™” ê²½í–¥
    - ìŒì˜ ìƒê´€ (correlation < 0): ìƒí˜¸ ì–µì œ ê²½í–¥
    - ìœ„ìƒ: ì‹ í˜¸ ê°„ì„­ ì‹œ ì‚¬ìš©
    
    âš ï¸ AGENTS ì •ì˜ëŠ” engine_config.phpì™€ ë™ê¸°í™”ë¨ (SSOT)
    """

    # 22ê°œ ì—ì´ì „íŠ¸ ì •ì˜ (engine_config.php ê¸°ì¤€)
    AGENTS = {
        1: "ì˜¨ë³´ë”©",              # onboarding
        2: "ì‹œí—˜ì¼ì •",            # exam_schedule
        3: "ëª©í‘œë¶„ì„",            # goals_analysis
        4: "ì•½ì ê²€ì‚¬",            # inspect_weakpoints
        5: "í•™ìŠµê°ì •",            # learning_emotion
        6: "êµì‚¬í”¼ë“œë°±",          # teacher_feedback
        7: "ìƒí˜¸ì‘ìš©íƒ€ê²ŸíŒ…",      # interaction_targeting
        8: "í‰ì˜¨ë„",              # calmness
        9: "í•™ìŠµê´€ë¦¬",            # learning_management
        10: "ê°œë…ë…¸íŠ¸",           # concept_notes
        11: "ë¬¸ì œë…¸íŠ¸",           # problem_notes
        12: "íœ´ì‹ë£¨í‹´",           # rest_routine
        13: "í•™ìŠµì´íƒˆ",           # learning_dropout
        14: "í˜„ì¬ìœ„ì¹˜",           # current_position
        15: "ë¬¸ì œì¬ì •ì˜",         # problem_redefinition
        16: "ìƒí˜¸ì‘ìš©ì¤€ë¹„",       # interaction_preparation
        17: "ë‚¨ì€í™œë™",           # remaining_activities
        18: "ì‹œê·¸ë‹ˆì²˜ë£¨í‹´",       # signature_routine
        19: "ìƒí˜¸ì‘ìš©ì½˜í…ì¸ ",     # interaction_content
        20: "ê°œì…ì¤€ë¹„",           # intervention_preparation
        21: "ê°œì…ì‹¤í–‰",           # intervention_execution
        22: "ëª¨ë“ˆê°œì„ "            # module_improvement
    }

    # í•µì‹¬ ì–½í˜ ê´€ê³„ (ì‹¤ì œ ì—ì´ì „íŠ¸ ê¸°ë°˜, engine_config.phpì™€ ë™ê¸°í™”)
    CORE_ENTANGLEMENTS: List[EntanglementEdge] = [
        # === Phase 1: ì •ë³´ ìˆ˜ì§‘ ì¶• ===
        EntanglementEdge(1, 3, 0.9, 0, "ì˜¨ë³´ë”©â†’ëª©í‘œë¶„ì„ ìˆœì°¨"),
        EntanglementEdge(3, 4, 0.85, pi/6, "ëª©í‘œë¶„ì„â†’ì•½ì ê²€ì‚¬"),
        EntanglementEdge(2, 17, 0.8, 0, "ì‹œí—˜ì¼ì •â†’ë‚¨ì€í™œë™ ì—°ë™"),

        # === ê°ì •-ìƒíƒœ ê´€ë¦¬ ì¶• ===
        EntanglementEdge(5, 8, 0.9, 0, "í•™ìŠµê°ì •â†’í‰ì˜¨ë„ ì—°ë™"),
        EntanglementEdge(8, 13, 0.85, pi/4, "í‰ì˜¨ë„â†’í•™ìŠµì´íƒˆ ì˜ˆë°©"),
        EntanglementEdge(5, 6, 0.7, 0, "í•™ìŠµê°ì •â†’êµì‚¬í”¼ë“œë°± ë°˜ì˜"),

        # === í•™ìŠµ ê´€ë¦¬ ì¶• ===
        EntanglementEdge(9, 14, 0.85, 0, "í•™ìŠµê´€ë¦¬â†’í˜„ì¬ìœ„ì¹˜ íŒŒì•…"),
        EntanglementEdge(9, 17, 0.8, pi/6, "í•™ìŠµê´€ë¦¬â†’ë‚¨ì€í™œë™ ê³„íš"),
        EntanglementEdge(14, 15, 0.75, 0, "í˜„ì¬ìœ„ì¹˜â†’ë¬¸ì œì¬ì •ì˜"),

        # === ë…¸íŠ¸-ë£¨í‹´ ì¶• ===
        EntanglementEdge(10, 11, 0.9, 0, "ê°œë…ë…¸íŠ¸â†”ë¬¸ì œë…¸íŠ¸"),
        EntanglementEdge(12, 18, 0.85, pi/6, "íœ´ì‹ë£¨í‹´â†’ì‹œê·¸ë‹ˆì²˜ë£¨í‹´"),

        # === ìƒí˜¸ì‘ìš© ì¶• ===
        EntanglementEdge(7, 16, 0.9, 0, "ìƒí˜¸ì‘ìš©íƒ€ê²ŸíŒ…â†’ìƒí˜¸ì‘ìš©ì¤€ë¹„"),
        EntanglementEdge(16, 19, 0.85, 0, "ìƒí˜¸ì‘ìš©ì¤€ë¹„â†’ìƒí˜¸ì‘ìš©ì½˜í…ì¸ "),

        # === ê°œì… ì¶• ===
        EntanglementEdge(20, 21, 0.95, 0, "ê°œì…ì¤€ë¹„â†’ê°œì…ì‹¤í–‰ ìˆœì°¨"),
        EntanglementEdge(13, 20, 0.85, pi/4, "í•™ìŠµì´íƒˆâ†’ê°œì…ì¤€ë¹„ íŠ¸ë¦¬ê±°"),

        # === ì‹œìŠ¤í…œ ê°œì„  ì¶• ===
        EntanglementEdge(21, 22, 0.7, pi/6, "ê°œì…ì‹¤í–‰â†’ëª¨ë“ˆê°œì„  í”¼ë“œë°±"),

        # === ì–µì œ ê´€ê³„ (ìŒì˜ ìƒê´€) ===
        EntanglementEdge(13, 8, -0.4, pi, "í•™ìŠµì´íƒˆâ†”í‰ì˜¨ë„ ì—­ìƒê´€"),
        EntanglementEdge(5, 12, -0.3, pi, "ë¶€ì •ê°ì •â†”íœ´ì‹ë£¨í‹´ ë°©í•´"),
    ]

    def __init__(self, custom_edges: List[EntanglementEdge] = None):
        self.edges = self.CORE_ENTANGLEMENTS.copy()
        if custom_edges:
            self.edges.extend(custom_edges)
        self._build_correlation_matrix()

    def _build_correlation_matrix(self):
        """22x22 ìƒê´€í–‰ë ¬ ìƒì„±"""
        self._matrix = np.eye(22)  # ëŒ€ê°ì„  = 1
        self._phase_matrix = np.zeros((22, 22))

        for edge in self.edges:
            i, j = edge.agent_a - 1, edge.agent_b - 1
            self._matrix[i, j] = edge.correlation
            self._matrix[j, i] = edge.correlation
            self._phase_matrix[i, j] = edge.phase
            self._phase_matrix[j, i] = -edge.phase  # ëŒ€ì¹­ ìœ„ìƒ

    def get_correlation(self, agent_a: int, agent_b: int) -> float:
        """ë‘ ì—ì´ì „íŠ¸ ê°„ ìƒê´€ê³„ìˆ˜"""
        return self._matrix[agent_a - 1, agent_b - 1]

    def get_phase(self, agent_a: int, agent_b: int) -> float:
        """ë‘ ì—ì´ì „íŠ¸ ê°„ ìœ„ìƒì°¨"""
        return self._phase_matrix[agent_a - 1, agent_b - 1]

    def get_correlation_matrix(self) -> np.ndarray:
        """ì „ì²´ ìƒê´€í–‰ë ¬ ë°˜í™˜"""
        return self._matrix.copy()

    def get_strongly_correlated_pairs(self, threshold: float = 0.7) -> List[Tuple[int, int, float]]:
        """ê°•í•œ ìƒê´€ê´€ê³„ ìŒ ë°˜í™˜"""
        pairs = []
        for i in range(22):
            for j in range(i + 1, 22):
                if abs(self._matrix[i, j]) >= threshold:
                    pairs.append((i + 1, j + 1, self._matrix[i, j]))
        return sorted(pairs, key=lambda x: -abs(x[2]))
```

### 3.3 InterferenceCalculator (ê°„ì„­ ê³„ì‚°ê¸°)

**íŒŒì¼**: `holons/_quantum_interference.py` (ì‹ ê·œ)

```python
from dataclasses import dataclass
from typing import Dict, Tuple, List
import numpy as np
from math import cos, sin

@dataclass
class AgentSignal:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ ì‹ í˜¸"""
    agent_id: int
    amplitude: float      # ì‹ í˜¸ ê°•ë„ [0, 1]
    phase: float          # ì‹ í˜¸ ìœ„ìƒ [0, 2Ï€]
    confidence: float     # ì‹ ë¢°ë„ [0, 1]


class InterferenceCalculator:
    """
    ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹ í˜¸ì˜ ì–‘ì ê°„ì„­ ê³„ì‚°

    í•µì‹¬ ì›ë¦¬:
    - ë™ìœ„ìƒ ì‹ í˜¸: ë³´ê°• ê°„ì„­ (í•©ì‚°)
    - ì—­ìœ„ìƒ ì‹ í˜¸: ìƒì‡„ ê°„ì„­ (ìƒì‡„)
    - ì–½í˜ ìƒê´€ê³„ìˆ˜ê°€ ê°„ì„­ ê°•ë„ë¥¼ ì¡°ì ˆ
    """

    def __init__(self, entanglement_map: 'EntanglementMap'):
        self.entanglement = entanglement_map

    def calculate_total_interference(
        self,
        signals: List[AgentSignal]
    ) -> Tuple[float, Dict[str, float]]:
        """
        ë‹¤ì¤‘ ì‹ í˜¸ì˜ ì´ ê°„ì„­ ê²°ê³¼ ê³„ì‚°

        Returns:
            (total_intensity, details_dict)
        """
        n = len(signals)
        if n == 0:
            return 0.0, {}

        total = 0.0
        constructive = 0.0
        destructive = 0.0

        for i, sig_i in enumerate(signals):
            # ìê¸° ê°„ì„­ í•­
            self_term = sig_i.amplitude ** 2 * sig_i.confidence
            total += self_term
            constructive += self_term

            for sig_j in signals[i + 1:]:
                # êµì°¨ ê°„ì„­ í•­
                corr = self.entanglement.get_correlation(sig_i.agent_id, sig_j.agent_id)
                phase_diff = sig_i.phase - sig_j.phase

                # ê°„ì„­ ê³µì‹: 2 * A_i * A_j * cos(Ï†_i - Ï†_j) * correlation
                cross_term = (
                    2 * sig_i.amplitude * sig_j.amplitude
                    * cos(phase_diff)
                    * corr
                    * min(sig_i.confidence, sig_j.confidence)
                )

                total += cross_term

                if cross_term > 0:
                    constructive += cross_term
                else:
                    destructive += abs(cross_term)

        details = {
            "total_intensity": total,
            "constructive": constructive,
            "destructive": destructive,
            "net_gain": constructive - destructive,
            "interference_ratio": constructive / (destructive + 1e-10)
        }

        return total, details

    def find_resonance_pattern(
        self,
        signals: List[AgentSignal],
        target_agents: List[int] = None
    ) -> List[AgentSignal]:
        """
        ìµœëŒ€ ë³´ê°• ê°„ì„­ì„ ìœ„í•œ ìœ„ìƒ ì¡°ì •

        Args:
            signals: í˜„ì¬ ì‹ í˜¸ë“¤
            target_agents: ê³µëª…ì‹œí‚¬ ëŒ€ìƒ ì—ì´ì „íŠ¸ë“¤ (Noneì´ë©´ ì „ì²´)

        Returns:
            ìœ„ìƒ ì¡°ì •ëœ ì‹ í˜¸ ë¦¬ìŠ¤íŠ¸
        """
        if target_agents is None:
            target_agents = [s.agent_id for s in signals]

        adjusted = []
        reference_phase = signals[0].phase if signals else 0

        for sig in signals:
            if sig.agent_id in target_agents:
                # íƒ€ê²Ÿ ì—ì´ì „íŠ¸ëŠ” ê¸°ì¤€ ìœ„ìƒìœ¼ë¡œ ì •ë ¬
                new_phase = reference_phase
            else:
                # ë¹„íƒ€ê²Ÿì€ í˜„ì¬ ìœ„ìƒ ìœ ì§€
                new_phase = sig.phase

            adjusted.append(AgentSignal(
                agent_id=sig.agent_id,
                amplitude=sig.amplitude,
                phase=new_phase,
                confidence=sig.confidence
            ))

        return adjusted
```

### 3.4 HamiltonianEvolution (í•´ë°€í† ë‹ˆì•ˆ ì§„í™”)

**íŒŒì¼**: `holons/_quantum_evolution.py` (ì‹ ê·œ)

```python
from dataclasses import dataclass
from typing import Dict, List, Optional, Callable
import numpy as np

@dataclass
class EvolutionConfig:
    """ì§„í™” ì•Œê³ ë¦¬ì¦˜ ì„¤ì •"""
    learning_rate: float = 0.1
    max_iterations: int = 100
    convergence_threshold: float = 1e-6
    regularization: float = 0.01


class HamiltonianEvolution:
    """
    í•™ìƒ ìƒíƒœì˜ ì‹œê°„ ì§„í™” - Flow State ìµœì í™”

    ë¬¼ë¦¬í•™ ê°œë…:
    - Hamiltonian: ì‹œìŠ¤í…œì˜ ì´ ì—ë„ˆì§€ ì—°ì‚°ì
    - ì—ë„ˆì§€ ìµœì†Œí™” = ìµœì  ìƒíƒœ íƒìƒ‰

    êµìœ¡í•™ ë§¤í•‘:
    - ë‚®ì€ ì—ë„ˆì§€ = ë†’ì€ í•™ìŠµ íš¨ìœ¨ (Flow State)
    - ë†’ì€ ì—ë„ˆì§€ = í•™ìŠµ ì €í•´ ìš”ì¸ ì¡´ì¬
    """

    # ì—ì´ì „íŠ¸ë³„ ìƒíƒœ ì°¨ì› ë§¤í•‘ (engine_config.phpì™€ ë™ê¸°í™”)
    AGENT_STATE_MAPPING: Dict[int, Dict[str, List[str]]] = {
        1: {  # ì˜¨ë³´ë”©
            "positive": ["goal_setting", "prior_knowledge", "engagement_behavior"],
            "negative": ["confusion", "anxiety"]
        },
        3: {  # ëª©í‘œë¶„ì„
            "positive": ["goal_setting", "metacognition", "self_monitoring"],
            "negative": ["confusion", "distraction_level"]
        },
        4: {  # ì•½ì ê²€ì‚¬
            "positive": ["concept_mastery", "discrimination", "retrieval_strength"],
            "negative": ["cognitive_load", "confusion"]
        },
        5: {  # í•™ìŠµê°ì •
            "positive": ["emotional_regulation", "engagement_emotion", "resilience"],
            "negative": ["anxiety", "frustration", "boredom"]
        },
        8: {  # í‰ì˜¨ë„
            "positive": ["emotional_regulation", "confidence", "resilience"],
            "negative": ["anxiety", "frustration"]
        },
        9: {  # í•™ìŠµê´€ë¦¬
            "positive": ["time_management", "self_regulation", "adaptive_behavior"],
            "negative": ["distraction_level", "time_pressure"]
        },
        13: {  # í•™ìŠµì´íƒˆ
            "positive": ["persistence", "motivation", "engagement_behavior"],
            "negative": ["boredom", "frustration", "distraction_level"]
        },
        14: {  # í˜„ì¬ìœ„ì¹˜
            "positive": ["metacognition", "self_monitoring", "concept_mastery"],
            "negative": ["confusion", "cognitive_load"]
        },
        20: {  # ê°œì…ì¤€ë¹„
            "positive": ["teacher_support", "help_seeking", "adaptive_behavior"],
            "negative": ["anxiety", "social_emotion"]
        },
        21: {  # ê°œì…ì‹¤í–‰
            "positive": ["engagement_behavior", "attention_level", "confidence"],
            "negative": ["anxiety", "confusion"]
        },
        22: {  # ëª¨ë“ˆê°œì„ 
            "positive": ["adaptive_behavior", "self_monitoring", "strategy_use"],
            "negative": []  # ì‹œìŠ¤í…œ ë ˆë²¨
        }
        # ë‚˜ë¨¸ì§€ ì—ì´ì „íŠ¸ëŠ” í•„ìš” ì‹œ í™•ì¥
    }

    def __init__(
        self,
        entanglement: 'EntanglementMap',
        config: EvolutionConfig = None
    ):
        self.entanglement = entanglement
        self.config = config or EvolutionConfig()
        self._iteration_history: List[float] = []

    def compute_hamiltonian(
        self,
        state: 'StudentStateVector'
    ) -> np.ndarray:
        """
        ì‹œìŠ¤í…œ í•´ë°€í† ë‹ˆì•ˆ êµ¬ì„±

        H = H_local + H_interaction

        - H_local: í•™ìƒ ìƒíƒœ ê¸°ë°˜ ë¡œì»¬ ì—ë„ˆì§€
        - H_interaction: ì—ì´ì „íŠ¸ ê°„ ìƒí˜¸ì‘ìš© ì—ë„ˆì§€
        """
        n = 21
        H = np.zeros((n, n))

        # ë¡œì»¬ ì—ë„ˆì§€ í•­
        for agent_id in range(1, n + 1):
            H[agent_id - 1, agent_id - 1] = self._local_energy(agent_id, state)

        # ìƒí˜¸ì‘ìš© í•­ (ì–½í˜ ê¸°ë°˜)
        interaction_strength = 0.1  # í•˜ì´í¼íŒŒë¼ë¯¸í„°
        correlation_matrix = self.entanglement.get_correlation_matrix()
        H += correlation_matrix * interaction_strength

        return H

    def _local_energy(self, agent_id: int, state: 'StudentStateVector') -> float:
        """
        ì—ì´ì „íŠ¸ë³„ ë¡œì»¬ ì—ë„ˆì§€ ê³„ì‚°

        ì—ë„ˆì§€ = - Î£(positive_dims) + Î£(negative_dims)
        (ë‚®ì€ ì—ë„ˆì§€ = ì¢‹ì€ ìƒíƒœ)
        """
        mapping = self.AGENT_STATE_MAPPING.get(agent_id, {})
        if not mapping:
            return 0.0

        state_vec = state.__dict__

        positive_sum = sum(
            state_vec.get(dim, 0.5)
            for dim in mapping.get("positive", [])
        )
        negative_sum = sum(
            state_vec.get(dim, 0.5)
            for dim in mapping.get("negative", [])
        )

        return -positive_sum + negative_sum

    def evolve_to_flow_state(
        self,
        initial_state: 'StudentStateVector',
        target_state: Optional['StudentStateVector'] = None
    ) -> 'StudentStateVector':
        """
        ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ Flow State ìˆ˜ë ´

        Update rule: Ïˆ_new = Ïˆ - Î· * âˆ‡E(Ïˆ)

        Args:
            initial_state: ì´ˆê¸° í•™ìƒ ìƒíƒœ
            target_state: ëª©í‘œ ìƒíƒœ (Noneì´ë©´ ì—ë„ˆì§€ ìµœì†Œí™”)

        Returns:
            ìµœì í™”ëœ StudentStateVector
        """
        state_vec = initial_state.to_vector()
        cfg = self.config
        self._iteration_history = []

        for iteration in range(cfg.max_iterations):
            H = self.compute_hamiltonian(
                StudentStateVector.from_vector(state_vec)
            )

            # í˜„ì¬ ì—ë„ˆì§€
            # (21ì°¨ì› ì¶•ì†Œ -> 64ì°¨ì› ìƒíƒœ ë²¡í„°ì— íˆ¬ì˜)
            energy = self._compute_total_energy(state_vec, H)
            self._iteration_history.append(energy)

            # ê²½ì‚¬ ê³„ì‚° (ìˆ˜ì¹˜ ë¯¸ë¶„)
            gradient = self._numerical_gradient(state_vec, H)

            # ì—…ë°ì´íŠ¸
            state_vec = state_vec - cfg.learning_rate * gradient

            # ê°’ ë²”ìœ„ í´ë¦¬í•‘ [0, 1]
            state_vec = np.clip(state_vec, 0.0, 1.0)

            # ìˆ˜ë ´ ì²´í¬
            if len(self._iteration_history) > 1:
                delta = abs(self._iteration_history[-1] - self._iteration_history[-2])
                if delta < cfg.convergence_threshold:
                    break

        return StudentStateVector.from_vector(state_vec)

    def _compute_total_energy(self, state_vec: np.ndarray, H: np.ndarray) -> float:
        """ì´ ì‹œìŠ¤í…œ ì—ë„ˆì§€ ê³„ì‚°"""
        # 64ì°¨ì› ìƒíƒœë¥¼ 21ì°¨ì› ì—ì´ì „íŠ¸ í™œì„±í™”ë¡œ íˆ¬ì˜
        agent_activation = self._state_to_agent_activation(state_vec)
        return float(agent_activation @ H @ agent_activation)

    def _state_to_agent_activation(self, state_vec: np.ndarray) -> np.ndarray:
        """64ì°¨ì› í•™ìƒ ìƒíƒœ â†’ 22ì°¨ì› ì—ì´ì „íŠ¸ í™œì„±í™”"""
        activation = np.zeros(22)
        for agent_id in range(1, 23):
            mapping = self.AGENT_STATE_MAPPING.get(agent_id, {})
            positive_dims = mapping.get("positive", [])

            # í•´ë‹¹ ì—ì´ì „íŠ¸ ê´€ë ¨ ì°¨ì›ë“¤ì˜ í‰ê· 
            if positive_dims:
                indices = [self._dim_to_index(dim) for dim in positive_dims]
                activation[agent_id - 1] = np.mean([state_vec[i] for i in indices if i >= 0])
            else:
                activation[agent_id - 1] = 0.5

        return activation

    def _dim_to_index(self, dim_name: str) -> int:
        """ì°¨ì› ì´ë¦„ â†’ ì¸ë±ìŠ¤ ë³€í™˜"""
        # StudentStateVectorì˜ í•„ë“œ ìˆœì„œì™€ ë§¤ì¹­
        dim_order = [
            # ì¸ì§€ 16
            "concept_mastery", "procedural_fluency", "cognitive_load", "attention_level",
            "working_memory", "metacognition", "transfer_ability", "problem_representation",
            "schema_activation", "retrieval_strength", "encoding_depth", "elaboration",
            "retention_strength", "discrimination", "generalization", "cognitive_flexibility",
            # ì •ì„œ 16
            "motivation", "self_efficacy", "confidence", "curiosity", "interest",
            "anxiety", "frustration", "boredom", "confusion", "engagement_emotion",
            "achievement_emotion", "social_emotion", "epistemic_emotion", "growth_mindset",
            "resilience", "emotional_regulation",
            # í–‰ë™ 16
            "engagement_behavior", "persistence", "help_seeking", "self_regulation",
            "time_management", "effort_investment", "strategy_use", "practice_frequency",
            "review_behavior", "note_taking", "question_asking", "collaboration",
            "resource_utilization", "goal_setting", "self_monitoring", "adaptive_behavior",
            # ì»¨í…ìŠ¤íŠ¸ 16
            "time_pressure", "time_of_day", "session_duration", "break_pattern",
            "social_context", "peer_influence", "teacher_support", "family_support",
            "physical_fatigue", "sleep_quality", "nutrition_state", "environment_fit",
            "distraction_level", "technology_access", "content_difficulty", "prior_knowledge"
        ]
        try:
            return dim_order.index(dim_name)
        except ValueError:
            return -1

    def _numerical_gradient(self, state_vec: np.ndarray, H: np.ndarray) -> np.ndarray:
        """ìˆ˜ì¹˜ ë¯¸ë¶„ìœ¼ë¡œ ê²½ì‚¬ ê³„ì‚°"""
        epsilon = 1e-5
        gradient = np.zeros_like(state_vec)

        for i in range(len(state_vec)):
            state_plus = state_vec.copy()
            state_plus[i] += epsilon

            state_minus = state_vec.copy()
            state_minus[i] -= epsilon

            energy_plus = self._compute_total_energy(state_plus, H)
            energy_minus = self._compute_total_energy(state_minus, H)

            gradient[i] = (energy_plus - energy_minus) / (2 * epsilon)

        return gradient

    def get_convergence_history(self) -> List[float]:
        """ì—ë„ˆì§€ ìˆ˜ë ´ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self._iteration_history.copy()
```

---

## 4. ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©

### 4.1 _brain_engine.py í™•ì¥

ê¸°ì¡´ `MemoryWeights` ì‹œìŠ¤í…œê³¼ ìƒˆë¡œìš´ `StudentStateVector`ë¥¼ ì—°ê²°:

```python
# holons/_brain_engine.py ì— ì¶”ê°€

from holons._quantum_state import StudentStateVector
from holons._quantum_evolution import HamiltonianEvolution

class EnhancedBrainEngine(BrainEngine):
    """ê¸°ì¡´ BrainEngine + Quantum Orchestration"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.entanglement = EntanglementMap()
        self.evolution = HamiltonianEvolution(self.entanglement)

    def calculate_quantum_score(
        self,
        holon: dict,
        student_state: StudentStateVector
    ) -> float:
        """
        ê¸°ì¡´ composite_score + í•™ìƒ ìƒíƒœ ë°˜ì˜
        """
        # ê¸°ì¡´ ìŠ¤ì½”ì–´
        base_score = self.calculate_composite_score(holon)

        # Quantum ì¡°ì •
        optimized_state = self.evolution.evolve_to_flow_state(student_state)
        flow_factor = self._calculate_flow_factor(optimized_state)

        return base_score * flow_factor

    def _calculate_flow_factor(self, state: StudentStateVector) -> float:
        """Flow State ê·¼ì ‘ë„ ê³„ì‚° (0.5 ~ 1.5 ë²”ìœ„)"""
        # í•µì‹¬ Flow ì§€í‘œë“¤ì˜ ê°€ì¤‘ í‰ê· 
        flow_indicators = [
            state.attention_level,
            state.engagement_behavior,
            state.motivation,
            1 - state.anxiety,  # ì—­ë°©í–¥
            1 - state.cognitive_load,  # ì—­ë°©í–¥
        ]

        avg = sum(flow_indicators) / len(flow_indicators)
        return 0.5 + avg  # [0.5, 1.5] ë²”ìœ„ë¡œ ë³€í™˜
```

### 4.2 _memory_engine.py í™•ì¥

ê¸°ì¡´ `MemoryScore`ì™€ `StudentStateVector` ìƒí˜¸ ë³€í™˜:

```python
# holons/_memory_engine.py ì— ì¶”ê°€

class EnhancedMemoryEngine(MemoryEngine):
    """ê¸°ì¡´ MemoryEngine + Quantum State í†µí•©"""

    @staticmethod
    def memory_score_to_state_vector(score: MemoryScore) -> StudentStateVector:
        """MemoryScoreë¥¼ StudentStateVector ì¼ë¶€ ì°¨ì›ì— ë§¤í•‘"""
        state = StudentStateVector()

        # MemoryScore 5ê°œ ì»´í¬ë„ŒíŠ¸ â†’ ê´€ë ¨ ì°¨ì›ì— ë§¤í•‘
        state.practice_frequency = score.usage_frequency
        state.achievement_emotion = score.impact_score
        state.metacognition = score.system_reflection
        state.goal_setting = score.goal_alignment
        state.emotional_regulation = score.emotional_intensity

        return state

    @staticmethod
    def state_vector_to_memory_score(state: StudentStateVector) -> MemoryScore:
        """StudentStateVectorì—ì„œ MemoryScore ê´€ë ¨ ê°’ ì¶”ì¶œ"""
        return MemoryScore(
            usage_frequency=state.practice_frequency,
            impact_score=state.achievement_emotion,
            system_reflection=state.metacognition,
            goal_alignment=state.goal_setting,
            emotional_intensity=state.emotional_regulation
        )
```

---

## 5. ì‚¬ìš© ì˜ˆì‹œ

### 5.1 ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from holons._quantum_state import StudentStateVector
from holons._quantum_entanglement import EntanglementMap
from holons._quantum_evolution import HamiltonianEvolution, EvolutionConfig

# 1. í•™ìƒ í˜„ì¬ ìƒíƒœ ì •ì˜
student = StudentStateVector(
    concept_mastery=0.6,
    cognitive_load=0.7,      # ë†’ìŒ - ë¬¸ì œ
    motivation=0.4,          # ë‚®ìŒ - ë¬¸ì œ
    anxiety=0.6,             # ë†’ìŒ - ë¬¸ì œ
    attention_level=0.5,
    persistence=0.6,
)

# 2. ì—ì´ì „íŠ¸ ì–½í˜ ë§µ ë¡œë“œ
entanglement = EntanglementMap()

# 3. Flow Stateë¡œ ì§„í™”
config = EvolutionConfig(learning_rate=0.05, max_iterations=50)
evolution = HamiltonianEvolution(entanglement, config)

optimized = evolution.evolve_to_flow_state(student)

# 4. ê²°ê³¼ í™•ì¸
print(f"Before: anxiety={student.anxiety}, motivation={student.motivation}")
print(f"After:  anxiety={optimized.anxiety}, motivation={optimized.motivation}")
```

### 5.2 ì„œë²„ API í†µí•©

```python
# server.py ì— ì¶”ê°€

@app.route('/api/quantum/optimize', methods=['POST'])
def quantum_optimize():
    """í•™ìƒ ìƒíƒœ ìµœì í™” API"""
    data = request.json

    # ì…ë ¥ íŒŒì‹±
    state_dict = data.get('student_state', {})
    student = StudentStateVector(**state_dict)

    # ìµœì í™” ì‹¤í–‰
    entanglement = EntanglementMap()
    evolution = HamiltonianEvolution(entanglement)
    optimized = evolution.evolve_to_flow_state(student)

    return jsonify({
        'original': student.__dict__,
        'optimized': optimized.__dict__,
        'convergence_steps': len(evolution.get_convergence_history()),
        'energy_reduction': evolution.get_convergence_history()[0] - evolution.get_convergence_history()[-1]
    })
```

---

## 5.3 ê°€ì¤‘ì¹˜ ë¶•ê´´ ì‹œë‚˜ë¦¬ì˜¤ (Wave Function Collapse)

### ê°œë…

í•™ìƒ ë°ì´í„°ì˜ **ì •ì²´ ìƒíƒœ**ë¥¼ ê°ì§€í•˜ê³ , ê°€ëŠ¥í•œ **ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ë“¤ì˜ ì¤‘ì²© ìƒíƒœ**ë¥¼ ê³„ì‚°í•œ í›„, í™•ë¥ ì ìœ¼ë¡œ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì‹œë‚˜ë¦¬ì˜¤ë¡œ **íŒŒë™í•¨ìˆ˜ ë¶•ê´´**ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì„ ì œì  ê°œì… ê²°ì •ì„ ë‚´ë¦°ë‹¤.

```
ì •ì²´ ê°ì§€ â†’ ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ì²© â†’ í™•ë¥  ì¡°ì • â†’ íŒŒë™í•¨ìˆ˜ ë¶•ê´´ â†’ ê°œì… ê²°ì •
```

### í•µì‹¬ ìˆ˜ì‹

#### 1. ì •ì²´ ì ìˆ˜ (Stagnation Score)

```
S_stagnation = 1 / (1 + ÏƒÂ²)
```

- ÏƒÂ² = ìµœê·¼ Nì¼ê°„ ë°ì´í„°ì˜ ë¶„ì‚°
- ë¶„ì‚°ì´ ì‘ì„ìˆ˜ë¡ ì •ì²´ ì ìˆ˜ê°€ ë†’ìŒ (ìµœëŒ€ 1.0)

#### 2. ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ì²© (Superposition)

```
|ÏˆâŸ© = Î±|ë°˜ë“±âŸ© + Î²|í•˜ë½âŸ© + Î³|ì •ì²´âŸ©
```

- ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” ê³ ìœ í•œ ìœ„ìƒ(phase)ì„ ê°€ì§
  - ë°˜ë“±: 0Â° (ê±´ê°•í•œ ìƒíƒœ)
  - ì •ì²´: 90Â° (ì¤‘ë¦½)
  - í•˜ë½: 135Â° (ìœ„í—˜ ìƒíƒœ)

#### 3. ë² ì´ì§€ì•ˆ í™•ë¥  ì¡°ì • (Bayesian Update)

```python
P(scenario | context) = P(context | scenario) Ã— P(scenario) / P(context)
```

ë§¥ë½ ì¸ì:
- `stagnation_long`: ì •ì²´ ì§€ì† ê¸°ê°„ â‰¥ 5ì¼ â†’ í•˜ë½ í™•ë¥  Ã—1.2
- `near_critical`: í˜„ì¬ê°’ < ê¸°ì¤€ì„  - 5% â†’ í•˜ë½ í™•ë¥  Ã—1.3
- `recent_decline`: ì¶”ì„¸ < -0.5 â†’ í•˜ë½ í™•ë¥  Ã—1.1

#### 4. Quantum Amplitude ê³„ì‚°

```python
amplitude = sqrt(probability)
phase = scenario_phase_deg * Ï€ / 180
```

#### 5. íŒŒë™í•¨ìˆ˜ ë¶•ê´´ (Collapse)

```python
collapsed_scenario = argmax(P(scenario | context))
entropy_reduction = H_before - H_after
```

- ì—”íŠ¸ë¡œí”¼ ê°ì†ŒëŸ‰ = ì˜ì‚¬ê²°ì • ì •ë³´ëŸ‰
- H_before: ë¶•ê´´ ì „ ì—”íŠ¸ë¡œí”¼ (ë¶ˆí™•ì‹¤ì„±)
- H_after = 0: ë¶•ê´´ í›„ ì™„ì „ í™•ì •

### êµ¬í˜„ ì˜ˆì‹œ

```python
from dataclasses import dataclass
from typing import List, Dict
import math

@dataclass
class FutureScenario:
    """ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜"""
    name: str
    phase_deg: float
    base_probability: float
    predicted_value: float
    agent_intervention: str

class WaveFunctionCollapse:
    """
    íŒŒë™í•¨ìˆ˜ ë¶•ê´´ ì—”ì§„
    
    ì •ì²´ ìƒíƒœ ê°ì§€ â†’ ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ì²© â†’ í™•ë¥  ì¡°ì • â†’ ë¶•ê´´
    """
    
    # ê¸°ë³¸ ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜ (engine_config.php ì—ì´ì „íŠ¸ ì´ë¦„ê³¼ ë™ê¸°í™”)
    DEFAULT_SCENARIOS = {
        "rebound": FutureScenario("ë°˜ë“±", 0, 0.35, 78, "Agent08_í‰ì˜¨ë„"),      # calmness
        "decline": FutureScenario("í•˜ë½", 135, 0.40, 62, "Agent05_í•™ìŠµê°ì •"),  # learning_emotion
        "plateau": FutureScenario("ì •ì²´ ì§€ì†", 90, 0.25, 72, "Agent09_í•™ìŠµê´€ë¦¬")  # learning_management
    }
    
    def __init__(self, decay_factor: float = 0.3):
        self.decay_factor = decay_factor  # ì‹œê°„ì  ê°ì‡ ìœ¨
    
    def detect_stagnation(self, values: List[float], window: int = 6) -> Dict:
        """ì •ì²´ íŒ¨í„´ ê°ì§€"""
        recent = values[-window:]
        mean = sum(recent) / len(recent)
        variance = sum((v - mean) ** 2 for v in recent) / len(recent)
        trend = (recent[-1] - recent[0]) / window
        
        stagnation_score = 1.0 / (1.0 + variance)
        
        return {
            "stagnation_score": stagnation_score,
            "variance": variance,
            "trend": trend,
            "pattern": "STAGNANT" if variance < 1.0 else "FLUCTUATING"
        }
    
    def calculate_adjusted_probabilities(
        self,
        stagnation_days: int,
        current_value: float,
        baseline: float,
        trend: float
    ) -> Dict[str, float]:
        """ë² ì´ì§€ì•ˆ í™•ë¥  ì¡°ì •"""
        # ë§¥ë½ ì¸ì ê³„ì‚°
        stagnation_factor = 1.2 if stagnation_days >= 5 else 1.0
        critical_factor = 1.3 if current_value < baseline - 5 else 1.0
        trend_factor = 1.1 if trend < -0.5 else 1.0
        
        decline_boost = stagnation_factor * critical_factor * trend_factor
        rebound_penalty = 1.0 / decline_boost
        
        probs = {
            "rebound": self.DEFAULT_SCENARIOS["rebound"].base_probability * rebound_penalty,
            "decline": self.DEFAULT_SCENARIOS["decline"].base_probability * decline_boost,
            "plateau": self.DEFAULT_SCENARIOS["plateau"].base_probability
        }
        
        # ì •ê·œí™”
        total = sum(probs.values())
        return {k: v / total for k, v in probs.items()}
    
    def collapse(self, adjusted_probs: Dict[str, float]) -> Dict:
        """íŒŒë™í•¨ìˆ˜ ë¶•ê´´ ìˆ˜í–‰"""
        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë¶•ê´´
        collapsed_key = max(adjusted_probs, key=adjusted_probs.get)
        collapsed_scenario = self.DEFAULT_SCENARIOS[collapsed_key]
        collapse_prob = adjusted_probs[collapsed_key]
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        entropy_before = -sum(
            p * math.log2(p) if p > 0 else 0 
            for p in adjusted_probs.values()
        )
        entropy_after = 0  # ì™„ì „ í™•ì •
        
        return {
            "collapsed_to": collapsed_key,
            "collapsed_scenario": collapsed_scenario,
            "collapse_probability": collapse_prob,
            "entropy_reduction": entropy_before - entropy_after,
            "quantum_signals": [
                {
                    "scenario": k,
                    "amplitude": math.sqrt(p),
                    "phase_deg": self.DEFAULT_SCENARIOS[k].phase_deg,
                    "probability": p * 100
                }
                for k, p in adjusted_probs.items()
            ]
        }
    
    def predict_with_intervention(
        self,
        current_value: float,
        collapsed_scenario: FutureScenario,
        baseline: float
    ) -> Dict:
        """ê°œì… ì—¬ë¶€ì— ë”°ë¥¸ ë¯¸ë˜ ì˜ˆì¸¡"""
        return {
            "current_state": f"{current_value}% (ì •ì²´)",
            "if_no_intervention": f"{collapsed_scenario.predicted_value}%",
            "if_intervention": f"{baseline}% (ê¸°ì¤€ì„  ë³µê·€)",
            "intervention_value": baseline - collapsed_scenario.predicted_value
        }
```

### ì‚¬ìš© ì˜ˆì‹œ

```python
# ì¹¨ì°©ë„ ë°ì´í„° ì •ì²´ ê°ì§€ ë° ë¯¸ë˜ ì˜ˆì¸¡
engine = WaveFunctionCollapse()

# 1. ì •ì²´ ê°ì§€
values = [75, 74, 73, 72, 72, 72, 72, 71, 72, 72]
stagnation = engine.detect_stagnation(values)
print(f"ì •ì²´ ì ìˆ˜: {stagnation['stagnation_score']:.3f}")

# 2. í™•ë¥  ì¡°ì •
probs = engine.calculate_adjusted_probabilities(
    stagnation_days=6,
    current_value=72,
    baseline=75,
    trend=stagnation['trend']
)
print(f"ì¡°ì •ëœ í™•ë¥ : {probs}")

# 3. íŒŒë™í•¨ìˆ˜ ë¶•ê´´
result = engine.collapse(probs)
print(f"ë¶•ê´´ ê²°ê³¼: {result['collapsed_to']} ({result['collapse_probability']*100:.0f}%)")
print(f"ì—”íŠ¸ë¡œí”¼ ê°ì†Œ: {result['entropy_reduction']:.3f} bits")

# 4. ë¯¸ë˜ ì˜ˆì¸¡
prediction = engine.predict_with_intervention(
    current_value=72,
    collapsed_scenario=result['collapsed_scenario'],
    baseline=75
)
print(f"ê°œì… ì‹œ íš¨ê³¼: +{prediction['intervention_value']:.1f}%")
```

### ì‹œê°„ì  ì—°ì‡„ì‘ìš© (Temporal Chain Effect)

ê³¼ê±° ì‹ í˜¸ê°€ í˜„ì¬ ì˜ì‚¬ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë©”ì»¤ë‹ˆì¦˜:

```python
# ì”ë¥˜íŒŒ ê°ì‡ 
A_residual(t) = A_0 Ã— e^(-Î»t)

# ëˆ„ì  amplitude
A_total = Î£(A_i Ã— e^(-Î»(t - t_i)))

# Î» = 0.3 (ì£¼ê°„ ê°ì‡ ìœ¨)
```

**ì˜ˆì‹œ**: 3ì£¼ê°„ ì—°ì† í•˜ë½ â†’ W3ì—ì„œ ë‹¨ìˆœ "íšŒë³µ ì¤‘"ìœ¼ë¡œ ì˜¤íŒ ë°©ì§€

| ì£¼ì°¨ | ë‹¨ë… ë¶„ì„ | ì‹œê°„ì  ì–½í˜ ë¶„ì„ |
|------|----------|-----------------|
| W1 | amplitude=0.85 â†’ HIGH | ë©”ëª¨ë¦¬ì— ì €ì¥ |
| W2 | amplitude=0.90 â†’ HIGH | +W1 ì”ë¥˜íŒŒ |
| W3 | amplitude=0.75 â†’ MEDIUM âŒ | Î£(W1,W2)=1.45 â†’ CRITICAL âœ… |

---

## 5.4 ê°œì… ì˜ì‚¬ê²°ì • ì—”ì§„ (Intervention Decision Engine, IDE)

> **íŒŒë™í•¨ìˆ˜ ë¶•ê´´ ì´í›„ "ì‹¤ì œ ê°œì… ì—¬ë¶€ì™€ ë°©ì‹"ì„ ê²°ì •í•˜ëŠ” ìµœì¢… ì˜ì‚¬ê²°ì • ë ˆì´ì–´**

### ê°œìš”

IDEëŠ” ê¸°ì¡´ 21ë‹¨ê³„ í”„ë¡œí† ì½œ + íŒŒë™í•¨ìˆ˜ ì²´ê³„ ìœ„ì— ì–¹ëŠ” **ìµœì¢… ì˜ì‚¬ê²°ì • ë ˆì´ì–´**ë¡œ, ì‚¬ëŒ ì„ ìƒë‹˜ì²˜ëŸ¼ íŒë‹¨í•˜ëŠ” ìë™ ê°œì… ì‹œìŠ¤í…œì„ êµ¬í˜„í•œë‹¤.

```
[1] ì—ì´ì „íŠ¸ë³„ Trigger ë°œìƒ
          â†“
[2] ê²½ê³„ì¡°ê±´(BCE) ì²´í¬
          â†“ (PASS)
[3] ê°œì… ì‹œë‚˜ë¦¬ì˜¤ í›„ë³´êµ° ìƒì„±
          â†“
[4] ì‹œë‚˜ë¦¬ì˜¤ ìš°ì„ ìˆœìœ„ í‰ê°€
          â†“
[5] í•„ìˆ˜ ì¶©ì¡±ì¡°ê±´ ì²´í¬
          â†“
[6] ìµœì  ìƒí˜¸ì‘ìš© ì„ íƒ
          â†“
[7] ê°œì… ì‹¤í–‰ (Mind â†’ Mouth)
```

### 5.4.1 STEP 1: Trigger ì‹ë³„

ê° ì—ì´ì „íŠ¸ëŠ” ìì‹ ì˜ **ë¬¸ì œ ìƒí™©**ì„ ê°ì§€í•˜ëŠ” Ruleì„ ê°€ì§„ë‹¤.

```python
@dataclass
class AgentTrigger:
    """ì—ì´ì „íŠ¸ë³„ ê°œì… íŠ¸ë¦¬ê±° ì¡°ê±´"""

    agent_triggers = {
        13: {  # í•™ìŠµì´íƒˆ (Drift)
            "condition": "focus_loss > threshold",
            "severity": "high",
            "response_time": "immediate"
        },
        11: {  # ë¬¸ì œë…¸íŠ¸ (ProblemNote)
            "condition": "misconception_detected == True",
            "severity": "medium",
            "response_time": "after_submission"
        },
        8: {   # ì¹¨ì°©ë„ (Calmness)
            "condition": "calmness_drop_rate > 0.15",
            "severity": "medium",
            "response_time": "gradual"
        },
        7: {   # ìƒí˜¸ì‘ìš©íƒ€ê²ŸíŒ… (InteractionTargeting)
            "condition": "engagement_score < 0.4",
            "severity": "low",
            "response_time": "scheduled"
        }
    }
```

**Trigger ë°œìƒ â†’ IDE íŒŒì´í”„ë¼ì¸ ì‹œì‘**

### 5.4.2 STEP 2: ê²½ê³„ì¡°ê±´(BCE) ì²´í¬

ê°œì… ì „ 4ê°€ì§€ ê²½ê³„ì¡°ê±´ì„ ê²€ì¦:

| BCE ì¡°ê±´ | ê²€ì¦ ë‚´ìš© | ìœ„ë°˜ ì‹œ ì²˜ë¦¬ |
|----------|----------|-------------|
| **ì´ì „ ìƒí˜¸ì‘ìš©** | ìµœê·¼ ê°œì… ì‹œì , ë™ì¼ ë°©ì‹ ë°˜ë³µ ì—¬ë¶€, ì‹¤íŒ¨ ì´ë ¥ | ê°œì… ê¸ˆì§€ ë˜ëŠ” ë°©ì‹ ë³€ê²½ |
| **í˜„ì¬ í™œë™ ì‹ë³„** | í’€ì´ ì¤‘ë‹¨/ì„¤ëª… ì½ê¸°/í…ŒìŠ¤íŠ¸ ëª¨ë“œ ê°ì§€ | ê°œì… ê¸ˆì§€ |
| **í•™ìƒ ì„ í˜¸ë„** | ë°©í•´ ë¯¼ê°í˜•/ë¹ ë¥¸ í”¼ë“œë°±í˜•/ì •ì„œ ì·¨ì•½í˜• | ê°œì… ë°©ì‹ ì¡°ì • |
| **ìˆ˜ìš©ì„± ì˜ˆì¸¡ê°’** | R_accept í™•ë¥  ê³„ì‚° | R<0.4: ê¸ˆì§€, 0.4â‰¤R<0.7: micro, Râ‰¥0.7: full |

```python
@dataclass
class BoundaryConditionEngine:
    """ê²½ê³„ì¡°ê±´ ê²€ì¦ ì—”ì§„"""

    def check_all_conditions(
        self,
        student_id: int,
        trigger_agent: int
    ) -> Tuple[bool, str]:
        """
        Returns: (í†µê³¼ì—¬ë¶€, ì‚¬ìœ )
        """
        # 1. ì´ì „ ìƒí˜¸ì‘ìš© ê²€ì‚¬
        last_interaction = self.get_last_interaction(student_id)
        if last_interaction.minutes_ago < 5:
            return False, "too_recent"

        if last_interaction.type == self.pending_type:
            return False, "same_type_repeated"

        # 2. í˜„ì¬ í™œë™ ì‹ë³„
        current_activity = self.detect_current_activity(student_id)
        if current_activity in ["solving", "reading", "test_mode"]:
            return False, f"blocked_by_{current_activity}"

        # 3. í•™ìƒ ì„ í˜¸ë„ ë°˜ì˜
        preferences = self.get_student_preferences(student_id)
        # preferences.sensitive_to_interruption ë“±

        # 4. ìˆ˜ìš©ì„± ì˜ˆì¸¡
        r_accept = self.predict_receptivity(student_id, trigger_agent)
        if r_accept < 0.4:
            return False, "low_receptivity"

        return True, "all_conditions_passed"
```

### 5.4.3 STEP 3: ê°œì… ì‹œë‚˜ë¦¬ì˜¤ í›„ë³´êµ° ìƒì„±

Triggerëœ ì—ì´ì „íŠ¸ ìœ í˜•ì— ë”°ë¼ ì‹œë‚˜ë¦¬ì˜¤ ë¬¶ìŒì„ ë¡œë”©:

| ìœ í˜• | ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤ | ì—°ê´€ ì—ì´ì „íŠ¸ |
|------|-------------|--------------|
| **ì˜¤ê°œë… í•´ê²°** | ê°œë…ì¬ì •ì˜, ì „ì œ í™•ì¸, ì‹œê°í™” ì„¤ëª… | Agent 11, 14 |
| **ì •ì„œ ì•ˆì •** | ì¹¨ì°©ë„ íšŒë³µ, ì¸ì§€ë¶€í•˜ ì¡°ì ˆ, íœ´ì‹ ì œì•ˆ | Agent 8, 9 |
| **ì´íƒˆ ë³µê·€** | ì§‘ì¤‘ ìœ ë„, ê°€ë²¼ìš´ ì§ˆë¬¸, ê°„ë‹¨í•œ ê³¼ì œ ì œê³µ | Agent 13 |
| **ë¬¸ì œ í•´ê²° ìœ ë„** | íŒíŠ¸(ë ˆë²¨ 1~3), í’€ì´ ë‹¨ê³„ ì œì‹œ | Agent 10, 11, 15 |
| **í•™ìŠµ ì§„í–‰ ë°©í–¥** | ëª©í‘œ ì¬ì •ë ¬, ì§„ë„ ë°©í–¥ ì œì‹œ | Agent 2, 3, 17 |
| **íŒ¨í„´ êµì •** | í’€ì´ íŒ¨í„´ í”¼ë“œë°±, ëŒ€í‘œ ë¬¸ì œ ì—°ê²° | Agent 12 |
| **ë©”íƒ€ì¸ì§€ ìœ ë„** | ìê¸°í™•ì¸ ì§ˆë¬¸, íŒë‹¨ ê·¼ê±° íƒìƒ‰ | Agent 4, 14 |

```python
class ScenarioGenerator:
    """ì‹œë‚˜ë¦¬ì˜¤ í›„ë³´êµ° ìƒì„±ê¸°"""

    scenario_mapping = {
        # Agent â†’ ì‹œë‚˜ë¦¬ì˜¤ ì¹´í…Œê³ ë¦¬
        13: ["drift_recovery", "engagement_boost", "light_task"],
        11: ["misconception_fix", "concept_clarify", "step_guide"],
        8:  ["emotional_support", "load_reduction", "rest_suggest"],
        7:  ["direction_guide", "goal_realign", "progress_feedback"],
    }

    def generate_candidates(
        self,
        trigger_agent: int,
        student_state: StudentStateVector
    ) -> List[InterventionScenario]:
        """íŠ¸ë¦¬ê±° ì—ì´ì „íŠ¸ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í›„ë³´ ìƒì„±"""
        categories = self.scenario_mapping.get(trigger_agent, [])
        candidates = []

        for category in categories:
            scenarios = self.load_scenarios_by_category(category)
            for s in scenarios:
                s.relevance_score = self.calculate_relevance(
                    s, student_state
                )
                candidates.append(s)

        return sorted(candidates, key=lambda x: -x.relevance_score)
```

### 5.4.4 STEP 4: ì‹œë‚˜ë¦¬ì˜¤ ìš°ì„ ìˆœìœ„ ê²°ì •

**Priority = ê°€ì¤‘í•© ê³µì‹**

```
Priority = Î±â‚Ã—Severity + Î±â‚‚Ã—Timing + Î±â‚ƒÃ—Ïˆ_Impact + Î±â‚„Ã—PreferenceMatch + Î±â‚…Ã—SuccessProb
```

| ìš”ì†Œ | ê°€ì¤‘ì¹˜ | ì„¤ëª… |
|------|:------:|------|
| **Severity** (ë¬¸ì œ ì‹¬ê°ë„) | Î±â‚=0.25 | ì˜¤ê°œë…/ì´íƒˆ ìœ„í—˜/ë¶€í•˜ í­ì£¼ ë“± |
| **Timing** (ì í•©ë„) | Î±â‚‚=0.20 | ì œì¶œ ì§í›„=1.0, í’€ì´ ì¤‘=0.2 |
| **Ïˆ_Impact** (íŒŒë™í•¨ìˆ˜ ì˜í–¥ë„) | Î±â‚ƒ=0.25 | Ïˆê°’ì— ë”°ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± |
| **PreferenceMatch** (ì„ í˜¸ë„ ë§¤ì¹­) | Î±â‚„=0.15 | í•™ìƒ ì„ í˜¸ ë°©ì‹ ì¼ì¹˜ë„ |
| **SuccessProb** (ì„±ê³µ í™•ë¥ ) | Î±â‚…=0.15 | ê³¼ê±° ë™ì¼ ìƒí™© ì„±ê³µë¥  |

```python
@dataclass
class PriorityCalculator:
    """ì‹œë‚˜ë¦¬ì˜¤ ìš°ì„ ìˆœìœ„ ê³„ì‚°ê¸°"""

    weights = {
        'severity': 0.25,
        'timing': 0.20,
        'psi_impact': 0.25,
        'preference_match': 0.15,
        'success_prob': 0.15
    }

    def calculate_priority(
        self,
        scenario: InterventionScenario,
        student_state: StudentStateVector,
        wavefunctions: Dict[str, float]
    ) -> float:
        """ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)"""

        # 1. ë¬¸ì œ ì‹¬ê°ë„
        severity = self.assess_severity(scenario)

        # 2. íƒ€ì´ë° ì í•©ë„
        timing = self.assess_timing(student_state.current_activity)

        # 3. íŒŒë™í•¨ìˆ˜ ì˜í–¥ë„
        psi_impact = self.calculate_psi_impact(scenario, wavefunctions)

        # 4. í•™ìƒ ì„ í˜¸ë„ ë§¤ì¹­
        pref_match = self.match_preferences(scenario, student_state)

        # 5. ê³¼ê±° ì„±ê³µ í™•ë¥ 
        success_prob = self.get_historical_success(scenario.type)

        return sum([
            self.weights['severity'] * severity,
            self.weights['timing'] * timing,
            self.weights['psi_impact'] * psi_impact,
            self.weights['preference_match'] * pref_match,
            self.weights['success_prob'] * success_prob
        ])

    def calculate_psi_impact(
        self,
        scenario: InterventionScenario,
        wavefunctions: Dict[str, float]
    ) -> float:
        """íŒŒë™í•¨ìˆ˜ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„±"""

        # Ïˆ_fluct â†‘ â†’ ì •ì„œì  ì•ˆì • ì‹œë‚˜ë¦¬ì˜¤ ìš°ì„ 
        if wavefunctions['psi_fluct'] > 0.6:
            if scenario.category == 'emotional_support':
                return 1.0

        # Ïˆ_align â†“ â†’ ë°©í–¥ ì¬ì •ë ¬ ìš°ì„ 
        if wavefunctions['psi_align'] < 0.4:
            if scenario.category == 'direction_guide':
                return 0.9

        # Ïˆ_tunnel ì‹¤íŒ¨ â†’ íŒíŠ¸ ì œê³µ ìš°ì„ 
        if wavefunctions['psi_tunnel'] < 0.5:
            if scenario.category == 'hint_provide':
                return 0.85

        # Ïˆ_affect ê³¼ë¶€í•˜ â†’ ë¶€í•˜ ê°ì†Œ ìµœìš°ì„ 
        if wavefunctions['psi_affect'] > 0.7:
            if scenario.category == 'load_reduction':
                return 1.0

        return 0.5  # ê¸°ë³¸ê°’
```

### 5.4.5 STEP 5: í•„ìˆ˜ ì¶©ì¡±ì¡°ê±´ ì²´í¬

ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” **í•„ìˆ˜ ì¡°ê±´**ì„ ì¶©ì¡±í•´ì•¼ ì‹¤í–‰ ê°€ëŠ¥:

| ì‹œë‚˜ë¦¬ì˜¤ | í•„ìˆ˜ ì¡°ê±´ | ì‹¤íŒ¨ ì‹œ |
|----------|----------|---------|
| ê°œë… ì¬ì •ì˜ | `Ïˆ_core.Î³(í˜¼ë€) > 0.35` | í›„ìˆœìœ„ ì´ë™ |
| íŒíŠ¸ ì œê³µ | `Ïˆ_tunnel < 0.5 AND cognitive_load < 0.7` | í›„ìˆœìœ„ ì´ë™ |
| ì •ì„œ ì•ˆì • | `Ïˆ_affect.Î¾(ê³¼ë¶€í•˜) > 0.3` | í›„ìˆœìœ„ ì´ë™ |
| ì´íƒˆ ë³µê·€ | `drift_risk > threshold` | í›„ìˆœìœ„ ì´ë™ |
| ì§„í–‰ ë°©í–¥ ì„¤ì • | `goal_alignment < 0.5` | í›„ìˆœìœ„ ì´ë™ |
| ë©”íƒ€ì¸ì§€ ì§ˆë¬¸ | `working_memory > 0.4` | í›„ìˆœìœ„ ì´ë™ |

```python
class PrerequisiteChecker:
    """í•„ìˆ˜ ì¡°ê±´ ê²€ì¦ê¸°"""

    prerequisites = {
        'concept_redefinition': {
            'condition': lambda wf, st: wf['psi_core_gamma'] > 0.35,
            'description': 'Ïˆ_core.Î³(í˜¼ë€) > 0.35'
        },
        'hint_provide': {
            'condition': lambda wf, st: (
                wf['psi_tunnel'] < 0.5 and
                st.cognitive_load < 0.7
            ),
            'description': 'Ïˆ_tunnel < 0.5 AND cognitive_load < 0.7'
        },
        'emotional_support': {
            'condition': lambda wf, st: wf['psi_affect_xi'] > 0.3,
            'description': 'Ïˆ_affect.Î¾(ê³¼ë¶€í•˜) > 0.3'
        },
        'drift_recovery': {
            'condition': lambda wf, st: st.drift_risk > 0.5,
            'description': 'drift_risk > threshold'
        },
        'direction_guide': {
            'condition': lambda wf, st: wf['psi_align'] < 0.5,
            'description': 'goal_alignment < 0.5'
        },
        'metacognition_prompt': {
            'condition': lambda wf, st: st.working_memory > 0.4,
            'description': 'working_memory > 0.4'
        }
    }

    def check_prerequisites(
        self,
        scenario: InterventionScenario,
        wavefunctions: Dict[str, float],
        student_state: StudentStateVector
    ) -> Tuple[bool, str]:
        """í•„ìˆ˜ ì¡°ê±´ ì¶©ì¡± ì—¬ë¶€ í™•ì¸"""
        prereq = self.prerequisites.get(scenario.type)
        if prereq is None:
            return True, "no_prerequisites"

        if prereq['condition'](wavefunctions, student_state):
            return True, "prerequisites_met"
        else:
            return False, f"failed: {prereq['description']}"
```

### 5.4.6 STEP 6: ìµœì¢… ìƒí˜¸ì‘ìš© ì„ íƒ

ëª¨ë“  ê²€ì¦ì„ í†µê³¼í•œ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ **ìµœê³  ìš°ì„ ìˆœìœ„** ì„ íƒ:

```python
@dataclass
class InterventionDecision:
    """ìµœì¢… ê°œì… ê²°ì •"""
    scenario: str           # ì‹œë‚˜ë¦¬ì˜¤ ìœ í˜•
    tone: str               # gentle | neutral | encouraging
    hint_level: int         # 0~3 (íŒíŠ¸ì¸ ê²½ìš°)
    timing: str             # immediate | after_submission | scheduled
    content_key: str        # ì½˜í…ì¸  ì¡°íšŒ í‚¤
    expected_receptivity: float  # ì˜ˆìƒ ìˆ˜ìš©ì„± (0.0~1.0)

class InterventionSelector:
    """ìµœì¢… ê°œì… ì„ íƒê¸°"""

    def select_best_intervention(
        self,
        candidates: List[InterventionScenario],
        student_state: StudentStateVector,
        wavefunctions: Dict[str, float]
    ) -> Optional[InterventionDecision]:
        """ìµœì  ê°œì… ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ"""

        for scenario in candidates:  # ìš°ì„ ìˆœìœ„ìˆœ ì •ë ¬ë¨
            # í•„ìˆ˜ ì¡°ê±´ ì²´í¬
            passed, reason = self.prereq_checker.check_prerequisites(
                scenario, wavefunctions, student_state
            )

            if passed:
                return InterventionDecision(
                    scenario=scenario.type,
                    tone=self.determine_tone(student_state),
                    hint_level=self.determine_hint_level(scenario),
                    timing=self.determine_timing(student_state),
                    content_key=scenario.content_key,
                    expected_receptivity=self.predict_receptivity(
                        scenario, student_state
                    )
                )

        return None  # ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì¡°ê±´ ë¶ˆì¶©ì¡±

    def determine_tone(self, state: StudentStateVector) -> str:
        """í•™ìƒ ìƒíƒœ ê¸°ë°˜ í†¤ ê²°ì •"""
        if state.anxiety > 0.6 or state.frustration > 0.5:
            return "gentle"
        elif state.confidence > 0.7:
            return "encouraging"
        return "neutral"
```

### 5.4.7 STEP 7: ê°œì… ì‹¤í–‰ (Mind â†’ Mouth)

ì„ íƒëœ ê²°ì •ì„ **Mind Layer**ë¡œ ì „ë‹¬í•˜ì—¬ ìì—°ì–´ ìƒì„±:

```python
class InterventionExecutor:
    """ê°œì… ì‹¤í–‰ê¸°"""

    def execute(self, decision: InterventionDecision) -> Dict:
        """Mind â†’ Mouth íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""

        # 1. Mind Layer: ìì—°ì–´ ìƒì„±
        message = self.mind_layer.generate_message(
            scenario=decision.scenario,
            tone=decision.tone,
            content_key=decision.content_key,
            hint_level=decision.hint_level
        )

        # 2. Mouth Layer: TTS ë³€í™˜ (ì„ íƒì )
        if self.tts_enabled:
            audio = self.mouth_layer.synthesize(
                text=message,
                emotion=decision.tone
            )
        else:
            audio = None

        # 3. ê°œì… ë¡œê·¸ ì €ì¥
        self.log_intervention(decision, message)

        return {
            "decision": decision.__dict__,
            "message": message,
            "audio": audio,
            "timestamp": datetime.now().isoformat()
        }
```

### 5.4.8 ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©

```python
class InterventionDecisionEngine:
    """ê°œì… ì˜ì‚¬ê²°ì • ì—”ì§„ (IDE) - ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.bce = BoundaryConditionEngine()
        self.generator = ScenarioGenerator()
        self.priority_calc = PriorityCalculator()
        self.prereq_checker = PrerequisiteChecker()
        self.selector = InterventionSelector()
        self.executor = InterventionExecutor()

    def process_trigger(
        self,
        student_id: int,
        trigger_agent: int,
        student_state: StudentStateVector,
        wavefunctions: Dict[str, float]
    ) -> Optional[Dict]:
        """
        IDE ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Returns:
            ì„±ê³µ ì‹œ: ê°œì… ì‹¤í–‰ ê²°ê³¼
            ì‹¤íŒ¨ ì‹œ: None
        """

        # STEP 2: BCE ì²´í¬
        bce_passed, bce_reason = self.bce.check_all_conditions(
            student_id, trigger_agent
        )
        if not bce_passed:
            return {"status": "blocked", "reason": bce_reason}

        # STEP 3: ì‹œë‚˜ë¦¬ì˜¤ í›„ë³´êµ° ìƒì„±
        candidates = self.generator.generate_candidates(
            trigger_agent, student_state
        )

        # STEP 4: ìš°ì„ ìˆœìœ„ ê³„ì‚° ë° ì •ë ¬
        for candidate in candidates:
            candidate.priority = self.priority_calc.calculate_priority(
                candidate, student_state, wavefunctions
            )
        candidates.sort(key=lambda x: -x.priority)

        # STEP 5 & 6: í•„ìˆ˜ ì¡°ê±´ ì²´í¬ + ìµœì¢… ì„ íƒ
        decision = self.selector.select_best_intervention(
            candidates, student_state, wavefunctions
        )

        if decision is None:
            return {"status": "no_valid_scenario"}

        # STEP 7: ê°œì… ì‹¤í–‰
        result = self.executor.execute(decision)
        result["status"] = "executed"

        return result
```

### 5.4.9 ì‹œìŠ¤í…œ ê°•ì 

| íŠ¹ì„± | ì„¤ëª… |
|------|------|
| **ê°œì… ì˜¤ë‚¨ìš© ë°©ì§€** | BCE ê²½ê³„ì¡°ê±´ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ê°œì… ì°¨ë‹¨ |
| **í•™ìƒ ë§ì¶¤ íƒ€ì´ë°** | í˜„ì¬ í™œë™, ì„ í˜¸ë„, ìˆ˜ìš©ì„± ë°˜ì˜ |
| **íŒŒë™í•¨ìˆ˜ ê¸°ë°˜ ì •ë°€ íŒë³„** | Ïˆ ê°’ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± í‰ê°€ |
| **21ë‹¨ê³„ ì‹œìŠ¤í…œ ì—°ê²°** | ê¸°ì¡´ ì—ì´ì „íŠ¸ Triggerì™€ ìì—°ìŠ¤ëŸ¬ìš´ í†µí•© |
| **ì •ì„œÂ·ì¸ì§€Â·ì„ í˜¸ë„ í†µí•©** | ë‹¤ì°¨ì› í•™ìƒ ìƒíƒœ ê³ ë ¤ |
| **ì™„ì „í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜** | Brain â†’ Mind â†’ Mouth íŒŒì´í”„ë¼ì¸ ì™„ì„± |

### 5.4.10 ê´€ë ¨ íŒŒë™í•¨ìˆ˜ ì—°ê²°

| íŒŒë™í•¨ìˆ˜ | IDEì—ì„œì˜ ì—­í•  |
|----------|---------------|
| `Ïˆ_core` | ê°œë… í˜¼ë€ë„ â†’ ì˜¤ê°œë… í•´ê²° ì‹œë‚˜ë¦¬ì˜¤ ìš°ì„ ìˆœìœ„ |
| `Ïˆ_affect` | ì •ì„œ ê³¼ë¶€í•˜ â†’ ì •ì„œ ì•ˆì • ì‹œë‚˜ë¦¬ì˜¤ ìµœìš°ì„  |
| `Ïˆ_fluct` | ë³€ë™ì„± â†’ ì•ˆì •í™” ê°œì… íŠ¸ë¦¬ê±° |
| `Ïˆ_align` | ë°©í–¥ ì •ë ¬ë„ â†’ ëª©í‘œ ì¬ì •ë ¬ ì‹œë‚˜ë¦¬ì˜¤ |
| `Ïˆ_tunnel` | í„°ë„ë§ ì‹¤íŒ¨ â†’ íŒíŠ¸ ì œê³µ ìš°ì„  |
| `Ïˆ_load` | ì¸ì§€ ë¶€í•˜ â†’ ë¶€í•˜ ê°ì†Œ ì¡°ê±´ |

---

## 6. êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: í•µì‹¬ ëª¨ë“ˆ (2ì£¼)

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ |
|--------|------|---------|
| StudentStateVector êµ¬í˜„ | `_quantum_state.py` | P0 |
| EntanglementMap êµ¬í˜„ | `_quantum_entanglement.py` | P0 |
| ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± | `test_quantum_*.py` | P0 |

### Phase 2: ì§„í™” ì—”ì§„ (2ì£¼)

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ |
|--------|------|---------|
| InterferenceCalculator êµ¬í˜„ | `_quantum_interference.py` | P1 |
| HamiltonianEvolution êµ¬í˜„ | `_quantum_evolution.py` | P1 |
| ê¸°ì¡´ ì—”ì§„ í†µí•© | `_brain_engine.py`, `_memory_engine.py` | P1 |

### Phase 3: API ë° ê²€ì¦ (2ì£¼)

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ |
|--------|------|---------|
| Server API ì¶”ê°€ | `server.py` | P2 |
| Dashboard í†µí•© | `dashboard.html` | P2 |
| ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ | `benchmarks/` | P2 |

### Phase 3.5: ê°€ì¤‘ì¹˜ ë¶•ê´´ (1ì£¼) âœ… êµ¬í˜„ë¨

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ | ìƒíƒœ |
|--------|------|---------|------|
| ì •ì²´ íŒ¨í„´ ê°ì§€ | `pocdashboard.php` | P1 | âœ… |
| ë¯¸ë˜ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ì²© | `pocdashboard.php` | P1 | âœ… |
| ë² ì´ì§€ì•ˆ í™•ë¥  ì¡°ì • | `pocdashboard.php` | P1 | âœ… |
| íŒŒë™í•¨ìˆ˜ ë¶•ê´´ | `pocdashboard.php` | P1 | âœ… |
| ì‹œë‚˜ë¦¬ì˜¤ 7 UI | `pocdashboard.php` | P1 | âœ… |

### Phase 4: ì‹œê°„ì  ì–½í˜ (2ì£¼) - ì˜ˆì •

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ |
|--------|------|---------|
| TemporalEntanglement êµ¬í˜„ | `_quantum_temporal.py` | P2 |
| ì”ë¥˜íŒŒ ê°ì‡  ê³„ì‚° | `_quantum_temporal.py` | P2 |
| ëˆ„ì  amplitude ì¶”ì  | `_quantum_temporal.py` | P2 |
| ë¹„êµ­ì†Œì  ìƒê´€ê´€ê³„ | `_quantum_entanglement.py` | P3 |

### Phase 4.5: IDE êµ¬í˜„ (3ì£¼) - ì„¤ê³„ ì™„ë£Œ

> **Intervention Decision Engine (IDE)** - Brain ë ˆì´ì–´ì˜ í•µì‹¬ ì˜ì‚¬ê²°ì • ì—”ì§„
> ì°¸ì¡°: [ì„¹ì…˜ 5.4](#54-intervention-decision-engine-ide)

#### 4.5.1 Core Components (1ì£¼)

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ | ì„¤ëª… |
|--------|------|---------|------|
| AgentTrigger êµ¬í˜„ | `_ide_trigger.py` | P1 | 21-Step Agent Protocol íŠ¸ë¦¬ê±° ê°ì§€ |
| BoundaryConditionEngine êµ¬í˜„ | `_ide_boundary.py` | P1 | 4ê°œ ê²½ê³„ì¡°ê±´(í•™ìŠµíë¦„/ì •ì„œ/ì¸ì§€ë¶€í•˜/í„°ë„ë§) ê²€ì¦ |
| IDE ê¸°ë³¸ êµ¬ì¡° | `_intervention_decision_engine.py` | P1 | 7ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ í”„ë ˆì„ì›Œí¬ |

#### 4.5.2 Scenario Engine (1ì£¼)

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ | ì„¤ëª… |
|--------|------|---------|------|
| ScenarioGenerator êµ¬í˜„ | `_ide_scenario.py` | P1 | ì‹œë‚˜ë¦¬ì˜¤ í›„ë³´êµ° ìƒì„± (ê°œì…/ë¹„ê°œì…/ë¯¸ì„¸ê°œì…) |
| PriorityCalculator êµ¬í˜„ | `_ide_priority.py` | P1 | ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ê³„ì‚° |
| PrerequisiteChecker êµ¬í˜„ | `_ide_prerequisite.py` | P2 | í•„ìˆ˜ ì¶©ì¡±ì¡°ê±´ ê²€ì¦ |

#### 4.5.3 Execution & Integration (1ì£¼)

| íƒœìŠ¤í¬ | íŒŒì¼ | ìš°ì„ ìˆœìœ„ | ì„¤ëª… |
|--------|------|---------|------|
| InterventionSelector êµ¬í˜„ | `_ide_selector.py` | P1 | ìµœì¢… ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ ë¡œì§ |
| InterventionExecutor êµ¬í˜„ | `_ide_executor.py` | P1 | Mindâ†’Mouth ì‹¤í–‰ ì—°ê²° |
| íŒŒë™í•¨ìˆ˜ ì—°ë™ | `_ide_wavefunction_adapter.py` | P2 | Ïˆ_core, Ïˆ_affect ë“± 6ì¢… íŒŒë™í•¨ìˆ˜ í†µí•© |
| API ì—”ë“œí¬ì¸íŠ¸ | `server.py` | P2 | `/api/ide/decide`, `/api/ide/execute` |
| ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | `test_ide_*.py` | P1 | ê° ì»´í¬ë„ŒíŠ¸ë³„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ |

#### 4.5.4 IDE ì˜ì¡´ì„± ë§µ

```
Phase 1 (StudentStateVector) â”€â”
                              â”œâ”€â†’ Phase 4.5 (IDE)
Phase 2 (HamiltonianEvolution)â”˜         â”‚
                                        â†“
                               Phase 5 (Mind/Mouth í†µí•©)
```

---

## 7. ì°¸ê³  ìë£Œ

### 7.1 ì–‘ìì—­í•™ ì›ë¦¬
- Superposition: ìƒíƒœ ì¤‘ì²© (|ÏˆâŸ© = Î±|0âŸ© + Î²|1âŸ©)
- Entanglement: Bell ìƒíƒœ, ìƒê´€ê´€ê³„
- Interference: ì´ì¤‘ìŠ¬ë¦¿ ì‹¤í—˜, ë³´ê°•/ìƒì‡„
- Hamiltonian: ì—ë„ˆì§€ ì—°ì‚°ì, ì‹œê°„ ì§„í™”
- **Wave Function Collapse**: ê´€ì¸¡ì— ì˜í•œ ìƒíƒœ ê²°ì •, í™•ë¥  â†’ í™•ì • ì „ì´

### 7.2 êµìœ¡í•™ ì´ë¡ 
- Flow Theory (Csikszentmihalyi)
- Cognitive Load Theory (Sweller)
- Self-Determination Theory (Deci & Ryan)
- Zone of Proximal Development (Vygotsky)

### 7.3 ì˜ˆì¸¡ ëª¨ë¸ë§
- **ë² ì´ì§€ì•ˆ ì¶”ë¡ **: ì‚¬ì „ í™•ë¥  Ã— ê°€ëŠ¥ë„ â†’ ì‚¬í›„ í™•ë¥ 
- **ì‹œê³„ì—´ ì •ì²´ ê°ì§€**: ë¶„ì‚° ê¸°ë°˜ plateau detection
- **ì—”íŠ¸ë¡œí”¼**: ì •ë³´ ì´ë¡ , ë¶ˆí™•ì‹¤ì„± ì¸¡ì •
- **ì‹œê°„ì  ê°ì‡ **: ì§€ìˆ˜ í•¨ìˆ˜ e^(-Î»t), ê³¼ê±° ì‹ í˜¸ì˜ ì˜í–¥ë ¥ ê°ì†Œ

---

## 8. ë²„ì „ íˆìŠ¤í† ë¦¬

| ë²„ì „ | ë‚ ì§œ | ì£¼ìš” ë³€ê²½ |
|------|------|----------|
| 1.0 | 2025-12-07 | ì´ˆê¸° ì„¤ê³„ì„œ ì‘ì„± |
| 1.1 | 2025-12-08 | ê°€ì¤‘ì¹˜ ë¶•ê´´(Wave Function Collapse) ì„¹ì…˜ ì¶”ê°€ |
| 1.2 | 2025-12-08 | **ì—ì´ì „íŠ¸ ì •ì˜ ë™ê¸°í™”** - AGENTS, CORE_ENTANGLEMENTS, AGENT_STATE_MAPPINGì„ engine_config.phpì™€ ë™ê¸°í™”. 21â†’22ê°œ ì—ì´ì „íŠ¸ í™•ì¥ |
| 1.3 | 2025-12-09 | **IDE(ê°œì… ì˜ì‚¬ê²°ì • ì—”ì§„) ì¶”ê°€** - ì„¹ì…˜ 5.4ì— 7ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì„¤ê³„ (Triggerâ†’BCEâ†’Scenarioâ†’Priorityâ†’Prerequisiteâ†’Selectâ†’Execute), Phase 4.5 ë¡œë“œë§µ ì¶”ê°€ |

---

*ë¬¸ì„œ ë*
