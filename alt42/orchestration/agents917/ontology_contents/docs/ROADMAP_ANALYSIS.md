# 📊 Mathking 온톨로지 시스템 - 전체 로드맵 상세 분석

**작성일**: 2025-11-01
**버전**: 1.0
**목적**: Phase 0 ~ Phase 5 로드맵의 실현 가능성, 난이도, 소요 기간 분석

---

## 📍 현재 위치 및 목표

### 현재 상태 (Phase 0 완료)

```yaml
completed:
  - 웹 인터페이스: inference_lab_v2.php (실시간 추론 실험)
  - 기본 추론 엔진: 3개 규칙 (하드코딩)
  - 온톨로지 파일: 01_minimal_ontology.json (구조만)
  - 22개 에이전트: agent_01 ~ agent_22 (구조 완성)
  - 테스트 자동화: Playwright E2E 테스트

strengths:
  - 실제 작동하는 프로토타입
  - 깨끗한 아키텍처 설계
  - 단계별 확장 가이드 준비

weaknesses:
  - 온톨로지를 실제로 사용하지 않음 (규칙이 하드코딩됨)
  - 에이전트-온톨로지 연동 없음
  - LLM 통합 없음
  - Moodle LMS 연동 없음
```

### 최종 목표 (Phase 5)

```yaml
target_system:
  name: "Mathking 자동개입 v1.0"

  components:
    - 22개 에이전트 전체 통합
    - 6레이어 온톨로지 시스템
    - 규칙 엔진 + LLM 하이브리드 추론
    - Moodle LMS 활동/기능 자동 호출
    - 학생 페르소나 기반 개입 강도 조절

  capabilities:
    - 실시간 학습 상황 모니터링 (30분 Heartbeat)
    - 증거 기반 자동 개입 결정
    - 개인화된 학습 지시문 생성
    - 다중 에이전트 협업 조율

  value:
    - 교사 업무 자동화 (개입 결정의 80% 자동화)
    - 학습 효율 향상 (개인화된 적시 개입)
    - 데이터 기반 의사결정 (증거 수집 및 분석)
```

---

## 🗺️ Phase별 상세 분석

### Phase 1: 온톨로지 확장 (감정 시스템)

#### 목표
- 개념 3개 → 10개 확장
- 규칙 3개 → 10개 확장
- **온톨로지 기반 추론으로 전환** (핵심!)

#### 기술적 요구사항

```yaml
ontology_changes:
  - 감정 인스턴스 5개 추가 (좌절, 집중, 피로, 불안, 기쁨)
  - 관계 속성 추가 (hasIntensity, triggersAction)
  - 규칙을 JSON-LD로 정의

engine_changes:
  - PHP에서 온톨로지 파일 파싱
  - JSON-LD 규칙 동적 로드
  - Python 추론 엔진 개선 (lambda → 온톨로지 기반)

interface_changes:
  - 감정 선택 옵션 5개로 확장
  - 추론 결과에 적용된 규칙 ID 표시
```

#### 난이도 평가

| 항목 | 난이도 | 예상 시간 | 위험도 |
|------|--------|-----------|--------|
| 온톨로지 파일 확장 | ⭐ 쉬움 | 2시간 | 낮음 |
| 규칙을 JSON-LD로 변환 | ⭐⭐ 보통 | 4시간 | 중간 |
| PHP 파서 구현 | ⭐⭐⭐ 어려움 | 8시간 | 높음 |
| Python 엔진 리팩토링 | ⭐⭐⭐ 어려움 | 12시간 | 높음 |
| 테스트 및 검증 | ⭐⭐ 보통 | 6시간 | 중간 |

**총 예상 시간**: **1-2주** (전일 작업 기준 4-6일)

#### 달성 시 얻는 것

✅ **온톨로지 기반 시스템의 기초** - 이후 모든 단계의 토대
✅ **동적 규칙 추가 가능** - 코드 수정 없이 규칙 확장
✅ **실제 사용 가능한 감정 인식** - 5가지 감정 상태 처리

---

### Phase 2: 복합 조건 추론

#### 목표
- 개념 10개 → 15개 확장
- 규칙 10개 → 20개 확장 (복합 조건 5개 포함)
- **AND, OR 논리 연산 지원**

#### 기술적 요구사항

```yaml
ontology_changes:
  - Learning 개념 추가 (학습 활동)
  - 관계: isLearning, hasRetryCount, hasDifficultyLevel
  - 복합 조건 규칙 정의 (condition_1 AND condition_2)

engine_changes:
  - 복합 조건 평가기 구현
  - 조건 조합 로직 (AND, OR, NOT)
  - 우선순위 기반 규칙 선택

new_features:
  - 학습 진행 상태 추적
  - 재시도 횟수 기반 난이도 조정
  - 복합 상황 인식 (예: 좌절 + 반복 실패 → 난이도 하향)
```

#### 난이도 평가

| 항목 | 난이도 | 예상 시간 | 위험도 |
|------|--------|-----------|--------|
| 복합 개념 정의 | ⭐⭐ 보통 | 3시간 | 낮음 |
| 논리 연산자 구현 | ⭐⭐⭐ 어려움 | 10시간 | 높음 |
| 우선순위 시스템 | ⭐⭐⭐ 어려움 | 8시간 | 중간 |
| 테스트 케이스 작성 | ⭐⭐ 보통 | 6시간 | 낮음 |

**총 예상 시간**: **2-3주**

#### 달성 시 얻는 것

✅ **실제 교육 상황 모델링 가능** - 복잡한 학습 맥락 이해
✅ **정교한 개입 결정** - 단순 규칙에서 맥락 기반 추론으로
✅ **확장 가능한 규칙 시스템** - 무한정 규칙 추가 가능

---

### Phase 3: 에이전트 연동 (1개 에이전트)

#### 목표
- 개념 15개 → 30개 확장
- 규칙 20개 → 50개 확장
- **첫 번째 에이전트 연동** (agent_04: 문제활동 또는 agent_05: 학습정서)

#### 기술적 요구사항

```yaml
ontology_changes:
  - Agent 개념 추가
  - CurriculumAgent 또는 EmotionAgent 정의
  - 관계: providesGuidance, triggersIntervention

agent_integration:
  - 에이전트 태스크 정의 (agent_04/tasks.yaml)
  - 증거 수집 인터페이스 (Evidence 객체)
  - 지시문 생성 로직 (Directive 객체)

database_schema:
  - mdl_agent_evidence (증거 저장)
  - mdl_agent_directives (지시문 저장)
  - mdl_agent_heartbeat (실행 기록)

backend_api:
  - POST /api/agents/{id}/collect-evidence
  - POST /api/agents/{id}/generate-directive
  - GET /api/agents/{id}/status
```

#### 난이도 평가

| 항목 | 난이도 | 예상 시간 | 위험도 |
|------|--------|-----------|--------|
| 온톨로지 에이전트 정의 | ⭐⭐ 보통 | 4시간 | 낮음 |
| DB 스키마 설계 | ⭐⭐⭐ 어려움 | 8시간 | 중간 |
| 증거 수집 API | ⭐⭐⭐⭐ 매우 어려움 | 16시간 | 높음 |
| 지시문 생성 로직 | ⭐⭐⭐⭐ 매우 어려움 | 20시간 | 높음 |
| Moodle DB 연동 | ⭐⭐⭐ 어려움 | 12시간 | 높음 |

**총 예상 시간**: **4-6주**

#### 주요 도전 과제

⚠️ **Moodle 데이터 구조 이해** - mdl_course, mdl_user, mdl_quiz 등
⚠️ **Heartbeat 스케줄러 구현** - 30분마다 자동 실행
⚠️ **증거 데이터 정의** - 무엇을 수집할지 결정
⚠️ **지시문 형식 표준화** - 에이전트 간 일관성

#### 달성 시 얻는 것

✅ **실제 작동하는 에이전트** - 증거 기반 자동 개입
✅ **확장 가능한 아키텍처** - 나머지 21개 에이전트 추가 가능
✅ **교육적 가치 검증** - 실제 학습 상황에서 효과 측정

---

### Phase 4: 다중 에이전트 통합 (5개 에이전트)

#### 목표
- 개념 30개 → 100개 확장
- 규칙 50개 → 200개 확장
- **5개 주요 에이전트 협업** (Curriculum, Assessment, Content, Emotion, Interaction)

#### 기술적 요구사항

```yaml
multi_agent_coordination:
  - 에이전트 간 Task Link (ontology layer 3.1)
  - 협업 패턴 정의 (순차, 병렬, 조건부)
  - 충돌 해결 메커니즘 (우선순위, 조정 알고리즘)

advanced_reasoning:
  - 에이전트 조합 규칙 (A + B → 협업 개입)
  - 맥락 공유 프로토콜
  - 상태 동기화

system_integration:
  - 통합 대시보드 (5개 에이전트 상태 모니터링)
  - 통합 로그 시스템
  - 성능 측정 및 최적화
```

#### 난이도 평가

| 항목 | 난이도 | 예상 시간 | 위험도 |
|------|--------|-----------|--------|
| 협업 온톨로지 설계 | ⭐⭐⭐⭐ 매우 어려움 | 24시간 | 높음 |
| 충돌 해결 로직 | ⭐⭐⭐⭐⭐ 극도로 어려움 | 40시간 | 매우 높음 |
| 5개 에이전트 구현 | ⭐⭐⭐⭐ 매우 어려움 | 80시간 | 높음 |
| 통합 테스트 | ⭐⭐⭐ 어려움 | 20시간 | 중간 |

**총 예상 시간**: **3-4개월**

#### 주요 도전 과제

⚠️ **복잡도 폭발** - 에이전트 조합 경우의 수 급증
⚠️ **디버깅 어려움** - 다중 에이전트 상호작용 추적
⚠️ **성능 문제** - 5개 에이전트 동시 실행 시 리소스 관리
⚠️ **일관성 유지** - 에이전트 간 데이터 동기화

#### 달성 시 얻는 것

✅ **완전한 학습 지원 시스템** - 커리큘럼 + 평가 + 감정 + 상호작용
✅ **복잡한 학습 맥락 처리** - 실제 교육 현장의 다양한 상황 대응
✅ **검증된 아키텍처** - Phase 5로 확장할 준비 완료

---

### Phase 5: 전체 시스템 통합 (22개 에이전트)

#### 목표
- **22개 에이전트 전체 통합**
- **6레이어 온톨로지 완성**
- **LLM 추론 통합** (규칙으로 처리 못하는 케이스)
- **프로덕션 배포**

#### 기술적 요구사항

```yaml
complete_ontology:
  - Layer 3.1: 에이전트/태스크 협력 온톨로지
  - Layer 3.2: LMS 활동/기능 매핑 온톨로지
  - Layer 3.3: Heartbeat 기반 동적 상호작용 온톨로지
  - Layer 3.4: 페르소나 상관관계 온톨로지
  - Layer 3.5: 페르소나 응답 시나리오 온톨로지
  - Layer 3.6: 콘텐츠 시스템 상관관계 온톨로지

llm_integration:
  - GPT-4 또는 Claude API 연동
  - 규칙 엔진 → LLM 라우팅 로직
  - LLM 프롬프트 템플릿 (지식 베이스 기반)
  - 안전장치 (guardrails, validation)

knowledge_base:
  - 의사결정 지식 (knowledge/의사결정_지식.md → 규칙 변환)
  - 에이전트별 프롬프트 템플릿
  - 페르소나 데이터베이스

production_readiness:
  - 성능 최적화 (캐싱, 인덱싱)
  - 에러 처리 및 복구
  - 모니터링 및 알림
  - 백업 및 롤백 전략
  - 보안 (인증, 권한, 데이터 보호)
```

#### 난이도 평가

| 항목 | 난이도 | 예상 시간 | 위험도 |
|------|--------|-----------|--------|
| 6레이어 온톨로지 완성 | ⭐⭐⭐⭐⭐ 극도로 어려움 | 80시간 | 매우 높음 |
| 22개 에이전트 구현 | ⭐⭐⭐⭐⭐ 극도로 어려움 | 200시간 | 매우 높음 |
| LLM 통합 | ⭐⭐⭐⭐ 매우 어려움 | 60시간 | 높음 |
| 지식 베이스 구축 | ⭐⭐⭐⭐ 매우 어려움 | 100시간 | 높음 |
| 프로덕션 배포 | ⭐⭐⭐ 어려움 | 40시간 | 중간 |

**총 예상 시간**: **6-8개월**

#### 주요 도전 과제

⚠️ **프로젝트 관리** - 장기 프로젝트 일정 관리
⚠️ **기술 부채** - 초기 설계 결정의 누적된 영향
⚠️ **팀 협업** - 여러 개발자 간 코드 통합
⚠️ **사용자 피드백** - 실제 교육 현장 테스트 및 개선
⚠️ **비용 관리** - LLM API 호출 비용 최적화

#### 달성 시 얻는 것

✅ **완전한 AI 튜터 시스템** - 22개 에이전트 자동 조율
✅ **상용화 가능** - 실제 교육 기관에 배포 가능
✅ **연구 가치** - 온톨로지 기반 AI 시스템 사례 연구
✅ **확장 기반** - v2.0에서 실제 LMS 기능 호출로 확장

---

## 📊 로드맵 종합 평가

### 실현 가능성 분석

```yaml
phase_1:
  feasibility: "높음 (90%)"
  duration: "1-2주"
  risk_level: "낮음"
  recommendation: "즉시 시작 가능"

phase_2:
  feasibility: "높음 (85%)"
  duration: "2-3주"
  risk_level: "중간"
  recommendation: "Phase 1 검증 후 진행"

phase_3:
  feasibility: "중간 (65%)"
  duration: "4-6주"
  risk_level: "높음"
  recommendation: "POC(개념 증명) 먼저, 완전 구현은 단계적"

phase_4:
  feasibility: "중간 (50%)"
  duration: "3-4개월"
  risk_level: "매우 높음"
  recommendation: "장기 프로젝트로 접근, 마일스톤 설정"

phase_5:
  feasibility: "낮음 (30%)"
  duration: "6-8개월"
  risk_level: "극도로 높음"
  recommendation: "단계적 검증, 팀 확장 고려"
```

### 현실적 추천 경로

#### 옵션 A: 신속한 가치 실현 (3개월)

```
Phase 0 ─→ Phase 1 ─→ Phase 2 ─→ Phase 3 (1개 에이전트만)
           (2주)      (3주)      (6주)

목표: 1개 에이전트로 실제 교육 가치 검증
결과물: 감정 기반 학습 개입 시스템 (프로토타입)
```

#### 옵션 B: 안정적인 확장 (6개월)

```
Phase 0 ─→ Phase 1 ─→ Phase 2 ─→ Phase 3 (3개 에이전트)
           (2주)      (3주)      (12주)        ↓
                                             Phase 3.5 (안정화 및 테스트)
                                              (4주)

목표: 핵심 3개 에이전트로 학습 사이클 완성
결과물: 커리큘럼 + 평가 + 감정 통합 시스템 (MVP)
```

#### 옵션 C: 완전한 시스템 (12개월)

```
Phase 0 ─→ Phase 1 ─→ Phase 2 ─→ Phase 3 ─→ Phase 4 ─→ Phase 5
           (2주)      (3주)      (6주)     (12주)    (24주)

목표: 22개 에이전트 전체 통합
결과물: Mathking 자동개입 v1.0 (프로덕션)
```

---

## 🎯 우선순위 및 의사결정 기준

### 즉시 시작해야 하는 것 (Critical Path)

1. **Phase 1 실행** - 온톨로지 기반 추론으로 전환 (토대)
2. **DB 스키마 설계** - 에이전트 연동 준비
3. **1개 에이전트 선정** - Phase 3 POC용 (추천: agent_05 학습정서)

### 나중에 고려할 것 (Nice to Have)

1. LLM 통합 - Phase 3까지는 규칙만으로 충분
2. 전체 22개 에이전트 - 5개만으로도 가치 증명 가능
3. 프로덕션 최적화 - MVP 검증 후

### 포기해도 되는 것 (Out of Scope for v1.0)

1. 실제 LMS 기능 호출 - v2.0 목표
2. 완벽한 6레이어 온톨로지 - 필요한 부분만 구현
3. 모든 엣지 케이스 처리 - 80/20 법칙 적용

---

## 💡 최종 권장사항

### 단기 목표 (다음 1개월)

```yaml
week_1_2:
  - Phase 1 완료 (온톨로지 기반 추론)
  - 감정 5개, 규칙 10개 시스템 검증
  - 웹 인터페이스 업데이트

week_3_4:
  - Phase 2 시작 (복합 조건)
  - DB 스키마 설계
  - 1개 에이전트 선정 및 요구사항 정의
```

### 중기 목표 (3개월)

```yaml
month_2:
  - Phase 2 완료 (복합 조건 추론)
  - Phase 3 시작 (1개 에이전트 연동)
  - 증거 수집 API 구현

month_3:
  - Phase 3 완료 (1개 에이전트 완전 작동)
  - 실제 학습 데이터로 테스트
  - 교육적 효과 측정
```

### 장기 목표 (6-12개월)

```yaml
result_based_decision:
  if_successful_poc:
    - Phase 4 진행 (5개 에이전트)
    - 팀 확장 고려
    - 투자 유치 또는 예산 확보

  if_limited_value:
    - 1-3개 에이전트만 운영
    - Phase 5 포기, 안정화에 집중
    - 다른 가치 창출 방향 모색
```

---

## 🔍 성공 지표 (KPI)

### Phase 1 성공 기준
- [ ] 온톨로지 파일에서 규칙 동적 로드
- [ ] 5가지 감정 상태 정확하게 추론
- [ ] 코드 수정 없이 새 규칙 추가 가능
- [ ] 추론 시간 <100ms

### Phase 3 성공 기준 (POC)
- [ ] 1개 에이전트가 실제 학습 데이터 처리
- [ ] 증거 기반 자동 지시문 생성
- [ ] 30분 Heartbeat 스케줄러 작동
- [ ] 교사가 80% 이상 지시문 수용

### Phase 5 성공 기준 (최종)
- [ ] 22개 에이전트 정상 작동
- [ ] 다중 에이전트 협업 시나리오 10개 이상
- [ ] 학습 효율 향상 측정 (A/B 테스트)
- [ ] 프로덕션 배포 및 실사용

---

**문서 버전**: 1.0.0
**작성자**: Ontology Brain Team
**최종 업데이트**: 2025-11-01
**다음 검토 예정**: Phase 1 완료 후
